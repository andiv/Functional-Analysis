%% LyX 2.0.5 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[11pt,ngerman,english]{scrreprt}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[a4paper]{geometry}
\geometry{verbose,tmargin=2.6cm,bmargin=3.5cm,lmargin=2.6cm,rmargin=2.6cm}
\usepackage{fancyhdr}
\pagestyle{fancy}
\setlength{\parskip}{\medskipamount}
\setlength{\parindent}{0pt}
\usepackage{babel}
\usepackage{float}
\usepackage{textcomp}
\usepackage{mathrsfs}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{esint}
\usepackage[unicode=true,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=false,
 breaklinks=true,pdfborder={0 0 0},backref=page,colorlinks=false]
 {hyperref}
\hypersetup{pdftitle={Functional Analysis},
 pdfauthor={Andreas Völklein},
 pdfkeywords={Functional Analysis, Mathematics}}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{\texorpdfstring%
  {L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
  {LyX}}
\newcommand{\noun}[1]{\textsc{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\usepackage{enumitem}		% customizable list environments
\newlength{\lyxlabelwidth}      % auxiliary length 

\@ifundefined{date}{}{\date{}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{tikz,pgfplots}
%\usepackage{tikz-3dplot,cancel,polynom,tocbasic}
\usetikzlibrary{matrix,arrows,calc,decorations.markings,snakes,intersections}
\usetikzlibrary{external}
\tikzexternalize
\usepackage{latexsym,stmaryrd,stackrel,icomma,braket,bbm,subfig,framed,booktabs,esvect,scrhack,calc}
\usepackage [OMLmathrm,OMLmathbf,sfdefault=fav]{isomath}
\usepackage[explicit]{titlesec}
\usepackage[activate]{pdfcprot}

\pgfkeys{/pgf/number format/dec sep={\text{,}}}

% Inhaltsverzeichnis
\usepackage[subfigure]{tocloft}

\tocloftpagestyle{fancy}

\renewcommand{\cftchapindent}{1 em}
\renewcommand{\cftchapnumwidth}{1.5 em}

\renewcommand{\cftsecindent}{2.7 em}
\renewcommand{\cftsecnumwidth}{2.5em}

\renewcommand{\cftsubsecindent}{5.2 em}
\renewcommand{\cftsubsecnumwidth}{3.8 em}

\renewcommand{\cftsubsubsecindent}{9 em}
\renewcommand{\cftsubsubsecnumwidth}{4.5 em}

% Mathe-Operatoren
\DeclareMathOperator*{\exsop}{\exists}
\DeclareMathOperator*{\exsgop}{\exists!}
\DeclareMathOperator*{\fallop}{\forall}
\DeclareMathOperator*{\bcupdop}{\dot{\bigcup}}
\DeclareMathOperator*{\bcapdop}{\dot{\bigcap}}

%Operatornorm
\newcommand{\opnor}[1]{\abs{\hspace*{-1.1pt}\norm{#1}\hspace*{-1.1pt}}}

% Rotieren
\newcommand{\Rotate}[1]{
\tikzset{external/export next=false}
\begin{tikzpicture}
\node[rotate=90] {\ensuremath{#1}};
\end{tikzpicture}
}

%QED-Zeichen (Box)
\newcommand{\qed}{\ensuremath{\Box}}
\newcommand{\qqed}[1][\arabic{chapter}.\arabic{section}\ifnum\arabic{subsection}>0{.\arabic{subsection}}\fi]{\hspace*{1mm}\hfill\qed\ensuremath{_{\text{#1}}}}

% Mengen Modulo
\newcommand{\moduloT}[2]{
\mbox{\raisebox{0.6ex}{\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\Large /}
\raisebox{-0.6ex}{\hspace*{-1.5mm}\ensuremath{\displaystyle #2}}
}}

% Links Modulo
\newcommand{\lmoduloT}[2]{
\mbox{\raisebox{-0.6ex}{\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\Large \ensuremath{\backslash}}
\raisebox{0.6ex}{\hspace*{-1.5mm}\ensuremath{\displaystyle #2}}
}}

% Für Z/2Z, um nicht soviel schreiben zu müssen
\newcommand{\modloT}[2]{\moduloT{ \mathbb{#1}}{#2\mathbb{#1}}}

%Die Modulo-Kommandos in klein, für die Darstellungen unter Quantoren.
\newcommand{\moduloScriptT}[2]{
\mbox{\raisebox{0.4ex}{\scriptsize\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\footnotesize /}
\raisebox{-0.4ex}{\hspace*{-1.5mm}\scriptsize\ensuremath{\displaystyle #2}}
}}

\newcommand{\lmoduloScriptT}[2]{
\mbox{\raisebox{-0.4ex}{\scriptsize\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\footnotesize \ensuremath{\backslash}}
\raisebox{0.4ex}{\hspace*{-1.5mm}\scriptsize\ensuremath{\displaystyle #2}}
}}

\newcommand{\modloScriptT}[2]{\moduloScriptT{ \mathbb{#1}}{#2\mathbb{#1}}}

% Damit nicht immer "Kapitel 1" etc. über der Kapitelüberschrift steht
\titleformat{\chapter}
  {\huge\bfseries}
  {\textrm{\thechapter} }{0pt}
  {\textrm{#1} \thispagestyle{fancy}
  }

% Neudefinition der Abschnittsmarker für die Kopfzeile
\renewcommand\partmark[1]{\markboth{#1}{}}
\renewcommand\chaptermark[1]{\markright{\arabic{chapter} #1}}
\renewcommand\sectionmark[1]{}
\renewcommand\subsectionmark[1]{}

% Schriften auf Serif umstellen
\addtokomafont{descriptionlabel}{\rmfamily}
\addtokomafont{disposition}{\rmfamily}

% Zeilenumbrüche in Gleichungen
 \allowdisplaybreaks

% Kopf- und Fußzeile
% Höhe der Kopfzeile
\setlength{\headheight}{14pt}
% obere Trennlinie
%\renewcommand{\headrulewidth}{0.4pt}
\fancyhf{} %alle Kopf- und Fußzeilenfelder bereinigen
\fancyhead[L]{\textbf{Functional Analysis}} %Kopfzeile links
%\fancyhead[C]{\leftmark} %zentrierte Kopfzeile
\fancyhead[R]{\rightmark} %Kopfzeile rechts
\fancyfoot[C]{\thepage\quad\!\!\!\slash\quad\!\!\!\pageref{END-front}} %Seitenzahl der Front-Matter

\AtBeginDocument{
  \def\labelitemi{\normalfont\bfseries{--}}
  \def\labelitemii{\(\circ\)}
  \def\labelitemiii{\(\triangleright\)}
}

\makeatother

\begin{document}




% Shell-Kommando für Tikz-Externalize:
% pdflatex -shell-escape Functional-Analysis.tex 

\global\long\def\norm#1{\left\lVert #1\right\rVert }


\global\long\def\abs#1{\left\lvert #1\right\rvert }


\global\long\def\opnorm#1{\opnor{#1}}


\global\long\def\BRA#1{\Bra{#1}}


\global\long\def\KET#1{\Ket{#1}}


\global\long\def\BraKet#1{\Braket{#1}}


\global\long\def\mins{\text{-}}


\global\long\def\LB{\LBO}


\global\long\def\exs{\exsop}


\global\long\def\exsg{\exsgop}


\global\long\def\fall{\fallop}


\global\long\def\bcupd{\bcupdop}


\global\long\def\bcapd{\bcapdop}


\global\long\def\sr#1#2#3{\underset{#3}{\overset{#2}{#1}}}


\global\long\def\dd{\textnormal{d}}


\global\long\def\DD{\textnormal{D}}


\global\long\def\TT{\textnormal{T}}


\global\long\def\ii{\textbf{i}}


\global\long\def\modulo#1#2{\moduloT{#1}{#2}}


\global\long\def\lmodulo#1#2{\lmoduloT{#1}{#2}}


\global\long\def\modlo#1#2{\modloT{#1}{#2}}


\global\long\def\moduloScript#1#2{\moduloScriptT{#1}{#2}}


\global\long\def\lmoduloScript#1#2{\lmoduloScriptT{#1}{#2}}


\global\long\def\modloScript#1#2{\modloScriptT{#1}{#2}}


\pagenumbering{roman}


\title{\hspace*{1mm}\vspace*{-15mm}\\
{\Huge Functional Analysis}}


\author{{\small \vspace*{-5mm}}\textit{\small }\\
\textit{\small lecture by}\\
\textit{\noun{\small Prof. Dr. Felix Finster}}\textit{\small }\\
\textit{\small during the winter semester 2012/13}\\
\textit{\small revision and layout in \LyX{} by}\\
\textit{\noun{\small Andreas Völklein}}\\
{\small \vspace*{5mm}}\\
{\small \includegraphics[clip,width=15cm]{unir}}\textit{\noun{\small }}\\
{\small \vspace*{3mm}}\\
Last changed: \today\\
{\small \vspace*{-30mm}}}

\maketitle
\fancyhead[R]{License}
\setcounter{page}{2} % sonst gibt es aus irgendeinem Grund zweimal die Seite 1!?


\subsubsection*{ATTENTION}

This script does \emph{not} replace the lecture.\\
Therefore it is recommended \emph{strongly} to attend the lecture.

\vfill{}



\subsubsection*{Copyright Notice}

Copyright © 2012-2013 \noun{Andreas Völklein}

Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3
or any later version published by the Free Software Foundation;\\
with no Invariant Sections, no Front-Cover Texts, and no Back-Cover
Texts.\\
A copy of the license is included in the section entitled “GNU Free
Documentation License”.


\subsubsection*{Disclaimer of Warranty}

\noun{Unless otherwise mutually agreed to by the parties in writing
and to the extent not prohibited by applicable law, }\textbf{\noun{the
Copyright Holders and any other party, who may distribute the Document
as permitted above,   provide the Document “as is}}\textbf{”,}\textbf{\noun{
without warranty of any kind}}\noun{, expressed, implied, statutory
or otherwise, including, but not limited to, the implied warranties
of merchantability, fitness for a particular purpose, non-infringement,
the absence of latent or other defects, accuracy, or the absence of
errors, whether or not discoverable.}


\subsubsection*{Limitation of Liability}

\textbf{\noun{In no event}}\noun{ unless required by applicable law
or agreed to in writing }\textbf{\noun{will the Copyright Holders,
or any other party, who may distribute the Document as permitted above,
be liable to you for any damages}}\noun{, including, but not limited
to, any general, special, incidental, consequential, punitive or exemplary
damages, however caused, regardless of the theory of liability, arising
out of or related to this license or any use of or inability to use
the Document, even if they have been advised of the possibility of
such damages.}

\textbf{\noun{In no event will the Copyright Holders'/Distributor's
liability to you}}\noun{, whether in contract, tort (including negligence),
or otherwise, }\textbf{\noun{exceed the amount you paid the Copyright
Holders/Distributor}}\noun{ for the document under this agreement.}


\subsubsection*{Links}

The text of the “GNU Free Documentation License” can also be read
on the following site:
\begin{quote}
\url{https://www.gnu.org/licenses/fdl-1.3.en.html}
\end{quote}
A transparent copy of the recent version of this document can be downloaded
from:
\begin{quote}
\url{https://github.com/andiv/Functional-Analysis}
\end{quote}
\newpage{}

\fancyhead[R]{Literature}


\subsection*{Literature}
\begin{itemize}
\item \noun{Peter D. Lax: }\emph{Functional analysis}; Wiley-Interscience,
2002; ISBN: 0-471-55604-1\emph{}\\
(good reference)
\item \noun{Micheal Reed, Barry Simon}: \emph{Methods of Modern Mathematical
Physics I - Functional Analysis; }Academic Press, 2010; ISBN: 978-0-12-585050-6
\item \noun{Friedrich Hirzebruch, Winfried Scharlau}: \foreignlanguage{ngerman}{\emph{Einführung
in die Funktionalanalysis}}; Spektrum Verlag, 1996; ISBN: 3-86025-429-4\\
(paperback, small)
\item \noun{Dirk Werner}: \foreignlanguage{ngerman}{\emph{Funktionalanalysis}};
Springer, 2011; ISBN: 978-3-642-21016-7
\item \noun{Joachim Weidmann}: \foreignlanguage{ngerman}{\emph{Lineare Operatoren
in Hilberträumen, Teil I: Grundlagen}}; Teubner, 2000; ISBN: 3-519-02236-2
\item \noun{Walter Rudin}: \emph{Functional Analysis}; McGraw-Hill, 1991;
ISBN: 7-111-13415-X
\end{itemize}
Zorn's Lemma:
\begin{itemize}
\item \noun{Hans-Joachim Kowalsky, Gerhard O. Michler}: \foreignlanguage{ngerman}{\emph{Lineare
Algebra}}; de Gruyter, 2003; ISBN: 3-11-017963-6
\end{itemize}
Measure theory for the Riesz representation theorem:
\begin{itemize}
\item \noun{Walter Rudin}: \emph{Real and complex analysis}; McGraw-Hill,
2009; ISBN: 0-07-054234-1
\end{itemize}
{\small \newpage{}}\fancyhead[R]{Table of contents}
\fancyhead[C]{}

\tableofcontents{}\label{END-front}\newpage{}\pagenumbering{arabic}
\fancyfoot[C]{\thepage\quad\!\!\!\slash\quad\!\!\!\pageref{END}} % Seitenzahl des Hauptteils%DATE: Do 18.10.2012

\setcounter{chapter}{-1}

\fancyhead[R]{Motivation}
\fancyhead[C]{}


\chapter*{Motivation}

In linear algebra one mainly considers finite-dimensional vector spaces
with additional structures like norm $\norm .$ or scalar product
$\left\langle .,.\right\rangle $.

Let $\left(V,\left\langle .,.\right\rangle \right)$ be a finite-dimensional
scalar product space and $A:V\to V$ a linear map, which is self-adjoint,
that means for all $u,v\in V$:
\begin{align*}
\left\langle Au,v\right\rangle  & =\left\langle u,Av\right\rangle 
\end{align*}



\section*{Theorem \textmd{(orthonormal eigenvector basis)}}

There exists an orthonormal eigenvector basis $\left(u_{i}\right)_{i\in\left\{ 1,\ldots,n\right\} }$,
that means with the eigenvalues $\lambda_{i}\in\mathbb{R}$:
\begin{align*}
\left\langle u_{i},u_{j}\right\rangle  & =\delta_{ij} & Au_{i} & =\lambda_{i}u_{i}
\end{align*}
In infinite dimensions the generalization is the \emph{spectral theorem}.

First reformulate the result from linear algebra:\\
Let $E_{\lambda_{i}}$ be the orthogonal projection operator on the
eigenspace corresponding to $\lambda_{i}$. If this eigenspace is
one dimensional, this means:
\begin{align*}
E_{\lambda_{i}}v & =u_{i}\left\langle u_{i},v\right\rangle =\left|u_{i}\right>\left<u_{i}|v\right>
\end{align*}
Then one can write $A$ as:
\begin{align*}
A & =\sum_{i=1}^{n}\lambda_{i}E_{\lambda_{i}}
\end{align*}



\section*{Theorem \textmd{(spectral theorem)}}

Let $A\in L\left(H\right)$ be a self-adjoint (\foreignlanguage{ngerman}{selbstadjungiert})
operator, then it holds:
\begin{align*}
A & =\int_{\sigma\left(A\right)}\lambda\dd E_{\lambda}
\end{align*}
$\sigma\left(A\right)\subseteq\mathbb{R}$ is the spectrum of $A$
and $E_{\lambda}$ the projection-valued measure (\foreignlanguage{ngerman}{Spektralmaß}).

Applications typically are differential operators, for example:
\begin{align*}
\Delta_{\mathbb{R}^{3}} & =\frac{\partial^{2}}{\partial x_{1}^{2}}+\frac{\partial^{2}}{\partial x_{2}^{2}}+\frac{\partial^{2}}{\partial x_{3}^{2}}
\end{align*}
\begin{align*}
\Delta_{\mathbb{R}^{3}}:C_{0}^{\infty}\left(\mathbb{R}^{3}\right) & \to C^{\infty}\left(\mathbb{R}^{3}\right)\quad\text{linear operator}
\end{align*}
Applications in more detail are studied in the lectures on partial
differential equations I + II.


\chapter{Basic Notions}

\fancyhead[R]{\rightmark}
%\fancyhead[C]{\leftmark}

Let $E$ be a vector space (\foreignlanguage{ngerman}{Vektorraum}),
for example the finite-dimensional vector space $E\simeq\mathbb{R}^{3}$.\\
In the following list the later spaces are special cases of the previous
ones:
\begin{itemize}
\item topological vector spaces
\item metric spaces with a metric $d\left(.,.\right)$ (Polish spaces if
complete)
\item normed spaces with norm $\norm .$ (Banach spaces if complete)
\item scalar product spaces $\left\langle .,.\right\rangle $ (Hilbert spaces
if complete)
\end{itemize}
Let $\mathbb{K}$ be either $\mathbb{R}$ or $\mathbb{C}$.


\section{Definition \textmd{(metric, \texorpdfstring{$\varepsilon$}{epsilon}-ball,
Cauchy sequence, complete, Polish space)}}

A map $d:E\times E\to\mathbb{R}$ is called \emph{metric}, if for
all $x,y,z\in E$ holds:
\begin{enumerate}[label=\roman*)]
\item $d\left(x,y\right)=d\left(y,x\right)$ (symmetry)
\item $d\left(x,y\right)\ge0$ and $d\left(x,y\right)=0$ $\Leftrightarrow$
$x=y$ (positive definiteness)
\item $d\left(x,y\right)\le d\left(x,z\right)+d\left(z,y\right)$ (triangle
inequality)
\end{enumerate}
$B_{\varepsilon}\left(x\right):=\left\{ z\in E\big|d\left(x,z\right)<\varepsilon\right\} $
is called \emph{$\varepsilon$-ball}.\\
Consider the topology generated by $B_{\varepsilon}\left(x\right)$:
A set $\Omega\subseteq E$ is open if and only if:
\begin{align*}
\fall_{x\in\Omega}\exs_{\varepsilon\in\mathbb{R}_{>0}} & :B_{\varepsilon}\left(x\right)\subseteq\Omega
\end{align*}
\emph{Completeness}:\\
$\left(x_{n}\right)_{n\in\mathbb{N}}$ is a \emph{Cauchy sequence}
if and only if:
\begin{align*}
\fall_{\varepsilon\in\mathbb{R}_{>0}}\exs_{N\in\mathbb{N}}\fall_{n,m\in\mathbb{N}_{>N}} & :d\left(x_{n},x_{m}\right)<\varepsilon
\end{align*}
$E$ is \emph{complete} if and only if every Cauchy sequence has a
limit.\\
A complete metric space is also called a \emph{Polish space}.


\section{Definition \textmd{(norm, Banach space)}}

Let $\left(E,\norm .\right)$ be a \emph{normed space}, i.e. a $\mathbb{K}$-vector
space with a map $\norm .:E\to\mathbb{R}_{\ge0}$ called \emph{norm}
with the following properties for $x,y\in E$ and $\lambda\in\mathbb{K}$:
\begin{enumerate}[label=\roman*)]
\item $\norm x\ge0$ and $\norm x=0\Leftrightarrow x=0$ (positive definiteness)
\item $\norm{\lambda x}=\abs{\lambda}\cdot\norm x$ (homogeneity)
\item $\norm{u+v}\le\norm u+\norm v$ (triangle inequality)
\end{enumerate}
Define the metric $d\left(x,y\right):=\norm{x-y}$. A complete normed
spaces is called \emph{Banach space}.

Let $A:E\to F$ be a linear map between the Banach spaces $\left(E,\norm ._{E}\right)$
and $\left(F,\norm ._{F}\right)$.


\section{Definition \textmd{(continuous, bounded)}}

$A$ is \emph{continuous} (\foreignlanguage{ngerman}{stetig}) if $A^{-1}\left(\Omega\right)\subseteq E$
is open for all open $\Omega\subseteq F$.\\
$A$ is \emph{bounded} (\foreignlanguage{ngerman}{beschränkt}) if
there exists a $C\in\mathbb{R}_{>0}$ such that for all $u\in E$
holds:
\begin{align*}
\norm{Au}_{F} & \le C\norm u_{E}
\end{align*}



\section{Lemma \textmd{(continuous \texorpdfstring{$\Leftrightarrow$}{equivalent to}
bounded)}}

$A$ is continuous $\Leftrightarrow$ $A$ is bounded.


\subsubsection*{(no proof)}


\section{Definition \textmd{(dual space, sup-norm)}}

The \emph{dual space} of $E$ is the space of continuous linear mappings
from $E$ to $\mathbb{K}$:
\begin{align*}
E^{*} & =L\left(E,\mathbb{K}\right)
\end{align*}
$L\left(E,F\right)$ is a vector space: For $A,B\in L\left(E,F\right)$,
$\lambda,\mu\in\mathbb{K}$ and $u\in E$ define:
\begin{align*}
\left(\lambda A+\mu B\right)\left(u\right) & :=\lambda A\left(u\right)+\mu B\left(u\right)
\end{align*}
Define also a norm on $L\left(E,F\right)$, which is called \emph{sup-norm}:
\begin{align*}
\norm A & :=\sup_{u\in E,\norm u_{E}\le1}\norm{Au}_{F}
\end{align*}



\section{Theorem}

If $F$ is complete, so is $L\left(E,F\right)$.\\
In particular $E^{*}$ is a Banach space for every $E$.


\subsubsection*{(no proof)}


\chapter{The Hahn-Banach Theorem and Applications}

As a preparation we need Zorn's lemma.


\section{Definition \textmd{(partial ordering, chain, upper bound, maximal)}}

Let $A$ be a set and $\le$ a \emph{partial ordering} (\foreignlanguage{ngerman}{Halbordnung}),
i.e. for all $a,b,c\in A$:
\begin{enumerate}[label=\roman*)]
\item $a\le b$ and $b\le c$ $\Rightarrow$ $a\le c$ (transitivity)
\item $a\le a$ (reflexivity)
\item $a\le b\wedge b\le a\Rightarrow a=b$ (antisymmetry)
\end{enumerate}
\emph{Note}: We do \emph{not} demand that for all $a,b\in A$ holds:
\begin{align*}
\left(a\le b\right)\vee\left(b\le a\right)
\end{align*}
This is a property of a ordering relation.\\
$\left(A,\le\right)$ is called \emph{partially ordered set} (\foreignlanguage{ngerman}{teilweise
geordnete Menge}).\\
A subset $K\subseteq A$ is called \emph{chain} (\foreignlanguage{ngerman}{Kette,
total geordnete Teilmenge}) if for all $x,y\in K$ holds:
\begin{align*}
\left(x\le y\right)\vee\left(y\le x\right)
\end{align*}
An element $u\in A$ is called \emph{upper bound} (\foreignlanguage{ngerman}{obere
Schranke}) of $B\subseteq A$ if $x\le u$ for all $x\in B$.\\
An element $m\in A$ is called \emph{maximal} if $m\le a\in A\Rightarrow m=a$.


\section{Zorn's lemma}

Let $\left(A,\le\right)$ be a partially ordered set in which every
chain has an upper bound. Then there is a maximal element.


\subsubsection*{Proof}

This follows from the axiom of choice, see e.g. Kowalsky: Linear algebra.


\section{Definition \textmd{(sublinear)}}

Let $X$ be a \emph{real} vector space (without topology) and $l:X\to\mathbb{R}$
linear.\\
$p:X\to\mathbb{R}$ is called \emph{sublinear} if for all $x,y\in X$
and $a\in\mathbb{R}_{>0}$:
\begin{enumerate}[label=\roman*)]
\item $p\left(ax\right)=ap\left(x\right)$
\item $p\left(x+y\right)\le p\left(x\right)+p\left(y\right)$
\end{enumerate}
A typical example is $p\left(x\right)=\norm x$, but $p$ does not
need to be positive. Another example is any linear mapping.


\section{Theorem \textmd{(Hahn-Banach, real version, 1927/29)\label{sec:Thm-Hahn-Banach-real}}}

Let $X$ be a real vector space and $Y\subseteq X$ a subspace (\foreignlanguage{ngerman}{Untervektorraum}),
$p:X\to\mathbb{R}$ sublinear and $l:Y\to\mathbb{R}$ linear with
$l\left(y\right)\le p\left(y\right)$ for all $y\in Y$.\\
Then there is a linear extension (\foreignlanguage{ngerman}{Fortsetzung})
$\tilde{l}:X\to\mathbb{R}$ of $l$ to $X$, i.e. $\tilde{l}\big|_{Y}=l$,
such that for all $x\in X$ holds:
\begin{align*}
\tilde{l}\left(x\right) & \le p\left(x\right)
\end{align*}



\subsubsection*{Proof}
\begin{enumerate}[label=\roman*)]
\item Assume $Y\subsetneq X$, since otherwise there is nothing to prove.
Choose a vector $z\in X\setminus Y$. We want to extend $l$ to the
span of $Y$ and $\left\langle z\right\rangle $. $\tilde{l}\left(z\right)$
needs to be prescribed. For all $y\in Y$ and $a\in\mathbb{R}$ holds:
\begin{align*}
\tilde{l}\left(y+az\right) & \stackrel{\text{linearity}}{=}l\left(y\right)+a\tilde{l}\left(z\right)\stackrel{\text{demand}}{\le}p\left(y+az\right)
\end{align*}
If $a=0$, the inequality is clear. By homogeneity assumptions, it
is sufficient to consider the case $a=\pm1$. We thus demand for all
$y,y'\in Y$:
\begin{align*}
l\left(y\right)+\tilde{l}\left(z\right) & \le p\left(y+z\right)\\
l\left(y'\right)-\tilde{l}\left(z\right) & \le p\left(y'-z\right)
\end{align*}
This is equivalent to:
\begin{align*}
l\left(y'\right)-p\left(y'-z\right) & \le\tilde{l}\left(z\right)\le p\left(y+z\right)-l\left(y\right)
\end{align*}
We can choose $\tilde{l}\left(z\right)$ if and only if:
\begin{align*}
l\left(y'\right)-p\left(y'-z\right) & \le p\left(y+z\right)-l\left(y\right)
\end{align*}
(For example set $\tilde{l}\left(z\right)=\sup_{y'\in Y}l\left(y'\right)-p\left(y'-z\right)$.)
\begin{align*}
\Leftrightarrow\quad l\left(y'\right)+l\left(y\right)\stackrel{\text{lineariy}}{=}l\left(y'+y\right) & \le p\left(y+z\right)+p\left(y'-z\right)
\end{align*}
Now prove this inequality:\\
From $y'+y\in Y$ follows that $l\left(y+y'\right)\le p\left(y+y'\right)$
by hypothesis. Moreover, as $p$ is sublinear, it follows:
\begin{align*}
p\left(y+z-z+y'\right) & \le p\left(y'+z\right)+p\left(y'-z\right)
\end{align*}
So the inequality is shown. Thus $l$ can be extended to $Y+\left\langle z\right\rangle $.
\item Consider all extensions:
\begin{align*}
A & :=\left\{ \left(Z,l\right)|Y\subseteq Z\subseteq X\text{ subspace},\ l:Z\to\mathbb{R}\text{ extension of }l_{Y}:Y\to\mathbb{R}\right\} 
\end{align*}
%DATE: Fr 19.10.12\\
This set has a partial ordering $\le$ defined by $\left(Z,l\right)\le\left(Z',l'\right)$
if $Z\subseteq Z'$ and $l'\big|_{Z}=l$.\\
For an index set $I$ (possibly infinite, uncountable) let $K=\left\{ \left(Z_{\nu},l_{\nu}\right)|\nu\in I\right\} $
be a chain, i.e. for all $\left(Z,l\right),\left(Z',l'\right)\in K$:
\begin{align*}
\left(\left(Z,l\right)\le\left(Z',l'\right)\right) & \vee\left(\left(Z',l'\right)\le\left(Z,l\right)\right)
\end{align*}
Set $Z=\bigcup_{\nu\in I}Z_{\nu}$ and define $l:Z\to\mathbb{R}$
by $l\big|_{Z_{\nu}}=l_{\nu}$. (Thus suppose $u\in Z$, so there
is a $\nu\in I$ with $u\in Z_{\nu}$. Set $l\left(u\right):=l_{\nu}\left(u\right)$.
$\nu$ need not be unique. Suppose $u\in Z_{\nu'}$, then we know
that either $Z_{\nu'}\subseteq Z_{\nu}$ and $l_{\nu}\big|_{Z_{\nu'}}=l_{\nu'}$
or $Z_{\nu}\subseteq Z_{\nu'}$ and $l_{\nu'}\big|_{Z_{\nu}}=l_{\nu}$.
In both cases we have $l_{\nu}\left(u\right)=l_{\nu'}\left(u\right)$,
thus $l\left(u\right)$ is well defined.)\\
This $\left(Z,l\right)$ is an upper bound, because for all $\nu\in I$
we have $Z_{\nu}\subseteq Z=\bigcup_{\lambda\in I}Z_{\lambda}$ and
$l$ is an extension of $l_{\nu}$.\\
With Zorn's Lemma follows, that there exists an maximal element $\left(\tilde{Y},\tilde{l}\right)$.

\begin{description}
\item [{Claim:}] $\tilde{Y}=X$
\item [{Proof:}] Otherwise there would be a vector $u\in X\setminus\tilde{Y}$,
and $\tilde{l}$ could be extended to $\tilde{Y}\oplus\left\langle u\right\rangle $,
as shown in i), in contradiction to the maximality of $\tilde{l}$.
Thus $\left(X=\tilde{Y},\tilde{l}\right)$ is the desired extension.\qqed[Claim]
\end{description}
\end{enumerate}
\qqed


\section{Theorem \textmd{(Hahn-Banach, complex version)}}

Let $X$ be a complex vector space and $Y\subseteq X$ a subspace.
Before, we had $l\left(x\right)\le p\left(x\right)$ as condition,
which does not make sense in the complex case, since:
\begin{align*}
l\left(e^{\ii\varphi}x\right) & =e^{\ii\varphi}l\left(x\right)\stackrel{\text{in general}}{\not\in}\mathbb{R}
\end{align*}
Let $p:X\to\mathbb{R}$ be a \emph{seminorm}, i.e.:
\begin{enumerate}[label=\roman*)]
\item $p\left(ax\right)=\abs ap\left(x\right)$ (homogeneity)
\item $p\left(x+y\right)\le p\left(x\right)+p\left(y\right)$ (triangle
inequality)
\end{enumerate}
Let $l:Y\to\mathbb{C}$ be a linear functional with $\abs{l\left(y\right)}\le p\left(y\right)$
for all $y\in Y$.\\
Then $l$ can be extended to $X$ such that $\abs{l\left(x\right)}\le p\left(x\right)$
holds for all $x\in X$.


\subsubsection*{Proof}

We also consider $X$ as a real vector space. ($u$ and $\ii u$ are
then linearly independent vectors.) Decompose $l$ into its real and
imaginary parts.
\begin{align*}
l\left(y\right) & =l_{1}\left(y\right)+\ii l_{2}\left(y\right)\\
l_{1} & :=\text{Re}\left(l\left(y\right)\right)\\
l_{2} & :=\text{Im}\left(l\left(y\right)\right)
\end{align*}
$l_{1}$ and $l_{2}$ are real-linear and:
\begin{align*}
l_{1}\left(\ii y\right) & =\text{Re}\left(l\left(\ii y\right)\right)=\text{Re}\left(\ii l\left(y\right)\right)=-\text{Im}\left(l\left(y\right)\right)=-l_{2}\left(y\right)
\end{align*}
Conversely, suppose that $l_{1}$ is real-linear. Then
\begin{align*}
l\left(x\right) & :=l_{1}\left(x\right)-\ii\cdot l_{1}\left(\ii x\right)
\end{align*}
this is indeed a complex-linear function. We know that $\abs{l\left(y\right)}\le p\left(y\right)$
holds for all $y\in Y$.
\begin{align*}
l_{1}\left(y\right)=\text{Re}\left(l\left(y\right)\right) & \le\abs{l\left(y\right)}\\
\Rightarrow\qquad l_{1}\left(y\right) & \le p\left(y\right)
\end{align*}
Theorem \ref{sec:Thm-Hahn-Banach-real} yields an real-linear extension
$\tilde{l}_{1}:X\to\mathbb{R}$ such that $\tilde{l}_{1}\left(x\right)\le p\left(x\right)$
for all $x\in X$.\\
Set $\tilde{l}\left(x\right)=\tilde{l}_{1}\left(x\right)-\ii\,\tilde{l}_{1}\!\left(\ii x\right)$,
so that $\tilde{l}:X\to\mathbb{C}$ is complex-linear.
\begin{description}
\item [{Claim:}] $\abs{\tilde{l}\left(x\right)}\le p\left(x\right)$ $\fall_{x\in X}$
\item [{Proof:}] Polar decomposition:
\begin{align*}
\tilde{l}\left(x\right) & =re^{\ii\varphi}\\
\abs{\tilde{l}\left(x\right)} & =r=e^{-\ii\varphi}\tilde{l}\left(x\right)\sr ={\tilde{l}\text{ is}}{\text{complex-linear}}\tilde{l}\left(e^{-\ii\varphi}x\right)=\text{Re}\left(\tilde{l}\left(e^{-\ii\varphi}x\right)\right)=\\
 & =\tilde{l}_{1}\left(e^{-\ii\varphi}x\right)\le p\left(e^{-\ii\varphi}x\right)\stackrel{\text{homogeneity}}{=}p\left(x\right)
\end{align*}
\qqed[Claim]
\end{description}
\qqed

Now to applications:


\section{Theorem\label{sec:Thm-HahnBanach-normedSpace}}

Let $\left(X,\norm .\right)$ be a normed $\mathbb{K}$-space (real
or complex), $Y\subseteq X$ a subspace. Let $\varphi$ be a continuous
linear functional from $Y$ to $\mathbb{K}$, i.e. for all $y\in Y$
holds:
\begin{align*}
\abs{\varphi\left(y\right)} & \le\norm{\varphi}\cdot\norm y
\end{align*}
Then $\varphi$ can be continued to all of $X$ with the same supnorm,
i. e.:
\begin{align*}
\norm{\tilde{\varphi}} & :=\sup_{x\in X,\norm x\le1}\abs{\varphi\left(x\right)}=\norm{\varphi}:=\sup_{y\in Y,\norm y\le1}\abs{\varphi\left(y\right)}
\end{align*}



\subsubsection*{Proof}

Apply the Hahn-Banach theorem with $\tilde{\varphi}:=\norm{\varphi}\cdot\norm x$.\qqed


\section{Corollary}

Let $X$ be a normed space and $u_{0}\in X$ with $\norm{u_{0}}=1$.
Then there exists a linear functional $\varphi:X\to\mathbb{K}$ such
that:
\begin{align*}
\varphi\left(u_{0}\right) & =1 & \norm{\varphi} & =1
\end{align*}



\subsubsection*{Proof}

Let $Y:=\left\langle u_{0}\right\rangle $ and define $\varphi_{0}:\left\langle u_{0}\right\rangle \to\mathbb{K}$
by $\varphi_{0}\left(u_{0}\right)=1$. Extend $\varphi_{0}$ by the
Hahn-Banach theorem \ref{sec:Thm-HahnBanach-normedSpace}.\qqed

The Hahn-Banach theorem also has a geometric formulation. Consider
only the real case:\\
A set $K\subseteq X$ is called \emph{convex} if for all $x,y\in K$
and $\tau\in\left[0,1\right]$:
\begin{align*}
\tau x+\left(1-\tau\right)y & \in K
\end{align*}


\begin{figure}[H]
\hfill{}\subfloat[convex set]{\begin{tikzpicture}[scale=2]
  \draw plot[smooth cycle,tension=.7] coordinates{(0,-1) (0.8,-0.6) (1,0) (0.5,0.8) (-0.3,0.5) (-0.5,0)};
  \draw (0,-0.5) -- (0.5,0.5);
  \draw (0,-0.5) node[right]{$x$} +(-0.05,-0.05) -- +(0.05,0.05) +(0.05,-0.05) -- +(-0.05,0.05);
  \draw (0.5,0.5) node[right]{$y$} +(-0.05,-0.05) -- +(0.05,0.05) +(0.05,-0.05) -- +(-0.05,0.05);
\end{tikzpicture}}\hfill{}\subfloat[concave set]{\begin{tikzpicture}[scale=2]
  \draw plot[smooth cycle,tension=.7] coordinates{(0,-1) (0.5,-0.3) (1,0) (0.5,0.8) (0,1) (0.2,-0.2) (-1,0)};
  \draw (-0.4,-0.3) -- (0.4,0.6);
  \draw (-0.4,-0.3) node[right]{$x$} +(-0.05,-0.05) -- +(0.05,0.05) +(0.05,-0.05) -- +(-0.05,0.05);
  \draw (0.4,0.6) node[right]{$y$} +(-0.05,-0.05) -- +(0.05,0.05) +(0.05,-0.05) -- +(-0.05,0.05);
\end{tikzpicture}}\hfill{}\hspace*{1mm}\caption{convexity}


\end{figure}


Geometric question:

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[scale=2]
  \draw plot[smooth cycle,tension=.7] coordinates{(0,-1) (0.8,-0.6) (1,0) (0.5,0.8) (-0.3,0.5) (-0.5,0)};
  \draw (1.5,0.5) node[right]{$y$} +(-0.05,-0.05) -- +(0.05,0.05) +(0.05,-0.05) -- +(-0.05,0.05);
  \draw[thick,red] (1,1.5) -- (2,-0.5) node[right]{$\mathcal{H}$};
  \node at (0.9,-0.7) {$K$};
\end{tikzpicture}\caption{not intersecting hyperplane}
\end{figure}


Is there a hyperplane $\mathcal{H}$, which meets $y\not\in K$, but
does not intersect $K$?


\section{Definition \textmd{(interior point)}}

$x_{0}\in K$ is an \emph{interior point} (\foreignlanguage{ngerman}{innerer
Punkt}) \emph{of $K$ with respect to $u\in X$} if there exists an
$\varepsilon\in\mathbb{R}_{>0}$ such that $x_{0}+tu\in K$ for all
$t\in\left(-\varepsilon,\varepsilon\right)$.\\
$x_{0}\in K$ is an \emph{interior point} if for all $u\in X$ there
is a $\varepsilon=\varepsilon\left(u\right)\in\mathbb{R}_{>0}$ such
that $x_{0}+tu\in X$ for all $t\in\left(-\varepsilon,\varepsilon\right)$.


\section{Theorem \textmd{(geometric Hahn-Banach)}\label{sec:Thm-HahnBanach-Geometric}}

Let $K\not=\emptyset$ be convex and all points of $K$ be interior
points. Let $y\not\in K$. Then there is a linear functional $l:X\to\mathbb{R}$
such that $l\left(x\right)<1$ for all $x\in K$ and $l\left(y\right)=1$.\\
$\mathcal{H}:=\left\{ x\in X\big|l\left(x\right)=1\right\} $ defines
a hyperplane. Now $y\in\mathcal{H}$ and $l\big|_{K}<1$ mean that
$K$ lies in one half-space.

First introduce a suitable sublinear functional. Without loss of generality,
assume $0\in K$ (otherwise shift $K$).

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[scale=2]
  \draw plot[smooth cycle,tension=.7] coordinates{(0,-1) (0.8,-0.6) (1,0) (0.5,0.8) (-0.3,0.5) (-0.5,0)};
  \draw (0,0) node[below]{$0$} +(-0.05,-0.05) -- +(0.05,0.05) +(0.05,-0.05) -- +(-0.05,0.05);
\end{tikzpicture}\caption{$0\in K$}
\end{figure}


The functional $p:K\to\mathbb{R}_{\ge0}$ with
\begin{align*}
p\left(x\right) & :=\text{inf}\left\{ a\in\mathbb{R}_{>0}\bigg|\frac{x}{a}\in K\right\} 
\end{align*}
is called gauge (\foreignlanguage{ngerman}{Eichung}).\\
Since $x$ is an interior point, we know that $\frac{x}{a}\in K$
if $a>1-\varepsilon\left(x\right)$.\\
$p$ is even defined on all of $X$, because for $x\in X$, now $\tau x\in K$
if $\abs{\tau}$ is sufficiently small, because $0\in K$ is an interior
point.
\begin{align*}
p\left(x\right)<1 & \quad\Leftrightarrow\quad x\in K
\end{align*}


\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[scale=2]
  \draw plot[smooth cycle,tension=.7] coordinates{(0,-1) (0.8,-0.6) (1,0) (0.5,0.8) (-0.3,0.5) (-0.5,0)};
  \draw (0,0) node[below]{$0$} +(-0.05,-0.05) -- +(0.05,0.05) +(0.05,-0.05) -- +(-0.05,0.05);
  \draw (1.5,0.8) node[right]{$x$} +(-0.05,-0.05) -- +(0.05,0.05) +(0.05,-0.05) -- +(-0.05,0.05);
  \draw (0.5,0.2666) node[below right]{$\tau x$} +(-0.05,-0.05) -- +(0.05,0.05) +(0.05,-0.05) -- +(-0.05,0.05);
  \draw[dashed] (1.5,0.8) -- (-0.75,-0.4);
\end{tikzpicture}\caption{$x\not\in K,\ \tau x\in K$}
\end{figure}



\section{Lemma}

$p$ is sublinear.


\subsubsection*{Proof}

The homogeneity is clear from the definition.

sub-additivity (triangle equation):\\
Take $x,y\in K$ and choose $a,b\in\mathbb{R}_{>0}$ such that $\frac{x}{a},\frac{y}{b}\in K$.
The convexity of $K$ implies for all $\tau\in\left[0,1\right]$:
\begin{align*}
\tau\frac{x}{a}+\left(1-\tau\right)\frac{y}{b} & \in K
\end{align*}
Choose ${\displaystyle \tau=\frac{a}{a+b}}$, then holds ${\displaystyle 1-\tau=\frac{b}{a+b}}$,
which gives:
\begin{align*}
\Rightarrow\quad\frac{1}{a+b}\left(x+y\right) & \in K
\end{align*}
\begin{align*}
p\left(x+y\right) & \le a+b
\end{align*}
Taking the infimum over $a$ and $b$ gives $p\left(x+y\right)\le p\left(x\right)+p\left(y\right)$:
\begin{align*}
p\left(x+y\right) & =\inf\underbrace{\left\{ c\in\mathbb{R}_{>0}\bigg|\frac{x+y}{c}\in K\right\} }_{\ni a+b}\le a+b
\end{align*}
\begin{align*}
p\left(x\right) & =\inf\left\{ a\bigg|\frac{x}{a}\in K\right\} \quad\Rightarrow\quad\fall_{\varepsilon>0}\exs_{a\in\mathbb{R}_{>0}}:p\left(x\right)\ge a-\varepsilon\\
p\left(y\right) & =\inf\left\{ b\bigg|\frac{x}{b}\in K\right\} \quad\Rightarrow\quad\fall_{\varepsilon>0}\exs_{b\in\mathbb{R}_{>0}}:p\left(y\right)\ge b-\varepsilon
\end{align*}
\qqed


\section{Lemma}

$p\left(x\right)<1\Leftrightarrow x\in K$


\subsubsection*{Proof}

If $x\not\in K$ then $\frac{1}{a}x\not\in K$ for all $0<a<1$ and
so $p\left(x\right)\ge1$.

For all $x\in K$ exists an $\varepsilon=\varepsilon\left(x\right)\in\mathbb{R}_{>0}$
with $\left(1+t\right)x\in K$ for all $t\in\left(-\varepsilon,\varepsilon\right)$.
\begin{align*}
\Rightarrow\quad & \left(1+\frac{\varepsilon}{2}\right)x\in K\\
\Rightarrow\quad & p\left(x\right)\le\frac{1}{1+\frac{\varepsilon}{2}}<1
\end{align*}
\qqed


\subsubsection*{Proof of Theorem \ref{sec:Thm-HahnBanach-Geometric}}

Introduce $l$ on $\left\langle y\right\rangle $ by $l\left(y\right)=1$.
(Assume again that $0\in K$ and so $y\not=0$.)\\
Write $z=ay\in\left\langle y\right\rangle $ with $a\in\mathbb{R}$.
\begin{itemize}
\item If $a<0$, then $l\left(z\right)=a\cdot l\left(y\right)=a<0$ but
$p\left(z\right)\ge0$ and thus the inequality $l\left(z\right)\le p\left(z\right)$
is trivially satisfied.
\item If $a>0$ it holds:
\begin{align*}
l\left(z\right) & =a\sr{\le}{y\not\in K}{\Rightarrow p\left(y\right)\ge1}a\cdot p\left(y\right)\sr ={\text{positive}}{\text{homogeneity}}p\left(ay\right)=p\left(z\right)
\end{align*}

\end{itemize}
So for all $z\in\left\langle y\right\rangle $ holds $l\left(z\right)\le p\left(z\right)$.\\
The Hahn-Banach Theorem yields an extension $l:X\to\mathbb{R}$ such
that $l\left(x\right)\le p\left(x\right)$ for all $x\in X$. Therefore
for all $x\in K$ we have:
\begin{align*}
l\left(x\right) & \le p\left(x\right)<1
\end{align*}
\qqed[\ref{sec:Thm-HahnBanach-Geometric}]

%DATE: Do 25.10.12


\chapter{Normed Spaces}

Let $\left(E,\norm .\right)$ be a normed space and let the open balls
$B_{\varepsilon}\left(x\right)=\left\{ y\big|\norm{x-y}<\varepsilon\right\} $
generate the topology on $E$.


\subsection{Definition \textmd{(equivalent norms)}}

Two norms $\norm ._{1}$ and $\norm ._{2}$ are \emph{equivalent},
if there exists a $C\in\mathbb{R}_{>0}$ such that:
\begin{align*}
\frac{1}{C}\norm x_{1} & \le\norm x_{2}\le C\norm x_{2}
\end{align*}



\subsection{Theorem}

Equivalent norms give rise to the same topology.


\subsubsection*{(No proof)}


\subsection{Theorem}

If $E$ is finite dimensional, then any two norms on $E$ are equivalent.


\subsubsection*{(No proof)}


\subsection{Constructions \textmd{(Quotient space, Cartesian product)}}

Let $F\subseteq E$ be a \emph{closed} subspace. Define the \emph{quotient
space }\foreignlanguage{ngerman}{(Faktorraum}) $\modulo EF$ as follows:
\begin{align*}
x\sim y & :\Leftrightarrow x-y\in F
\end{align*}
defines an equivalence relation on $E$.
\begin{align*}
\modulo EF & :=\modulo E{\sim}
\end{align*}
is a vector space.
\begin{align*}
\norm u_{\moduloScript EF} & :=\inf_{\sr{}{\hat{u}\in E}{\hat{u}-u\in F}}\norm{\hat{u}}_{E}
\end{align*}
$\left(\modulo EF,\norm ._{\moduloScript EF}\right)$ is a normed
space. The closedness of $F$ is essential:\\
Suppose $F\subseteq E$ is not closed. Then there exists an $x\in\overline{F}\setminus F$,
thus there is a $\left(x_{n}\right)_{n\in\mathbb{N}}$, $x_{n}\in F$
with $x_{n}\to x$.\\
Let $\left[x\right]\in\modulo EF$ be the equivalence class. Then
$\left[x\right]\not=0$, since $x\not\in F$, but:
\begin{align*}
\norm{\left[x\right]} & =\inf_{\sr{}{\hat{x}\in E}{\hat{x}-x\in F}}\norm{\hat{x}}\stackrel{x-x_{n}\sim x}{\le}\inf\norm{x-x_{n}}=0
\end{align*}
If $\norm ._{\moduloScript EF}$ was a norm, it would imply $\left[x\right]=0$
and thus $x\in F$ in contradiction to $x\in\overline{F}\setminus F$.

Another construction is the \emph{Cartesian product}: Let $E$ and
$F$ be normed spaces.
\begin{align*}
E\times F & :=\left\{ \left(u,v\right)\Big|u\in E,v\in F\right\} 
\end{align*}
\begin{align*}
\norm{\left(u,v\right)}_{E\times F} & :=\norm u_{E}+\norm v_{F}
\end{align*}
is a norm on $E\times F$.


\subsection{Definition \textmd{(separable)}}

A normed space is called \emph{separable}, if there is a countable
dense subset, i.e. there exists a sequence $\left(x_{n}\right)_{n\in\mathbb{N}}$
such that every nonempty open subset of the space contains at least
one element of the sequence.


\subsection{Examples}

The space $\ell^{\infty}$ of bounded sequences $\left(a_{n}\right)_{n\in\mathbb{N}}$,
$a_{n}\in\mathbb{K}$ with $\norm{\left(a_{n}\right)_{n\in\mathbb{N}}}_{\infty}:=\sup_{n}\abs{a_{n}}$
is a Banach space.
\begin{align*}
A & :=\left\{ \left(a_{n}\right)_{n\in\mathbb{N}}\bigg|a_{2n}=0\fall_{n\in\mathbb{N}}\right\} \subseteq\ell^{\infty}
\end{align*}
is a closed subspace.
\begin{align*}
\modulo{\ell^{\infty}}A & \stackrel{\sim}{=}\left\{ \left(a_{n}\right)\bigg|a_{2n+1}=0\fall_{n\in\mathbb{N}}\right\} 
\end{align*}
\begin{align*}
d & :=\left\{ \left(a_{n}\right)\bigg|\exs_{N\in\mathbb{N}}\fall_{n\in\mathbb{N}_{>N}}a_{n}=0\right\} \subseteq\ell^{\infty}
\end{align*}
is a subspace, but not closed in $\ell^{\infty}$. Consider for example
$\left(a_{n}=\frac{1}{n}\right)=:x\in\ell^{\infty}\setminus d$, $x_{n}\in d$
with $x_{n}=\left(a_{n_{l}}\right)_{l\in\mathbb{N}}$ and:
\begin{align*}
a_{n_{l}} & =\begin{cases}
\frac{1}{l} & \text{if }l\le n\\
0 & \text{if }l>n
\end{cases}
\end{align*}
Then converges $x_{n}\to x\not\in d$, and therefore $d$ is not closed.
The closure is:
\begin{align*}
\overline{d} & =\left\{ \left(a_{n}\right)\big|a\xrightarrow{n\to\infty}0\right\} 
\end{align*}
$\ell^{\infty}$ is not separable.


\subsection{Example}

For $1\le p<\infty$ define
\begin{align*}
\ell^{p} & =\left\{ \left(a_{n}\right)_{n\in\mathbb{N}}\bigg|\sum_{n=1}^{\infty}\abs{a_{n}}^{p}<\infty\right\} 
\end{align*}
and the $\ell^{p}$-norm:
\begin{align*}
\norm{\left(a_{n}\right)}_{p} & :=\left(\sum_{n=1}^{\infty}\abs{a_{n}}^{p}\right)^{\frac{1}{p}}
\end{align*}
$\ell^{p}$ is a normed space (Hölder's inequality, Minkowski inequality)
and also separable (see exercises).


\subsection{Example}

Let $\left(\Omega,\mu\right)$ be a measure space (\foreignlanguage{ngerman}{Maßraum}).
\begin{align*}
L^{p}\left(\Omega\right) & \ \left(1\le p<\infty\right) & \norm f_{p} & =\left(\int_{\Omega}\abs{f\left(x\right)}^{p}\dd\mu\right)^{\frac{1}{p}}\\
L^{\infty}\left(\Omega\right) &  & \norm f_{\infty} & =\text{supess}_{\Omega}\abs{f\left(x\right)}=\sup\left\{ L\in\mathbb{R}\big|\mu\left(f^{-1}\left([L,\infty)\right)\right)>0\right\} 
\end{align*}



\section{Non-Compactness of the Unit Ball}

Let $\left(E,\norm .\right)$ be a normed vector space.
\begin{align*}
K & :=\overline{B_{1}\left(0\right)}=\left\{ x\in E\big|\norm x\le1\right\} 
\end{align*}
If $\dim\left(E\right)<\infty$, $K$ is compact by the Heine-Borel
theorem.


\subsection{Theorem\label{sub:Thm-NonCompactUnitBall}}

If $E$ is infinite-dimensional, then $K$ is not sequentially compact
(\foreignlanguage{ngerman}{folgenkompakt}), i.e. it is possible to
construct a sequence $\left(y_{n}\right)$, $y_{n}\in K$, which has
no convergent subsequence.


\subsection{Lemma\label{sub:Lem-d>0.5}}

Let $Y\subsetneq E$ be a proper (\foreignlanguage{ngerman}{echter})
closed subspace. Then there is a $z\in E\setminus Y$ with $\norm z=1$
such that holds:
\begin{align*}
\fall_{y\in Y}:\ \norm{z-y} & >\frac{1}{2}\\
\Leftrightarrow\quad\overline{B_{\frac{1}{2}}\left(z\right)}\cap Y & =\emptyset
\end{align*}


\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[scale=2]
  \draw (0,0) node[above]{$0$} +(-0.05,-0.05) -- +(0.05,0.05) +(0.05,-0.05) -- +(-0.05,0.05);
  \draw (0.542,-0.84) node[right]{$z$} circle (0.5) node[below=30]{$\overline{B}_{\frac{1}{2}}(z)$} +(-0.05,-0.05) -- +(0.05,0.05) +(0.05,-0.05) -- +(-0.05,0.05);
  \draw  (-1,0.3) -- (3,-0.9) node[above]{$Y$};
  \draw[dotted]  (0,0) -- (0.542,-0.84);
  \draw[dashed]  (0.542,-0.84) -- node[below]{$\frac{1}{2}$} (0.042,-0.84);
  \draw (2.5,-1) node[right]{$x$} +(-0.05,-0.05) -- +(0.05,0.05) +(0.05,-0.05) -- +(-0.05,0.05);
  \draw (0.2,-0.31) node[left]{$z'$} +(-0.05,-0.05) -- +(0.05,0.05) +(0.05,-0.05) -- +(-0.05,0.05);
\end{tikzpicture}\caption{$\overline{B_{\frac{1}{2}}\left(z\right)}\cap Y=\emptyset$}
\end{figure}



\subsubsection*{Proof}

Choose $x\in E\setminus Y\not=\emptyset$. As $E\setminus Y$ is open,
there is a $\delta\in\mathbb{R}_{>0}$ with $B_{\delta}\left(x\right)\cap Y=\emptyset$.
Thus we can define:
\begin{align*}
d:=\inf_{y\in Y}\norm{x-y} & >0
\end{align*}
Choose $y_{0}\in Y$ such that $\norm{x-y_{0}}<2d$. Set $z'=x-y_{0}$.
Then $\norm{z'}<2d$ and $\norm{z'-y}\ge d$ for all $y\in Y$. Thus
$z:=\frac{z'}{\norm{z'}}$ has the desired properties. \qqed


\subsubsection*{Proof of Theorem \ref{sub:Thm-NonCompactUnitBall}}

Choose inductively a sequence $\left(y_{n}\right)$: $y_{1}\in K$
is arbitrary. $Y_{1}:=\left\langle y_{1}\right\rangle $ is a one
dimensional subspace, which is closed. Choose $y_{2}\in K$ such that
$\norm{y_{2}-y}>\frac{1}{2}$ for all $y\in Y_{1}$, which is possible
according to Lemma \ref{sub:Lem-d>0.5}.\\
Suppose $y_{1},\ldots,y_{n}$ are given. $Y_{n}:=\left\langle y_{1},\ldots,y_{n}\right\rangle $
is closed. So there exists a $y_{n+1}\in K$ such that for all $y\in Y_{n}$
holds:
\begin{align*}
\norm{y_{n+1}-y} & >\frac{1}{2}
\end{align*}
This sequence has the following properties:
\begin{itemize}
\item $y_{k}\in K$
\item For all $k,l\in\mathbb{N}$ with $k<l$ holds $\norm{y_{l}-y_{k}}>\frac{1}{2}$,
since $y_{k}\in Y_{l-1}=\left\langle y_{1},\ldots,y_{l-1}\right\rangle $
and we know by construction that $\norm{y_{l}-y}>\frac{1}{2}$ for
all $y\in Y_{l-1}$ so especially for $y_{k}\in Y_{l-1}$.
\end{itemize}
This implies that $\left(y_{k}\right)$ has no convergent subspace.
\qqed[\ref{sub:Thm-NonCompactUnitBall}]


\section{Spaces of linear Mappings, Dual Spaces}

Let $E,F$ be normed spaces.\\
$A:E\to F$ is continuous if and only if it is bounded, i.e. there
exists a $C\in\mathbb{R}_{>0}$ such that for all $u\in E$ holds:
\begin{align*}
\norm{Au}_{F} & \le C\norm u_{E}
\end{align*}
Denote by $L\left(E,F\right)$ the normed space of all bounded linear
maps from $E$ to $F$ and define:
\begin{align*}
\norm A & :=\sup_{\norm u\le1}\norm{Au}=\sup_{\norm u=1}\norm{Au}
\end{align*}



\subsection{Lemma}

If $B\in L\left(E,F\right)$ and $A\in L\left(F,G\right)$ then Schwarz
inequality or Kato inequality holds:
\begin{align*}
\norm{A\cdot B} & \le\norm A\cdot\norm B\\
\norm{Au} & \le\norm A\cdot\norm u
\end{align*}



\subsubsection*{(no proof)}


\subsection{Theorem and Definition \textmd{(dual pairing)\label{sub:TuD-dual-pairing}}}

If $F$ is complete, so is $L\left(E,F\right)$.\\
Special case $F=\mathbb{R}$ and $\norm x_{\mathbb{R}}=\abs x$: $E^{*}:=L\left(E,\,\mathbb{R}\right)$
is the dual space.

For $\varphi\in E^{*}$ and $u\in E$
\begin{align*}
\varphi\left(u\right) & =\left(\varphi,u\right)
\end{align*}
is called \emph{dual pairing} (\foreignlanguage{ngerman}{duale Paarung}).
\begin{align*}
\left(.,.\right):E^{*}\times E & \to\mathbb{R}
\end{align*}
is a continuous bilinear map. For $u\in E$ 
\begin{align*}
\left(.,u\right):E^{*} & \to\mathbb{R}
\end{align*}
defines an element of $E^{**}=L\left(E^{*},\mathbb{R}\right)$. This
gives rise to a linear mapping:
\begin{align*}
\iota:E & \to E^{**}
\end{align*}



\subsubsection*{(no proof)}


\subsection{Theorem}

$\iota:E\hookrightarrow E^{**}$ is an isometric embedding of $E$
into $E^{**}$.


\subsubsection*{Proof}

For $u\in E$ holds:
\begin{align*}
\norm{\iota\left(u\right)} & :=\sup_{\varphi\in E^{*},\norm{\varphi}=1}\norm{\left(\iota\left(u\right)\right)\left(\varphi\right)}=\sup_{\varphi\in E^{*},\norm{\varphi}=1}\norm{\varphi\left(u\right)}\stackrel{?}{=}\norm u
\end{align*}
\begin{align*}
\norm{\varphi} & =\sup_{v\in E,\norm v=1}\abs{\varphi\left(v\right)}
\end{align*}
\begin{align*}
\norm{\varphi\left(u\right)} & \le\norm{\varphi}\cdot\norm u\stackrel{\norm{\varphi}=1}{=}\norm u\\
\Rightarrow\quad\sup_{\varphi\in E^{*},\norm{\varphi}=1}\norm{\varphi\left(u\right)} & \le\norm u
\end{align*}
To prove $\norm{\iota\left(u\right)}\ge\norm u$ apply the Hahn-Banach
theorem:\\
Let $l:\left\langle u\right\rangle \to\mathbb{R}$ be the linear map
with $l\left(u\right)=\norm u$, thus:
\begin{align*}
\norm l & =\sup_{v\in\left\langle u\right\rangle ,\norm v=1}\left(l\left(v\right)\right)=\sup\left(l\left(\pm\frac{u}{\norm u}\right)\right)=1
\end{align*}
By the Hahn-Banach theorem we can extend $l$ to
\begin{align*}
\tilde{l}:E & \to\mathbb{R}
\end{align*}
with $\norm{\tilde{l}}=1$ and then holds:
\begin{align*}
\sup_{\varphi\in E^{*},\norm{\varphi}=1}\varphi\left(u\right) & \stackrel{\norm{\tilde{l}}=1}{\ge}\tilde{l}\left(u\right)=\norm u
\end{align*}
Therefore $\iota$ is injective, because from $\iota\left(u\right)=0$
follows $\norm u_{E}=\norm{\iota\left(u\right)}=0$ and therefore
$u=0$.\qqed


\subsection{Definition \textmd{(reflexive)}}

A Banach space is called \emph{reflexive} (\foreignlanguage{ngerman}{reflexiv})
if $\iota$ is bijective, i.e. $E\stackrel{\sim}{=}E^{**}$.


\subsection{Example}

Let $\ell_{1}$ be the space of absolutely convergent functions with
the norm:
\begin{align*}
\norm{\left(a_{n}\right)}_{1} & =\sum_{n=1}^{\infty}\abs{a_{n}}<\infty
\end{align*}
Let $\left(\lambda_{n}\right)\in\ell_{\infty}$ be a bounded sequence
and define $\Lambda\in\ell_{1}^{*}$:
\begin{align*}
\Lambda:\ell_{1} & \to\mathbb{R}\\
\Lambda\left(\left(a_{n}\right)\right) & =\sum_{n=1}^{\infty}\lambda_{n}a_{n}
\end{align*}
\begin{align*}
\abs{\Lambda\left(\left(a_{n}\right)\right)} & =\abs{\sum_{n=1}^{\infty}\lambda_{n}a_{n}}\le\sum_{n=1}^{\infty}\abs{\lambda_{n}}\cdot\abs{a_{n}}\le\norm{\left(\lambda_{n}\right)}_{\infty}\sum_{n=1}^{\infty}\abs{a_{n}}=\norm{\left(\lambda_{n}\right)}_{\infty}\cdot\norm{\left(a_{n}\right)}_{1}<\infty
\end{align*}
Thus $\Lambda$ is bounded and:
\begin{align*}
\norm{\Lambda} & =\sup_{n\in\mathbb{N}}\abs{\lambda_{n}}
\end{align*}
%DATE: Fr 26.10.12
\begin{description}
\item [{Claim:}] Every bounded linear functional on $\ell_{1}$ is of this
form, i.e. $\ell_{1}^{*}=\ell_{\infty}$.
\item [{Proof:}] Let $\Lambda\in\ell_{1}^{*}$. Choose $u_{l}\in\ell_{1}$
by $u_{l}=\left(0,\ldots,0,1,0,\ldots\right)$ with a one at the $l$-th
position. Setting $\lambda_{l}:=\Lambda\left(u_{l}\right)$ gives:
\begin{align*}
\abs{\lambda_{l}} & =\abs{\Lambda\left(u_{l}\right)}\le\underbrace{\norm{\Lambda}}_{<\infty}\cdot\underbrace{\norm{u_{l}}}_{=1}\le\norm{\Lambda}<\infty
\end{align*}
So $\left(\lambda_{l}\right)\in\ell_{\infty}$.\\
Let $\left(a_{k}\right)$ be a finite sequence, with only zeros for
$k>K\in\mathbb{N}$. Then:
\begin{align*}
\Lambda\left(\left(a_{k}\right)\right) & =\Lambda\left(\sum_{k=1}^{K}a_{k}u_{k}\right)=\sum a_{k}\Lambda\left(u_{k}\right)=\sum\lambda_{k}a_{k}
\end{align*}
Since the finite sequences are dense in $\ell_{1}$, the claim follows.
\qqed[Claim]
\end{description}
So $\ell_{1}^{*}=\ell_{\infty}$ and one could assume $\ell_{\infty}^{*}=\ell_{1}$,
but this is not the case (see exercises).

Thus $\ell_{1}^{**}\not=\ell_{1}$, which means, that $\ell_{1}$
is \emph{not} reflexive.


\section{Weak Convergence \textmd{(Schwache Konvergenz)}}

Let $E$ be a Banach space and $\left(u_{n}\right)$ a sequence in
$E$.

Normal convergence: $u_{n}\to u$ if and only if $\norm{u-u_{n}}\xrightarrow{n\to\infty}0$.


\subsection{Definition \textmd{(weak convergence, weak Cauchy sequence)}}

A sequence $\left(u_{n}\right)$ in $E$ \emph{converges weakly} to
$u$, written as $u_{n}\rightharpoondown u$, if for all $\varphi\in E^{*}$
the sequence $\varphi\left(u_{n}\right)$ converges to $\varphi\left(u\right)$,
i.e. $\varphi\left(u_{n}\right)\to\varphi\left(u\right)$.

$\left(u_{n}\right)$ is a \emph{weak Cauchy sequence} if for all
$\varphi\in E^{*}$ the sequence $\varphi\left(u_{n}\right)$ is a
Cauchy sequence.


\subsection{Theorem \textmd{(Uniqueness of weak limit)}}

The weak limit is unique.


\subsubsection*{Proof}

Let $\left(u_{n}\right)$ be a sequence in $E$, which converges weakly
to $u$ and $u'$, i.e. for all $\varphi\in E^{*}$ holds:
\begin{align*}
\varphi\left(u_{n}\right) & \to\varphi\left(u\right) & \varphi\left(u_{n}\right) & \to\varphi\left(u'\right)
\end{align*}
\begin{align*}
\Rightarrow\quad0=\varphi\left(u_{n}-u_{n}\right) & \to\varphi\left(u-u'\right)
\end{align*}
So $\varphi\left(u-u'\right)=0$ for all $\varphi\in E^{*}$.
\begin{description}
\item [{Claim:}] $v:=u-u'=0$
\item [{Proof:}] Assume to the contrary that $v\not=0$.\\
Choose $\varphi:\left\langle v\right\rangle \to\mathbb{R}$ with $\varphi\left(v\right)=1$.
By the Hahn-Banach theorem $\varphi$ can be extended continuously
to $E$.\\
Therefore exists a $\varphi\in E^{*}$ with $\varphi\left(v\right)=1$,
which is a contradiction to $\varphi\left(v\right)=0$.\qqed[Claim]
\end{description}
\qqed


\subsection{Theorem \textmd{(convergence implies weak convergence)}}

Every convergent sequence converges weakly.


\subsubsection{Proof}

Suppose that $u_{n}\to u$. For $\varphi\in E^{*}$ follows:
\begin{align*}
\abs{\varphi\left(u_{n}\right)-\varphi\left(u\right)} & =\abs{\varphi\left(u_{n}-u\right)}\le\underbrace{\norm{\varphi}}_{\in\mathbb{R}}\cdot\norm{u_{n}-u}\to0
\end{align*}
\begin{align*}
\Rightarrow\quad\varphi\left(u_{n}\right) & \to\varphi\left(u\right)\\
\Rightarrow\quad u_{n} & \rightharpoondown u
\end{align*}
\qqed


\subsection{Example}

$E=\left\{ \left(a_{n}\right)\bigg|a_{n}\xrightarrow{n\to\infty}0\right\} \subsetneq\ell_{\infty}$
with $\norm{\left(a_{n}\right)}=\sup_{n}\abs{a_{n}}$ is a Banach
space.\\
Let $u_{n}=\left(0,\ldots,0,1,0,\ldots\right)$ be the sequence with
a one at the $n$-th position and zeros elsewhere. For $n\not=m$
we have:
\begin{align*}
\norm{u_{n}-u_{m}} & =\sup\left\{ 0,\abs 1,\abs{-1}\right\} =1
\end{align*}
Thus $\left(u_{n}\right)$ is \emph{not} a Cauchy sequence. Every
$\varphi\in E^{*}$ can be represented with $\left(\lambda_{k}\right)\in\ell_{1}$
as (see exercises):
\begin{align*}
\varphi\left(\left(a_{n}\right)\right) & =\sum_{k}\lambda_{k}a_{k}\\
\norm{\varphi} & =\sum_{k=1}^{\infty}\abs{\lambda_{k}}<\infty
\end{align*}
\begin{align*}
\varphi\left(u_{n}\right) & =\sum_{k=1}^{\infty}\lambda_{k}\delta_{kn}=\lambda_{n}\xrightarrow{n\to\infty}0
\end{align*}
From $\left(\lambda_{n}\right)\in\ell_{1}$ follows $\lambda_{n}\to0$.
This means that $u_{k}\rightharpoondown0$.\\
This is used in the lectures on partial differential equations.\\
From $\mathscr{S}\left(u_{n}\right)\to\inf\mathscr{S}$ follows not
necessarily $u_{n}\to u$, but $u_{n}\rightharpoondown u$.

Consider $A_{n}\in L\left(E,F\right)$.
\begin{itemize}
\item \emph{norm convergence}: $A_{n}\to A$ in $L\left(E,F\right)$ means
$\norm{A_{n}-A}\to0$.
\item \emph{strong convergence}: $A_{n}u\to Au$ in $F$ for all $u\in E$.
\item \emph{weak convergence}: $A_{n}u\rightharpoondown Au$ for all $u\in E$,
i.e. for all $\varphi\in F^{*}$ holds $\varphi\left(A_{n}u\right)\to\varphi\left(Au\right)$.
\end{itemize}

\section{The Baire Category Theorem}

Let $E$ be a metric space (e.g. a normed space).


\subsection{Definition \textmd{(nowhere dense, set of first/second category)}}

A subset $A\subseteq E$ is called \emph{nowhere dense} (\foreignlanguage{ngerman}{nirgends
dicht}) if $\overline{A}^{\circ}=\emptyset$.\\
$A$ is called \emph{of first category} (or \emph{meager}) if it can
be written as a countable union of nowhere dense sets. Otherwise it
is \emph{of second category}.


\subsubsection*{Example}
\begin{itemize}
\item $\mathbb{N}\subseteq\mathbb{R}$ is nowhere dense: $\overline{\mathbb{N}}=\mathbb{N}$,
$\mathbb{N}^{\circ}\:=\emptyset$
\item $\mathbb{Q}\subseteq\mathbb{R}$ is dense: $\overline{\mathbb{Q}}=\mathbb{R}$,
$\overline{\mathbb{Q}}^{\circ}=\mathbb{R}^{\circ}=\mathbb{R}$
\end{itemize}

\subsection{Theorem \textmd{(René Baire, 1899)\label{sub:Thm-Baire}}}

Let $E\not=\emptyset$ be a complete metric space (Polish space).
Then $E$ is of second category.


\subsubsection*{Proof}

\begin{figure}[h]
\noindent \centering{}\begin{tikzpicture}
  % n=1
  \draw (0,0) circle (4);
  \node at (3.1,3.1) {$\overline{B_1}$};
  \draw (-4, -5) -- (7,-3) node[right]{$M_1$};
  \draw (2.5,-1) node[right]{$x_1$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  % n=2
  \draw (1,1) circle (2);
  \draw (1,1)  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw[dotted] (1,1) -- node[above]{$r_2$} (-1,1);
  \node at (2,3) {$\overline{B_2}$};
  \draw (-4, -2) -- (7,-2) node[right]{$M_2$};
  \draw (1.7,1.3) node[right]{$x_2$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  % n --> Infinity
  \draw[red] (0.7,1.8) node[right]{$x_0$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (0.9,1.9) circle (0.5) node[above right=6] {$\overline{B_3}$};
\end{tikzpicture}\caption{$B_{n}\cap M_{n}=\emptyset$}
\end{figure}


Assume in contrast that $E=\bigcup_{n\in\mathbb{N}}M_{n}$ and the
sets $M_{n}$ are nowhere dense. Without loss of generality assume
that the $M_{n}$ are closed, since otherwise one can replace $M_{n}$
by $\overline{M_{n}}$.\\
We shall construct inductively balls $\overline{B_{n}}=\overline{B_{r_{n}}\left(x_{n}\right)}$
such that $\overline{B_{n+1}}\subseteq\overline{B_{n}}$, $r_{n}<2^{-n}$
and $\overline{B_{n}}\cap M_{n}=\emptyset$ for all $n$.

Then the points $x_{n}$ form a Cauchy sequence, because for all $n<m\in\mathbb{N}$
we have $x_{n+1}\in B_{n}$ and so $\norm{x_{n}-x_{n+1}}<r_{n}<2^{-n}$:
\begin{align*}
\norm{x_{n}-x_{m}} & \le\norm{x_{n}-x_{n+1}}+\norm{x_{n+1}-x_{m}}\le\ldots\le\\
 & \le2^{-n}+2^{-\left(n+1\right)}+\ldots+2^{-\left(m-1\right)}\le2^{-n}\left(1+\frac{1}{2}+\frac{1}{4}+\ldots\right)\le2\cdot2^{-n}
\end{align*}
Since $E$ is complete, $x_{n}\to x_{0}\in E$ converges. Then $x_{0}\in\overline{B_{n}}$
for all $n$, which implies $x_{0}\not\in M_{n}$ and thus the contradiction
$x_{0}\not\in\bigcup_{n}M_{n}=E$ follows.

Construction of the balls $\overline{B_{n}}$:\\
$M_{1}$ is nowhere dense and therefore $B_{1}\left(0\right)\not\subseteq M_{1}$.
So there exists a $x_{1}\in B_{1}\left(0\right)\setminus M_{1}$.
Since $M_{1}$ is closed, $B_{1}\left(0\right)\setminus M_{1}$ is
open and therefore there exists a radius $r_{1}$ such that $B_{2r_{1}}\left(x_{1}\right)$
is contained in $B_{1}\left(0\right)\setminus M_{1}$ and thus $\overline{B_{r_{1}}\left(x_{1}\right)}\cap M_{1}=\emptyset$.

Suppose $\overline{B_{n}}$ has been constructed. $M_{n+1}$ is nowhere
dense and closed and so there exists a $x_{n+1}\in\overline{B_{n}}\setminus M_{n+1}$
and $r_{n+1}<2^{-\left(n+1\right)}$ such that $B_{2r_{n+1}}\left(x_{n+1}\right)\subseteq\overline{B_{n}}\setminus M_{n+1}$.
Then follows $\overline{B_{r_{n+1}}\left(x_{n+1}\right)}\cap M_{n+1}=\emptyset$.\qqed


\subsection{Theorem \textmd{(Uniform boundedness principle, }\foreignlanguage{ngerman}{\textmd{Prinzip
der gleichmäßigen Beschränktheit}}\textmd{)\label{sub:Thm-Uniform-boundedness}}}

Let $E$ be a Banach space and $F$ a normed space. Let $T_{i}$ be
a sequence in $L\left(E,F\right)$ which is point-wise bounded, i.e.
for all $u\in E$:
\begin{align*}
\sup_{i}\norm{T_{i}u} & \le C\left(u\right)<\infty
\end{align*}
Then sup-norms of $T_{i}$ are bounded:
\begin{align*}
\sup_{i}\norm{T_{i}} & =\sup_{i}\sup_{\norm u=1}\norm{T_{i}u}\le\tilde{C}<\infty
\end{align*}
(Thus there exists a constant $C\in\mathbb{R}_{>0}$ such that $\norm{T_{i}u}\le C$
for all $i\in\mathbb{N}$ and for all $u\in E$ with $\norm u=1$.)


\subsubsection*{Proof}

The sets $M_{n}=\left\{ u\in E\big|\sup_{i}\norm{T_{i}u}\le n\right\} $
are closed by continuity of the $T_{i}\in L\left(E,F\right)$, i.e.
for $u_{k}\to u$ converges $\norm{T_{i}u_{k}}\xrightarrow{k\to\infty}\norm{T_{i}u}$.\\
$E=\bigcup_{n}M_{n}$, because for any $u\in E$, $\sup_{i}\norm{T_{i}u}<\infty$
and thus $u\in M_{n}$ for $n>\sup_{i}\norm{T_{i}u}$.\\
If all the sets $M_{n}$ had empty interior, we would get a contradiction
to Baire's theorem.\\
So there exists an $n_{0}\in\mathbb{N}$ such that $\stackrel{\circ}{M_{n_{0}}}\not=\emptyset$
and thus there are $u_{0}\in E$ and $r\in\mathbb{R}_{>0}$ such that
$B_{r}\left(u_{0}\right)\subseteq M_{n_{0}}$.

\begin{figure}[h]
\noindent \centering{}\begin{tikzpicture}[scale=0.5]
  \draw (0,0) circle (2);
  \draw (0,0) node[right]{$u_0$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw[dotted] (0,0) -- node[above right]{$r$} (-1.41,1.41);
  \draw (0.5,-1) node[right]{$v$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (-5,-4) -- (4,-4) node[below right]{$M_{n_0}\subseteq E$} -- (5,4) -- (-4,4) -- cycle;
\end{tikzpicture}\caption{$B_{r}\left(u_{0}\right)\subseteq M_{n_{0}}$}
\end{figure}


For all $v\in B_{r}\left(u_{0}\right)$ we know that $\sup_{i}\norm{T_{i}v}\le n_{0}$
which is equivalent to:
\begin{align*}
\sup_{v\in B_{r}\left(u_{0}\right)}\norm{T_{i}v} & \le n_{0}\qquad\fall_{i\in\mathbb{N}}
\end{align*}
Let $w\in B_{r}\left(0\right)$ be arbitrary. Then $v:=u_{0}+w\in B_{r}\left(u_{0}\right)$.
\begin{align*}
T_{i}w & \stackrel{T_{i}\text{ linear}}{=}T_{i}v-T_{i}u_{0}
\end{align*}
\begin{align*}
\norm{T_{i}w} & \le\norm{T_{i}v}+\norm{T_{i}u_{0}}\le n_{0}+\sup_{i}\norm{T_{i}u_{0}}<\infty
\end{align*}
Here $\sup_{i}\norm{T_{i}u_{0}}<\infty$, because the $T_{i}$ are
point-wise bounded.
\begin{align*}
\Rightarrow\quad\norm{T_{i}w} & \le C\qquad\fall_{w\in B_{r}\left(0\right)}\\
\Rightarrow\quad\norm{T_{i}\tilde{w}} & \le\tilde{C}=\frac{C}{r}\qquad\fall_{\tilde{w}\in\overline{B_{1}\left(0\right)}}
\end{align*}
So $\norm{T_{i}}\le\tilde{C}$ for all $i\in\mathbb{N}$ and so $\norm{T_{i}}$
is bounded.\qqed


\subsection{Corollary}

Let $E$ be a normed space, not necessarily complete, and $\left(u_{n}\right)$
a weak Cauchy sequence. Then $\norm{u_{n}}$ is a bounded sequence.


\subsubsection*{Proof}

$E^{*}=L\left(E,\mathbb{R}\right)$ is a Banach space after theorem
\ref{sub:TuD-dual-pairing}, since $\mathbb{R}$ is complete. Now
we can view every $u_{n}$ as operator:
\begin{align*}
u_{n}:E^{*} & \to\mathbb{R}\\
\varphi & \mapsto\varphi\left(u_{n}\right)
\end{align*}
So $\left(u_{n}\right)$ is a sequence in $L\left(E^{*},\mathbb{R}\right)$.
For all $\varphi\in E^{*}$ we know that $\varphi\left(u_{n}\right)$
is a Cauchy sequence and thus bounded:
\begin{align*}
\Rightarrow\quad\abs{\varphi\left(u_{n}\right)} & <C\left(\varphi\right)
\end{align*}
Applying theorem \ref{sub:Thm-Uniform-boundedness} yields:
\begin{align*}
\abs{\varphi\left(u_{n}\right)} & <C\quad\fall_{\varphi\text{ with }\norm{\varphi}=1}\\
\Leftrightarrow\quad\sup_{n\in\mathbb{N}}\ \sup_{\varphi\in E^{*},\norm{\varphi}=1}\abs{\varphi\left(u_{n}\right)} & <C
\end{align*}
For any $v\in E$ we have
\begin{align*}
\sup_{\varphi\in E^{*},\norm{\varphi}=1}\abs{\varphi\left(v\right)} & =\norm v
\end{align*}
by the Hahn-Banach theorem:
\begin{itemize}
\item $\abs{\varphi\left(v\right)}\le\norm{\varphi}\cdot\norm v\stackrel{\norm{\varphi}=1}{=}\norm v$
\item Choose $\varphi:\left\langle v\right\rangle \to\mathbb{R}$ with $\varphi\left(v\right)=\norm v$
and so $\norm{\varphi}=1$. By the Hahn-Banach theorem we can extend
$\varphi$ to $\tilde{\varphi}:E\to\mathbb{R}$ such that $\norm{\tilde{\varphi}}=1$.
Then $\tilde{\varphi}\left(v\right)=\norm v$ and so $\sup_{\norm{\varphi}=1}\abs{\varphi\left(v\right)}\ge\norm v$.
\end{itemize}
Thus we get $\sup_{n}\norm{u_{n}}<C$.\qqed

%DATE: Fr 2.11.12


\subsection{Corollary and Definition \textmd{(Banach-Steinhaus, equicontinuous,
uniformly continuous)}}

Let $E,F$ be Banach spaces and $T_{i}\in L\left(E,F\right)$.

If the $\left(T_{i}\right)$ are point-wise bounded, then the $T_{i}$
are \emph{equicontinuous} (\foreignlanguage{ngerman}{gleichgradig
stetig}).


\subsubsection{Definition \textmd{(uniformly continuous, equicontinuous)}}

Let $f:\mathbb{R}\to\mathbb{R}$ be a real-valued function.

Continuity:
\begin{align*}
\fall_{x_{0}\in\mathbb{R}}\ \fall_{\varepsilon\in\mathbb{R}_{>0}}\ \exs_{\delta\in\mathbb{R}_{>0}}:\quad & \abs{x-x_{0}}<\delta\quad\Rightarrow\quad\abs{f\left(x\right)-f\left(x_{0}\right)}<\varepsilon
\end{align*}
 $f$ is called \emph{uniformly continuous} (\foreignlanguage{ngerman}{gleichmäßig
stetig}) if:
\begin{align*}
\fall_{\varepsilon\in\mathbb{R}_{>0}}\ \exs_{\delta\in\mathbb{R}_{>0}}: & \quad\norm{x-y}<\delta\quad\Rightarrow\quad\norm{f\left(x\right)-f\left(y\right)}<\varepsilon
\end{align*}
Let $f_{n}:\mathbb{R}\to\mathbb{R}$ be a series of real-valued functions.
$\left(f_{n}\right)$ is called \emph{equicontinuous} if: 
\begin{align*}
\fall_{x_{0}\in\mathbb{R}}\ \fall_{\varepsilon\in\mathbb{R}_{>0}}\ \exs_{\delta\in\mathbb{R}_{>0}}\ \fall_{n\in\mathbb{N}}: & \quad\norm{x-x_{0}}<\delta\quad\Rightarrow\quad\norm{f_{n}\left(x\right)-f_{n}\left(x_{0}\right)}<\varepsilon
\end{align*}
For a linear map $A\in L\left(E,F\right)$ holds:
\begin{align*}
\norm{Au} & \le\norm A\norm u\\
\norm{Au-Au_{0}} & \le\norm A\norm{u-u_{0}}
\end{align*}
Therefore choose $\delta=\frac{\varepsilon}{2\norm A}$, i.e.:
\begin{align*}
\fall_{\varepsilon\in\mathbb{R}_{>0}}\ \exs_{\delta\in\mathbb{R}_{>0}}: & \quad\norm u<\delta\quad\Rightarrow\quad\norm{Au}<\varepsilon
\end{align*}



\subsubsection*{Proof}

Since $\left(T_{i}\right)$ is point-wise bounded there is a $C\in\mathbb{R}_{>0}$
such that for all $i\in\mathbb{N}$ holds $\norm{T_{i}}\le C$ due
to the principle of uniform boundedness \ref{sub:Thm-Uniform-boundedness}.
So for all $i\in\mathbb{N}$ holds:
\begin{align*}
\norm{T_{i}u} & \le\norm{T_{i}}\norm u\le C\norm u
\end{align*}
Choose $\delta=\frac{\varepsilon}{2C}$ shows that the $T_{i}$ is
equicontinuous.\qqed

In the following let $E$ and $F$ be Banach spaces.


\subsection{Definition \textmd{(open)}}

A (not necessarily linear) map $A:E\to F$ is called \emph{open} if
the image of every open set is open. (If there exists an inverse $A^{-1}$
then ``$A$ open'' is equivalent to ``$A^{-1}$ continuous''.)

Let $A$ be linear and open. $B_{1}\left(0\right)\subseteq E$ is
open, so $A\left(B_{1}\left(0\right)\right)\subseteq F$ is open.\\
Since $0\in A\left(B_{1}\left(0\right)\right)$, there is a $\varepsilon\in\mathbb{R}_{>0}$
such that $B_{\varepsilon}\left(0\right)\subseteq A\left(B_{1}\left(0\right)\right)$.

\begin{figure}[h]
\noindent \centering{}\begin{tikzpicture}[scale=0.5]
  \draw (0,0) circle (2);
  \draw (0,0) node[right]{$0$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw[dotted] (0,0) -- node[above right]{$\varepsilon$} (-1.41,1.41);
  \draw plot[smooth cycle] coordinates {(-3,-1) (-1,-3) (2,-4) (3,-1) (2,2) (1,3) (-1,3) (-2,2)};
  \node at (5,0) {$A(B_1(0))$};
\end{tikzpicture}\caption{$B_{\varepsilon}\left(0\right)\subseteq A\left(B_{1}\left(0\right)\right)$}
\end{figure}


Due to the linearity holds in general:
\begin{align*}
B_{\lambda}\left(0\right) & \subseteq A\left(B_{\frac{\lambda}{\varepsilon}}\left(0\right)\right)
\end{align*}
In particular, $A$ is surjective.

If $A$ is additionally injective, then $A$ is bijective and the
openness means that $A^{-1}$ is continuous.


\subsection{Theorem \textmd{(Open mapping theorem, }\foreignlanguage{ngerman}{\textmd{Prinzip
der offenen Abbildung}}\textmd{)\label{sub:Thm-Open-mapping}}}

If $A\in L\left(E,F\right)$ is surjective, then $A$ is open.


\subsection{Corollary\label{sub:Cor-open-mapping}}

If $A\in L\left(E,F\right)$ is bijective, then $A^{-1}\in L\left(F,E\right)$
is continuous.


\subsubsection*{Proof}

$A$ is open following \ref{sub:Thm-Open-mapping}, since $A$ is
surjective. This means that $A^{-1}$ is continuous.\qqed


\subsubsection*{Proof of \ref{sub:Thm-Open-mapping}}

Since $A$ is surjective, $F=A\left(E\right)$. Since every element
of $E$ has a finite norm, we know:
\begin{align*}
E & =\bigcup_{n\in\mathbb{N}}B_{n}\left(0\right)\\
\Rightarrow\quad F & =A\left(\bigcup_{n\in\mathbb{N}}B_{n}\left(0\right)\right)=\bigcup_{n\in\mathbb{N}}A\left(B_{n}\left(0\right)\right)
\end{align*}
According to Baire's theorem there is a $n\in\mathbb{N}$ such that
$\overline{A\left(B_{n}\left(0\right)\right)}^{\,\circ}\not=\emptyset$.

\begin{figure}[h]
\noindent \centering{}\begin{tikzpicture}[scale=0.5]
  \draw (0,0) circle (2);
  \draw (0,0) node[right]{$y_0$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw[dotted] (0,0) -- node[above right]{$\varepsilon$} (-1.41,1.41);
  \draw plot[smooth cycle] coordinates {(-3,-1) (-1,-3) (2,-4) (3,-1) (2,2) (1,3) (-1,3) (-2,2)};
  \node at (5.5,0) {$\overline{A(B_n(0))}\subseteq F$};
\end{tikzpicture}\caption{$B_{\varepsilon}\left(y_{0}\right)\subseteq\overline{A\left(B_{n}\left(0\right)\right)}$}
\end{figure}


So there exists a $y_{0}\in A\left(B_{n}\left(0\right)\right)$ and
a $\varepsilon\in\mathbb{R}_{>0}$ such that $B_{\varepsilon}\left(y_{0}\right)\subseteq\overline{A\left(B_{n}\left(0\right)\right)}$.
Since $A$ is surjective, there is a $x_{0}\in B_{n}\left(0\right)$
with $y_{0}=A\left(x_{0}\right)$.
\begin{align*}
\Rightarrow\quad\overline{A\left(B_{n}\left(0\right)-x_{0}\right)} & =\overline{A\left(B_{n}\left(0\right)\right)-y_{0}}=\overline{A\left(B_{n}\left(0\right)\right)}-y_{0}\supseteq B_{\varepsilon}\left(y_{0}\right)-y_{0}=B_{\varepsilon}\left(0\right)
\end{align*}
If $n'$ is large enough, then $B_{n}\left(-x_{0}\right)\subseteq B_{n'}\left(0\right)$
and so $\overline{A\left(B_{n'}\left(0\right)\right)}\supseteq B_{\varepsilon}\left(0\right)$.\\
Since $A$ is linear, we can rescale, i.e. there is a $c:=\frac{\varepsilon}{n'}\in\mathbb{R}_{>0}$
such that for all $r\in\mathbb{R}_{<0}$ holds:
\begin{align*}
\overline{A\left(B_{r}\left(0\right)\right)} & \supseteq B_{cr}\left(0\right)
\end{align*}
Now we show that every $u\in B_{c}\left(0\right)$ is the image of
a $x\in B_{2}\left(0\right)$, i.e. $B_{c}\left(0\right)\subseteq A\left(B_{2}\left(0\right)\right)$:\\
Ansatz as a series:
\begin{align*}
x & =\sum_{j=1}^{\infty}x_{j}
\end{align*}
Choose $x_{1}\in B_{1}\left(0\right)$ with $\norm{u-Ax_{1}}<\frac{c}{2}$,
which is possible since $\overline{A\left(B_{1}\left(0\right)\right)}\supseteq B_{c}\left(0\right)$.\\
Choose $x_{2}\in B_{2}\left(0\right)$ with $\norm{u-Ax_{1}-Ax_{2}}<\frac{c}{4}$,
which is possible since $u-Ax_{1}\in B_{\frac{c}{2}}\left(0\right)$
and $\overline{A\left(B_{\frac{1}{2}}\left(0\right)\right)}\subseteq B_{\frac{c}{2}}\left(0\right)$.\\
And so on choose $x_{m}\in B_{\frac{1}{2^{m}}}\left(0\right)$ with
$\norm{u-\sum_{i=1}^{m}Ax_{i}}<\frac{c}{2^{m}}$.\\
The series $\sum_{i=1}^{\infty}x_{i}$ converges, since:
\begin{align*}
\norm{\sum_{j=m}^{M}x_{j}} & \le\sum_{j=m}^{M}\norm{x_{j}}\le\sum_{j=m}^{M}2^{-j}
\end{align*}
So the sequence of partial sums is a Cauchy sequence. Because $E$
is complete, this sequence converges.

The continuity of $A$ yields:
\begin{align*}
Ax & =\sum_{j=1}^{\infty}Ax_{j}=u
\end{align*}
So there exists a $x\in E$ with $\norm x<2$ and $Ax=u$. \qqed[\ref{sub:Thm-Open-mapping}]

\begin{align*}
\sum_{j=1}^{n}x_{j} & \xrightarrow{n\to\infty}x & \norm x & <2\\
\sum_{j=1}^{n}Ax_{j} & \xrightarrow{n\to\infty}u\\
\Rotate{=}\quad\\
A\left(\sum_{j=1}^{n}x_{j}\right) & \xrightarrow[\text{continuity of }A]{n\to\infty}Ax
\end{align*}



\subsubsection{Definition \textmd{(Graph)}}

For a function $f:\mathbb{R}\to\mathbb{R}$ the \emph{graph} is defined
as:
\begin{align*}
\text{graph}f & :=\left\{ \left(x,f\left(x\right)\right)\big|x\in\mathbb{R}\right\} \subseteq\mathbb{R}\times\mathbb{R}
\end{align*}
For $A:E\to F$ the \emph{graph} is:
\begin{align*}
\text{graph}A & :=\left\{ \left(u,Au\right)\big|u\in E\right\} \subseteq E\times F
\end{align*}
Here $E\times F$ is a product of normed spaces which has the norm:
\begin{align*}
\norm{\left(u,v\right)} & :=\norm u_{E}+\norm v_{F}
\end{align*}



\subsubsection{Lemma}

If $A$ is continuous, then $\text{graph}A$ is closed.


\subsubsection{Proof}

Let $\left(u_{n},Au_{n}\right)\in\text{graph}A$ be a Cauchy sequence
in $E\times F$ for Banach spaces $E$ and $F$, i.e. $u_{n}\to u$.
Since $A$ is continuous, it follows:
\begin{align*}
Au_{n} & \to v:=Au
\end{align*}
Therefore $\left(u,v\right)\in\text{graph}\left(A\right)$ and so
the graph is closed.\qqed[Lemma]

Consider the function:
\begin{align*}
f:\mathbb{R}\setminus\left\{ 0\right\}  & \to\mathbb{R}\\
x & \mapsto\frac{1}{x}
\end{align*}
 $f$ is not continuous, but $\text{graph}\left(f\right)$ is closed
in $\left(\mathbb{R}\setminus\left\{ 0\right\} \right)\times\mathbb{R}$.

\begin{figure}[h]
\noindent \centering{}\begin{tikzpicture}
 \begin{axis}[width=10cm, axis x line=middle, axis y line=middle,
			xtick={0}, ytick={0}, ymax=7, ymin=-7, xlabel=$x$, ylabel=$\ y$, domain=-7:7,samples=500]
  \addplot[mark=none] {1/x};
  \addlegendentry{$f(x)$}
 \end{axis}
\end{tikzpicture} \caption{$f$ is not continuous, but $\text{graph}f$ is closed.}
\end{figure}



\subsection{Theorem \textmd{(Closed graph theorem, }\foreignlanguage{ngerman}{\textmd{Satz
vom abgeschlossenen Graphen}}\textmd{)\label{sub:Thm-Closed-graph}}}

Suppose a linear map $A:E\to F$ between Banach spaces $E$ and $F$
has a closed graph. Then $A$ is continuous.

$\text{graph}\left(A\right)$ closed means:\\
For all $u_{n}\in E$ with $u_{n}\to u$ \emph{and} $Au_{n}\to v$,
the point $\left(u,v\right)\in\text{graph}\left(A\right)$, i.e. $Au=v$.

$A$ continuous means:\\
For all $u_{n}\in E$ with $u_{n}\to u$, the sequence $Au_{n}\to v$
converges and $Au=v$


\subsubsection{Proof}

On $E\times F$ we have the norm:
\begin{align*}
\norm{\left(u,v\right)} & :=\norm u_{E}+\norm v_{F}
\end{align*}
The graph
\begin{align*}
G & :=\left\{ \left(u,Au\right)\big|u\in E\right\} \subseteq E\times F
\end{align*}
is a subspace of $E\times F$, since for $\lambda\in\mathbb{R}$ and
$u,\tilde{u}\in E$ holds:
\begin{align*}
\lambda\left(u,Au\right)+\left(\tilde{u},A\tilde{u}\right) & =\left(\lambda u+\tilde{u},\lambda Au+A\tilde{u}\right)\stackrel{A\text{ linear}}{=}\left(\lambda u+\tilde{u},A\left(\lambda u+\tilde{u}\right)\right)\in G
\end{align*}
So $G$ is complete and therefore a Banach space, since we assumed
it to be closed.\\
Define:
\begin{align*}
P:G & \to E\\
\left(u,Au\right) & \mapsto u
\end{align*}
\begin{align*}
\norm{\left(u,Au\right)} & =\norm u+\norm{Au}\ge\norm u=\norm{P\left(u,Au\right)}
\end{align*}
So for all $w\in G$ holds $\norm{Pw}\le\norm w$ and therefore $\norm P\le1$.
In particular, $P$ is continuous.\\
$P$ is obviously surjective and it is also injective, since:
\begin{align*}
P^{-1}\left(u\right) & =\left(u,Au\right)
\end{align*}
Following the open mapping theorem, $P^{-1}$ is continuous, i.e.
there exists a $C\in\mathbb{R}_{>0}$ such that:
\begin{align*}
\norm u+\norm{Au} & =\norm{\left(u,Au\right)}=\norm{P^{-1}\left(u\right)}\le C\norm u
\end{align*}
Then follows:
\begin{align*}
\norm{Au} & \le\left(C-1\right)\norm u
\end{align*}
Therefore $A$ is continuous.\qqed


\section{Neumann series}

Let $E$ be a Banach space and $A\in L\left(E,E\right)=:L\left(E\right)$.

When is $A$ continuously invertible?\\
Remember that for $x\in\mathbb{K}$ with $\abs x<1$ holds:
\begin{align*}
\frac{1}{1-x} & =\sum_{n=0}^{\infty}x^{n}
\end{align*}
This is the geometric series.\\
\emph{Idea}: $A=\mathbbm{1}-B$ with $B\in L\left(E\right)$

\emph{Ansatz}: ${\displaystyle A^{-1}:=\sum_{n=0}^{\infty}B^{n}}$

This works indeed if $\norm B<1$.


\subsection{Lemma and Definition \textmd{(Neumann series)}}

The series
\begin{align*}
C & :=\sum_{n=0}^{\infty}B^{n}
\end{align*}
is called Neumann series (\foreignlanguage{ngerman}{Neumannsche Reihe}).

If $\norm B<1$, then $C$ defines an element of $L\left(E,E\right)$,
i.e. the Neumann series converges absolutely.


\subsubsection*{Proof}

Consider the partial sums:
\begin{align*}
S_{n} & :=\sum_{k=0}^{n}B^{k}
\end{align*}
Since $L\left(E,E\right)$ is a Banach space, it is enough to show
that $S_{n}$ is a Cauchy series. Without loss of generality assume
$m>n$:
\begin{align*}
\norm{S_{n}-S_{m}} & =\norm{\sum_{k=n}^{m}B^{k}}\stackrel{\Delta\text{ inequality}}{\le}\sum_{k=n}^{m}\norm{B^{k}}\stackrel{\text{Schwarz}}{\le}\sum_{k=n}^{m}\norm B^{k}<c\norm B^{n}\to0
\end{align*}
\qqed

%DATE: Do 8.11.12


\subsection{Theorem}

\begin{align*}
C & =\left(\mathbbm{1}-B\right)^{-1}
\end{align*}



\subsubsection*{Proof}

\begin{align*}
\left(\mathbbm{1}-B\right)C & =\left(\mathbbm{1}-B\right)\sum_{n=0}^{\infty}B^{n}=\left(\mathbbm{1}+B+B^{2}+\ldots\right)-\left(B+B^{2}+\ldots\right)=\mathbbm{1}
\end{align*}


\qqed


\subsection{Theorem\label{sub:Thm-set-cont-invertible-->open}}

The set of all continuously invertible mappings is open in $L\left(E\right)$.


\subsubsection*{Proof}

Assume that $A\in L\left(E\right)$ is continuously invertible, i.e.
$A^{-1}$ exists and $A^{-1}\in L\left(E\right)$. Set:
\begin{align*}
\varepsilon & =\frac{1}{2\norm{A^{-1}}}
\end{align*}
Let us show, that every element of $B_{\varepsilon}\left(A\right)\subseteq L\left(E\right)$
is continuously invertible:\\
Let $C\in B_{\varepsilon}\left(A\right)$, i.e. $\norm{A-C}<\varepsilon$.
\begin{align*}
C & =A-\left(A-C\right)=A\big(\mathbbm{1}-\underbrace{A^{-1}\left(A-C\right)}_{=:B}\big)
\end{align*}
Then holds:
\begin{align*}
\norm B & \le\norm{A^{-1}}\cdot\norm{A-C}<\norm{A^{-1}}\cdot\frac{1}{2\norm{A^{-1}}}=\frac{1}{2}<1
\end{align*}
Hence $\mathbbm{1}-B$ is continuously invertible by the Neumann series
and therefore
\begin{align*}
C^{-1} & =\left(\mathbbm{1}-B\right)^{-1}\cdot A^{-1}
\end{align*}
is continuous.\qqed


\chapter{Hilbert spaces}

\setcounter{subsection}{0}


\subsubsection{Definition \textmd{(scalar product)}}

Let $H$ be a real ($\mathbb{K}:=\mathbb{R}$) or complex ($\mathbb{K}:=\mathbb{C}$)
vector space with \emph{scalar product}:
\begin{align*}
\left\langle .,.\right\rangle :H\times H & \to\mathbb{K}
\end{align*}

\begin{enumerate}[label=\roman*)]
\item Positive definiteness: $\left\langle u,u\right\rangle \ge0$ and
$\left\langle u,u\right\rangle =0$ $\Rightarrow$ $u=0$.
\item Linear in the second and anti-linear in the first argument:
\begin{align*}
\left\langle \lambda u,v\right\rangle  & =\overline{\lambda}\left\langle u,v\right\rangle 
\end{align*}

\item Symmetry: $\overline{\left\langle u,v\right\rangle }=\left\langle u,v\right\rangle $
\end{enumerate}
Define the corresponding norm:
\begin{align*}
\norm u & :=\sqrt{\left\langle u,u\right\rangle }
\end{align*}



\subsection{Definition \textmd{(Hilbert space)}}

A complete scalar product space is called \emph{Hilbert space}.

The Schwarz inequality holds:
\begin{align*}
\abs{\left\langle u,v\right\rangle } & \le\norm u\cdot\norm v
\end{align*}



\subsection{Lemma \textmd{(parallelogram equality)\label{sub:Lem-parallelogram-equality}}}

The parallelogram equality (\foreignlanguage{ngerman}{Parallelogramm-Gleichung})
is:
\begin{align*}
\norm{u+v}^{2}+\norm{u-v}^{2} & =2\left(\norm u^{2}+\norm v^{2}\right)
\end{align*}


\begin{figure}[h]
\noindent \centering{}\begin{tikzpicture}
  \draw[->] (0,0) -- node[left]{$u$} (2,2);
  \draw[->] (0,0) -- node[below]{$v$} (2,-3);
  \draw[->] (2,-3) -- node[above right]{$u-v$} (2,2);
  \draw[->] (0,0) -- (4,-1) node[right]{$u+v$};
  \draw[dashed] (2,2) -- (4,-1);
  \draw[dashed] (2,-3) -- (4,-1);
\end{tikzpicture}\caption{parallelogram}
\end{figure}



\subsubsection*{Proof}

\begin{align*}
\norm{u+v}^{2} & =\left\langle u+v,u+v\right\rangle =\left\langle u,u\right\rangle +\left\langle u,v\right\rangle +\left\langle v,u\right\rangle +\left\langle v,v\right\rangle \\
\norm{u-v}^{2} & =\left\langle u-v,u-v\right\rangle =\left\langle u,u\right\rangle -\left\langle u,v\right\rangle -\left\langle v,u\right\rangle +\left\langle v,v\right\rangle \\
\Rightarrow\quad\norm{u+v}^{2}+\norm{u-v}^{2} & =2\left(\norm u^{2}+\norm v^{2}\right)
\end{align*}
\qqed


\subsection{Definition \textmd{(orthogonal, orthonormal)}}
\begin{enumerate}[label=\roman*)]
\item Vectors $u,v\in H$ are called \emph{orthogonal}, symbolically $u\perp v$,
if $\left\langle u,v\right\rangle =0$.
\item Subspaces $M_{1},M_{2}\subseteq H$ are orthogonal, symbolically $M_{1}\perp M_{2}$,
if $\left\langle u,v\right\rangle =0$ for all $u\in M_{1}$ and $v\in M_{2}$.
\item A family $\left(u_{i}\right)_{i\in I}$ of vectors $u_{i}\in H$ is
called \emph{orthonormal} if:
\begin{align*}
\left\langle u_{i},u_{j}\right\rangle  & =\delta_{ij}
\end{align*}

\end{enumerate}

\subsection{Theorem \textmd{(Bessel's inequality)}}

Let $\left(u_{i}\right)_{1\le i\le N}$ be an orthonormal family.
Then for all $u\in H$ holds:
\begin{align*}
\norm u^{2} & =\sum_{i=1}^{N}\left\langle u_{i},u\right\rangle ^{2}+\norm{u-\sum_{i=1}^{N}u_{i}\left\langle u_{i},u\right\rangle }^{2}\\
\norm u^{2} & \ge\sum_{i=1}^{N}\left\langle u_{i},u\right\rangle ^{2}
\end{align*}



\subsubsection*{Proof}

\begin{align*}
\norm{u-\sum_{i=1}^{N}u_{i}\left\langle u_{i},u\right\rangle }^{2} & =\left\langle u-\sum_{i=1}^{N}u_{i}\left\langle u_{i},u\right\rangle ,u-\sum_{j=1}^{N}u_{j}\left\langle u_{j},u\right\rangle \right\rangle =\\
 & =\left\langle u,u\right\rangle -\sum_{j=1}^{N}\left\langle u,u_{j}\right\rangle \left\langle u_{j},u\right\rangle -\sum_{i=1}^{N}\overline{\left\langle u_{i},u\right\rangle }\left\langle u_{i},u\right\rangle +\sum_{i,j=1}^{N}\overline{\left\langle u_{i},u\right\rangle }\left\langle u_{j},u\right\rangle \underbrace{\left\langle u_{i},u_{j}\right\rangle }_{=\delta_{ij}}=\\
 & =\norm u^{2}-2\sum_{i=1}^{N}\abs{\left\langle u_{i},u\right\rangle }^{2}+\sum_{i=1}^{N}\abs{\left\langle u_{i},u\right\rangle }^{2}=\\
 & =\norm u^{2}-\sum_{i=1}^{N}\abs{\left\langle u_{i},u\right\rangle }^{2}
\end{align*}
\qqed


\subsubsection{Definition \textmd{(Hilbert space isomorphism)}}

Let $\left(H_{1},\left\langle .,.\right\rangle _{1}\right)$ and $\left(H_{2},\left\langle .,.\right\rangle _{2}\right)$
be Hilbert spaces.

A \emph{Hilbert space isomorphism} is a mapping $U:H_{1}\to H_{2}$
which is linear, bijective and isometric (\foreignlanguage{ngerman}{isometrisch}),
i.e. for all $u,v\in H_{1}$:
\begin{align*}
\left\langle u,v\right\rangle _{1} & =\left\langle Uu,Uv\right\rangle _{2}
\end{align*}



\subsubsection{Definition \textmd{(Direct sum)}}

Let $\left(H_{1},\left\langle .,.\right\rangle _{1}\right)$ and $\left(H_{2},\left\langle .,.\right\rangle _{2}\right)$
be Hilbert spaces.

Define:
\begin{align*}
H: & =\left\{ \left(u,v\right)\big|u\in H_{1},v\in H_{2}\right\} 
\end{align*}
\begin{align*}
\left(u_{1},v_{1}\right)+\left(u_{2},v_{2}\right) & :=\left(u_{1}+u_{2},v_{1}+v_{2}\right)\\
\lambda\left(u,v\right) & :=\left(\lambda u,\lambda v\right)\\
\left\langle \left(u_{1},v_{1}\right),\left(u_{2},v_{2}\right)\right\rangle  & :=\left\langle u_{1},u_{2}\right\rangle +\left\langle v_{1},v_{2}\right\rangle 
\end{align*}
This makes $H=:H_{1}\oplus H_{2}$ a Hilbert space, called \emph{direct
sum} of $H_{1}$ and $H_{2}$, which is sometimes called orthogonal
due to:
\begin{align*}
\left\langle \left(u,0\right),\left(0,v\right)\right\rangle  & =0
\end{align*}



\subsection{Example}

\begin{align*}
\ell_{2} & =\left\{ \left(a_{n}\right)_{n\in\mathbb{N}}\bigg|a_{n}\in\mathbb{K},\sum_{n=1}^{\infty}\abs{a_{n}}^{2}<\infty\right\} 
\end{align*}
Define a scalar product:
\begin{align*}
\left\langle \left(a_{n}\right),\left(b_{n}\right)\right\rangle  & :=\sum_{n=1}^{\infty}\overline{a}_{n}\cdot b_{n}
\end{align*}
\begin{align*}
\left\langle \left(a_{n}\right),\left(a_{n}\right)\right\rangle  & =\sum_{n=1}^{\infty}\abs{a_{n}}^{2}=\norm{a_{n}}_{2}^{2}
\end{align*}
$\left(\ell^{2},\norm ._{2}\right)$ is a Banach space. Thus $\left(\ell^{2},\left\langle .,.\right\rangle \right)$
is a Hilbert space.


\section{Projection on closed convex subsets}

Let $\left(H,\left\langle .,.\right\rangle \right)$ be a Hilbert
space and $K\subseteq H$ a closed convex subset.
\begin{align*}
u,v & \in K & w & \in H\setminus K
\end{align*}
We want to find a vector $v$ such that $\norm{v-w}=\inf_{u\in K}\norm{u-w}$.

\begin{figure}[h]
\noindent \centering{}\begin{tikzpicture}
  \draw[rotate=30] (0,0) ellipse (2 and 1);
  \node at (0,0) {$K$};
  \draw (2,-1) node[right]{$w$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (1,0.5) node[right]{$u$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (1.25,-0.3) node[right]{$v$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw[dashed] (1.25,-0.3) -- (2,-1);
  \draw (1,-0.54) arc [radius=0.35,start angle=225,delta angle=90];
  \draw[fill] (1.25,-0.5) circle (0.03);
\end{tikzpicture}\caption{$\norm{v-w}=\inf_{u\in K}\norm{u-w}$}
\end{figure}


If $K$ were compact, then choose minimizing sequence (\foreignlanguage{ngerman}{Minimalfolge}),
i.e.:
\begin{align*}
\norm{u_{i}-w} & \to\inf_{u\in K}\norm{u-w}
\end{align*}
Choose a convergent subsequence $u_{i_{l}}\to v$. Then by continuity:
\begin{align*}
\norm{v-w} & =\lim_{i\to\infty}\norm{u_{i}-w}=\inf_{u\in K}\norm{u-w}
\end{align*}


The main application are closed subspaces $K\subseteq H$.

\begin{figure}[h]
\noindent \centering{}\begin{tikzpicture}
  \draw (0,0) -- (3,3) node [above right]{$K$};
  \draw (3,-1) node[right]{$w$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (1,1) node[right]{$v$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw[dashed] (1,1) -- (3,-1);
  \draw (0.75,0.75) arc [radius=0.35,start angle=225,delta angle=90];
  \draw[fill] (1,0.8) circle (0.03);
\end{tikzpicture}\caption{$v-w\perp K$}
\end{figure}


In this case $v-w$ will be called orthogonal to $K$ motivating the
name \emph{orthogonal projection}.


\subsection{Theorem \textmd{(Hilbert)\label{sub:Thm-Hilbert}}}

There is a unique $v\in K$ with:
\begin{align*}
\norm{v-w} & =\inf_{u\in K}\norm{u-w}
\end{align*}



\subsubsection*{Proof}

Consider a minimizing sequence $u_{i}$:
\begin{align*}
\norm{u_{i}-w} & \to\inf_{u\in K}\norm{u-w}=:d
\end{align*}
We show that $\left(u_{i}\right)$ is a Cauchy sequence:
\begin{align*}
\norm{u_{i}-u_{j}}^{2} & =\norm{\left(u_{i}-w\right)+\left(w-u_{j}\right)}^{2}=\\
 & \stackrel{\ref{sub:Lem-parallelogram-equality}}{=}2\norm{u_{i}-w}^{2}+2\norm{w-u_{j}}^{2}-\norm{\left(u_{i}-w\right)-\left(w-u_{j}\right)}^{2}=\\
 & =2\norm{u_{i}-w}^{2}+2\norm{w-u_{j}}^{2}-\norm{-2\left(w-\frac{u_{i}+u_{j}}{2}\right)}^{2}=\\
 & =2\left(\underbrace{\norm{u_{i}-w}^{2}}_{\to d^{2}}+\underbrace{\norm{w-u_{j}}^{2}}_{\to d^{2}}-2\norm{\frac{u_{i}+u_{j}}{2}-w}^{2}\right)
\end{align*}
\begin{align*}
\norm{u_{i}-w} & \xrightarrow{i\to\infty}d=\inf_{u\in K}\norm{u-w}\\
\norm{u_{j}-w} & \xrightarrow{j\to\infty}d=\inf_{u\in K}\norm{u-w}
\end{align*}
Since $K$ is convex and $u_{i},u_{j}\in K$, we know:
\begin{align*}
\frac{u_{i}+u_{j}}{2} & \in K
\end{align*}
\begin{align*}
\Rightarrow\quad\norm{\frac{u_{i}+u_{j}}{2}-w} & \ge d
\end{align*}
Thus:
\begin{align*}
\norm{u_{i}-u_{j}}^{2} & \le2\left(\norm{u_{i}-w}^{2}+\norm{w-u_{j}}^{2}-2d^{2}\right)\xrightarrow{i,j\to\infty}2\left(d^{2}+d^{2}-2d^{2}\right)=0
\end{align*}
So there exists a $N\in\mathbb{N}$ such that $\norm{u_{i}-u_{j}}<\varepsilon$
for all $i,j>N$. Therefore $\left(u_{i}\right)$ is a Cauchy sequence.
Since $H$ is complete, we know that $u_{i}\to u$ converges.\\
By continuity follows:
\begin{align*}
\norm{u-w} & =\lim_{i\to\infty}\norm{u_{i}-w}=d
\end{align*}
Uniqueness follows from the fact, that \emph{every} minimizing sequence
converges:\\
Let $u,\tilde{u}$ be both minimizers, then the sequence $\left(u,\tilde{u},u,\tilde{u},\ldots\right)$
is a minimizing sequence. Since it converges, $u=\tilde{u}$.\qqed


\subsection{Corollary}

Let $M\subseteq H$ be a closed subspace of $H$. Then a $w\in H$
can be decomposed uniquely in the form
\begin{align*}
w & =v+x
\end{align*}
with $v\in M$ and $x\in M^{\perp}$. We write $H=M\oplus M^{\perp}$.

\begin{figure}[h]
\noindent \centering{}\begin{tikzpicture}[arr/.style={decoration={markings,mark=at position 1 with {\arrow[thick]{>}}},postaction={decorate}}]
  \draw (-1,-1) -- (3,3) node [above right]{$M$};
  \draw (4,0) node[right]{$w$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (2,2) +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (0,0) node[below right]{$0$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw [arr] (0,0) -- node[above]{$v$} (2,2);
  \draw[arr] (2,2) -- node[right]{$x$} (4,0);
  \draw (1.75,1.75) arc [radius=0.35,start angle=225,delta angle=90];
  \draw[fill] (2,1.8) circle (0.03);
\end{tikzpicture}\caption{$w=v+x$}
\end{figure}



\subsubsection*{Proof}

Let $v\in M$ be as in Theorem \ref{sub:Thm-Hilbert}.
\begin{align*}
\norm{v-w} & =\inf_{u\in M}\norm{u-w}
\end{align*}
Define $x:=w-v$.
\begin{itemize}
\item $H$ real: For $u\in M$ define $\tilde{u}\left(\tau\right)=v+\tau u$
with $\tau\in\mathbb{R}$.
\begin{align*}
\norm{\tilde{u}-w}^{2} & =\norm x^{2}+2\tau\left\langle u,x\right\rangle +\tau^{2}\norm u^{2}\ge\norm x^{2}\\
0 & \le2\tau\left\langle u,x\right\rangle +\tau^{2}\norm u^{2}=:f\left(\tau\right)
\end{align*}
$f\left(\tau\right)$ has a minimum at $\tau=0$ and so $f'\left(0\right)=0$.
\begin{align*}
f'\left(0\right) & =2\left\langle u,x\right\rangle \\
\Rightarrow\quad2\left\langle u,x\right\rangle  & =0\quad\fall_{u\in M}
\end{align*}
So $x\in M^{\perp}$.
\item $H$ complex: Define $\tilde{u}\left(\tau\right)=v+\tau u$, $\tau=re^{\ii\varphi}\in\mathbb{K}$
with $r\ge0$.
\begin{align*}
\norm{\tilde{u}-w}^{2} & =\norm x^{2}+2\text{Re}\left(re^{-\ii\varphi}\left\langle u,x\right\rangle \right)+r^{2}\norm u^{2}=:f\left(r,\varphi\right)
\end{align*}
This has a minimum at $r=0$.
\begin{align*}
\Rightarrow\quad0 & =\partial_{r}f\left(0,\varphi\right)=2\text{Re}\left(e^{-\ii\varphi}\left\langle u,x\right\rangle \right)\\
\stackrel{\varphi\text{ arbitrary}}{\Rightarrow}\quad\left\langle u,x\right\rangle  & =0
\end{align*}
So $x\in M^{\perp}$.
\end{itemize}
%DATE: Fr 9.11.12

\emph{Uniqueness}: Assume that $w=v_{1}+x_{1}=v_{2}+x_{2}$ where
$v_{1},v_{2}\in M$, $x_{1},x_{2}\in M^{\perp}$.
\begin{align*}
\underbrace{v_{1}-v_{2}}_{\in M} & =\underbrace{x_{2}-x_{1}}_{\in M^{\perp}}\in M\cap M^{\perp}=\left\{ 0\right\} 
\end{align*}
Because from $u\in M\cap M^{\perp}$ follows $\left\langle u,u\right\rangle =0$
and so $u=0$.\qqed

For a Banach space $E$ we have $E,E^{*},E^{**}$ and a natural injection
$\iota:E\hookrightarrow E^{**}$.\\
For a Hilbert space $H$, suppose $u\in H$ and define:
\begin{align*}
\varphi:H & \to\mathbb{K}\\
\varphi\left(v\right) & :=\left\langle u,v\right\rangle 
\end{align*}
$\varphi$ is continuous, because:
\begin{align*}
\abs{\varphi\left(v\right)}=\abs{\left\langle u,v\right\rangle } & \le\norm u\cdot\norm v\le C\norm v
\end{align*}
Now
\begin{align*}
\iota:H & \hookrightarrow H^{*}\\
\iota\left(u\right) & =\varphi
\end{align*}
is a linear mapping, which is injective.


\subsection{Theorem \textmd{(Fréchet-Riesz)\label{sub:Thm-Frechet-Riesz}}}

For any $\varphi\in H^{*}$ there is a unique $v\in H$ such that
for all $x\in H$:
\begin{align*}
\varphi\left(x\right) & =\left\langle v,x\right\rangle 
\end{align*}
In other words: $\iota:H\to H^{*}$ is a Banach space isomorphism.


\subsubsection*{Proof}

Let $\varphi\in H^{*}$, without loss of generality $\varphi\not=0$.
\begin{align*}
M & :=\ker\varphi\subseteq H
\end{align*}
is a subspace. It is closed by continuity: For $u_{n}\in\ker\varphi$
with $u_{n}\to u$ holds:
\begin{align*}
\varphi\left(u\right) & \stackrel{\text{continuity}}{=}\lim_{n\to\infty}\varphi\left(u_{n}\right)=0
\end{align*}
So $u\in\ker\varphi$.

\begin{figure}[h]
\noindent \centering{}\begin{tikzpicture}[arr/.style={decoration={markings,mark=at position 1 with {\arrow[thick]{>}}},postaction={decorate}}]
  \draw (-1,-1) -- (3,3) node [above right]{$M$};
  \draw (4,0) node[right]{$u$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (2,2) +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (0,0) node[below right]{$0$}  +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw [arr] (0,0) -- node[above]{$v$} (2,2);
  \draw[arr] (2,2) -- node[right]{$x$} (4,0);
  \draw (1.75,1.75) arc [radius=0.35,start angle=225,delta angle=90];
  \draw[fill] (2,1.8) circle (0.03);
\end{tikzpicture}\caption{$u=v+x$}
\end{figure}

\begin{itemize}
\item $M^{\perp}$ is a one-dimensional subspace of $H$:\\
$M^{\perp}\not=\left\{ 0\right\} $:\\
Since $\varphi\not=0$ there exists a $u\in H$ with $\varphi\left(u\right)\not=0$,
thus $u\not\in M$.\\
Now decompose $u=v+x$, $v\in M$, $x\in M^{\perp}\setminus\left\{ 0\right\} $.\\
$M^{\perp}$ is one-dimensional: Take $u,v\in M^{\perp}$, $u,v\not=0$,
then $\varphi\left(u\right)\not=0$ and $\varphi\left(v\right)\not=0$.
\begin{align*}
\varphi\left(\varphi\left(v\right)u-\varphi\left(u\right)v\right) & =0
\end{align*}
So $\varphi\left(v\right)u-\varphi\left(u\right)v\in M\cap M^{\perp}=\left\{ 0\right\} $.
Thus $\varphi\left(v\right)u-\varphi\left(u\right)v=0$, implying
that $u$ and $v$ are linearly dependent.
\item Choose $u\in M^{\perp}$ with $\varphi\left(u\right)=1$, which is
always possible by rescaling.
\begin{align*}
v & :=\frac{u}{\norm u^{2}}\\
\Rightarrow\quad\varphi\left(v\right) & =\frac{1}{\norm u^{2}}\underbrace{\varphi\left(u\right)}_{=1}=\frac{1}{\norm u^{2}}\\
\left\langle v,v\right\rangle  & =\frac{\left\langle u,u\right\rangle }{\norm u^{4}}=\frac{1}{\norm u^{2}}=\varphi\left(v\right)
\end{align*}

\item This $v$ has the desired properties:\\
For $x\in H$ decompose:
\begin{align*}
x & =\underbrace{m}_{\in M}+\underbrace{\alpha v}_{\in M^{\perp}=\left\langle v\right\rangle }
\end{align*}
\begin{align*}
\Rightarrow\quad\varphi\left(x\right) & =\underbrace{\varphi\left(m\right)}_{=0}+\alpha\varphi\left(v\right)=\alpha\left\langle v,v\right\rangle =\\
 & =\left\langle v,\alpha v\right\rangle =\left\langle v,m+\alpha v\right\rangle =\left\langle v,x\right\rangle 
\end{align*}

\end{itemize}
\qqed


\subsection{Theorem \textmd{(Lax-Milgram)}}

Let $H$ be a Hilbert space and $B:H\times H\to\mathbb{K}$ be a mapping
with the following properties:
\begin{enumerate}[label=\roman*)]
\item $B\left(x,y\right)$ is linear in the second an anti-linear in the
first argument.
\item $\abs{B\left(x,y\right)}\le C\norm x\cdot\norm y$ (continuity)
\item $B$ is symmetric ($\overline{B\left(x,y\right)}=B\left(y,x\right)$)
and positive definite, i.e. $B\left(x,x\right)\ge b\norm x^{2}$ with
$b\in\mathbb{R}_{>0}$.
\item [iii')] $\abs{B\left(x,x\right)}\ge b\norm x^{2}$ with $b\in\mathbb{R}_{>0}$.
\end{enumerate}
Then every $l\in H^{*}$ can be represented uniquely as:
\begin{align*}
l\left(y\right) & =B\left(x,y\right)\qquad\fall_{y\in H}
\end{align*}



\subsubsection*{Proof}

First the easy case iii):\\
We introduce a new scalar product $\left\langle .,.\right\rangle _{B}$
by:
\begin{align*}
\left\langle x,y\right\rangle _{B} & :=B\left(x,y\right)
\end{align*}
Using ii) and iii) one sees that $\norm ._{B}$ is equivalent to $\norm .$,
i.e. there exists a $C\in\mathbb{R}_{>0}$ such that:
\begin{align*}
\frac{1}{C}\norm x & \le\norm x_{B}\le C\norm x
\end{align*}
According to the Fréchet-Riesz theorem, there exists a unique $v\in H$
with
\begin{align*}
\varphi\left(x\right) & =\left\langle v,x\right\rangle _{B}=B\left(v,x\right)
\end{align*}
for all $x\in H$.

More difficult case iii'): Given $x\in H$,
\begin{align*}
B\left(x,.\right):H & \to\mathbb{K}
\end{align*}
is a linear bounded functional according to i) and ii), i.e. $B\left(x,.\right)\in H^{*}$.\\
According to the Fréchet-Riesz theorem there exists a unique $z\in H$
such that $B\left(x,y\right)=\left\langle z,y\right\rangle $ for
all $y\in H$. This yields a mapping:
\begin{align*}
\varphi:H & \to H\\
x & \mapsto z
\end{align*}
\begin{align*}
B\left(x,y\right) & =\left\langle \varphi\left(x\right),y\right\rangle 
\end{align*}

\begin{itemize}
\item $\varphi$ is linear, because both $B$ and $\left\langle .,.\right\rangle $
are anti-linear in their first arguments.
\item $\varphi\left(H\right)\subseteq H$ is closed:
\begin{align}
b\norm x^{2}\stackrel{\text{iii')}}{\le}\abs{B\left(x,x\right)} & =\abs{\left\langle z,x\right\rangle }\le\norm z\cdot\norm x\nonumber \\
b\norm x & \le\norm z\label{eq:bx<z}
\end{align}
Let $z_{n}\in\varphi\left(H\right)$ be a sequence with $z_{n}\to z\in H$.
Choose $x_{n}$ such that $\varphi\left(x_{n}\right)=z_{n}$, i.e.
$B\left(x_{n},y\right)=\left\langle z_{n},y\right\rangle $ for all
$y\in H$.\\
Due to the anti-linearity in the first argument follows that:
\begin{align*}
B\left(x_{n}-x_{m},y\right) & =\left\langle z_{n}-z_{m},y\right\rangle 
\end{align*}
\eqref{eq:bx<z} yields that $\norm{x_{n}-x_{m}}\le\norm{z_{n}-z_{m}}$.\\
Hence $\left(x_{n}\right)$ is a Cauchy sequence and so $x_{n}\to x\in H$
converges. Since $B$ is continuous according to ii), we get:
\begin{align*}
\underbrace{B\left(x_{n},y\right)}_{\to B\left(x,y\right)} & =\underbrace{\left\langle z_{n},y\right\rangle }_{\to\left\langle z,y\right\rangle }
\end{align*}
This gives:
\begin{align*}
B\left(x,y\right) & =\left\langle z,y\right\rangle \\
\varphi\left(x\right) & =z
\end{align*}
Thus $z$ is in $\varphi\left(H\right)$.
\item $\varphi\left(H\right)=H$: Otherwise there would be a vector $y\in\varphi\left(H\right)^{\perp}\setminus\left\{ 0\right\} $
and thus for all $x\in H$ holds.
\begin{align*}
B\left(x,y\right) & =\left\langle \varphi\left(x\right),y\right\rangle =0
\end{align*}
In particular for $x=y$ this gives:
\begin{align*}
0 & =\abs{B\left(y,y\right)}\ge b\norm y^{2}\\
\Rightarrow\quad y & =0
\end{align*}
This is a contradiction and so $\varphi\left(H\right)=H$.
\item $\varphi$ is injective: Suppose there are $x,\, x'\in H$ with $\varphi\left(x\right)=\varphi\left(x'\right)$.
Then follows:
\begin{align*}
B\left(x-x',y\right) & =\big<\underbrace{\varphi\left(x\right)-\varphi\left(x'\right)}_{=0},y\big>=0
\end{align*}
Choose $y=x-x'$ so we get:
\begin{align*}
B\left(x-x',x-x'\right) & =0
\end{align*}
Since $B$ is positive definite, it follows $x=x'$.
\item Let $l\in H^{*}$. According to Fréchet-Riesz there exists a unique
$z\in H$ with $l\left(y\right)=\left\langle z,y\right\rangle $ for
all $y\in H$ and we have
\begin{align*}
\left\langle z,y\right\rangle  & =B\left(x,y\right)
\end{align*}
for $x=\varphi^{-1}\left(z\right)$. So $l\left(y\right)=B\left(x,y\right)$.
\end{itemize}
\qqed


\subsection{Corollary}

Every Hilbert space is reflexive.


\subsubsection*{Proof}

Recall $\iota:H\hookrightarrow H^{**}$. $H$ is \emph{reflexive}
if and only if $\iota$ is surjective, i.e. a Banach space isomorphism.
\begin{align*}
\tilde{\iota}:H & \to H^{*}\\
\left(\tilde{\iota}\left(u\right)\right)\left(v\right) & =\left\langle u,v\right\rangle 
\end{align*}
is bijective by Fréchet-Riesz. This holds also for $\overline{\iota}:H^{*}\to H^{**}$.
\begin{align*}
H\stackrel{\tilde{\iota}}{\to}H^{*}\stackrel{\overline{\iota}}{\to}H^{**}
\end{align*}
So $\iota=\overline{\iota}\circ\tilde{\iota}$ is bijective as composition
of bijective maps.\qqed


\section{Orthonormal Bases in Separable Hilbert Spaces}


\subsection{Example}

\begin{align*}
\ell_{2} & =\left\{ \left(a_{n}\right)_{n\in\mathbb{N}}\bigg|\sum_{n\in\mathbb{N}}\abs{a_{n}}^{2}<\infty\right\} 
\end{align*}
with the scalar product
\begin{align*}
\left\langle \left(a_{n}\right),\left(b_{n}\right)\right\rangle  & :=\sum_{n}\overline{a}_{n}b_{n}
\end{align*}
is a Hilbert space.

Idea: Let $H$ be an abstract Hilbert space. Choose an ``orthonormal
basis'' $\left(e_{i}\right)$.
\begin{align*}
H\ni u & =\sum_{i=1}^{\infty}\lambda_{i}e_{i}\\
v & =\sum_{i=1}^{\infty}\nu_{i}e_{i}
\end{align*}
\begin{align*}
\left\langle u,v\right\rangle  & =\sum_{i,j=1}^{\infty}\left\langle \lambda_{i}e_{i},\nu_{j}e_{j}\right\rangle =\sum_{i,j=1}^{\infty}\overline{\lambda_{i}}\nu_{j}\delta_{ij}=\sum_{i}\overline{\lambda_{i}}\nu_{i}
\end{align*}



\subsection{Definition \textmd{(orthonormal system, Hilbert space basis, cardinality)}}

A system $\left(e_{i}\right)_{i\in J}$ is an \emph{orthonormal system},
if $\left\langle e_{i},e_{j}\right\rangle =\delta_{ij}$. The algebraic
span is the vector space of \emph{finite} linear combinations:
\begin{align*}
\left\langle \left(e_{i}\right)\right\rangle  & =\left\{ \sum_{i=1}^{N}\lambda_{i}e_{i}\big|N\in\mathbb{N},\lambda_{i}\in\mathbb{K}\right\} 
\end{align*}
This is a subspace of $H$. Now the subspace $\overline{\left\langle \left(e_{i}\right)\right\rangle }\subseteq H$
is called \emph{Hilbert space span} (\foreignlanguage{ngerman}{Hilbertraumerzeugnis}).

An orthonormal system $\left(e_{i}\right)$ is called a \emph{orthonormal
Hilbert space basis} if $\overline{\left\langle \left(e_{i}\right)\right\rangle }=H$.

Two sets $A$ and $B$ have the same cardinality if there exists an
bijective map $\varphi:A\to B$.


\subsubsection*{Theorem \textmd{(Bernstein-Schröder)}}

$A$ and $B$ have the same cardinality if and only if there exists
an injective map from $A$ to $B$ and an injective map from $B\to A$.


\subsubsection*{(no proof)}

\clearpage{}

%DATE: Do 15.11.12

A typical application of the Lax-Milgram theorem is for $x\in\mathbb{R}^{n}$,
given real-valued functions $V\left(x\right)\!,\, f\left(x\right)$
and looking for $u\left(x\right)$ that solves:
\begin{align*}
-\Delta u\left(x\right)+V\left(x\right)u\left(x\right) & =f\left(x\right)
\end{align*}
Question: Is there a solution which ``decays at infinity''?
\begin{enumerate}
\item Weak formulation:\\
Suppose we have a solution $u\in\mathcal{C}^{2}\left(\mathbb{R}^{n}\right)$
\begin{align*}
-\Delta u+Vu-f & =0
\end{align*}
Let $\eta\in\mathcal{C}_{0}^{\infty}\left(\mathbb{R}^{n}\right)$
be a test function.
\begin{align*}
0 & =\int_{\mathbb{R}^{n}}\left(-\Delta u+Vu-f\right)\eta\dd^{n}x\sr ={\text{integration}}{\text{by parts}}\underbrace{\int_{\mathbb{R}^{n}}\left(\left\langle \nabla u,\nabla\eta\right\rangle +Vu\eta\right)\dd^{n}x}_{=:B\left(u,\eta\right)}-\underbrace{\int_{\mathbb{R}^{n}}f\eta\dd^{n}x}_{=l\left(\eta\right)}
\end{align*}
So for all $\eta\in\mathcal{C}_{0}^{\infty}\left(\mathbb{R}^{n}\right)$
holds:
\begin{align*}
B\left(u,\eta\right) & =l\left(\eta\right)
\end{align*}
\textbf{Definition:} $u$ is a \emph{weak solution} of the equation
$-\Delta u+Vu=f$ if for all $\eta\in\mathcal{C}_{0}^{\infty}\left(\mathbb{R}^{n}\right)$
holds:
\begin{align*}
B\left(u,\eta\right) & =l\left(\eta\right)
\end{align*}

\item Choose the correct Hilbert space. The first idea is $L^{2}\left(\mathbb{R}^{n}\right)$
with the scalar product:
\begin{align*}
\left\langle u,v\right\rangle  & =\int_{\mathbb{R}^{n}}uv\dd^{n}x
\end{align*}
\begin{align*}
u_{n}\left(x\right) & :=e^{-\abs x^{2}}\sin\left(nx_{1}\right)
\end{align*}
Then for all $n\in\mathbb{N}$ holds:
\begin{align*}
\norm{u_{n}}_{L^{2}} & \le C
\end{align*}
But $B\left(u_{n},u_{n}\right)\xrightarrow{n\to\infty}\infty$ diverges.
Thus $B$ is \emph{not} continuous.\\
Better choose instead:
\begin{align*}
\left\langle u,v\right\rangle  & =\int_{\mathbb{R}^{n}}\left(uv+\left\langle \nabla u,\nabla v\right\rangle \right)\dd^{n}x
\end{align*}
The corresponding Hilbert space $H^{1,2}\left(\mathbb{R}^{n}\right)$
is a Sobolev space.
\begin{align*}
L^{2}\left(\mathbb{R}^{3}\right) & \supseteq H^{1,2}\left(\mathbb{R}^{3}\right)\ni u
\end{align*}
Assume for simplicity that $0<\varepsilon\le V\le C<\infty$, then
we get:
\begin{align*}
B\left(u,u\right) & =\int_{\mathbb{R}^{n}}\left(\abs{\nabla u}^{2}+Vu^{2}\right)\dd^{n}x\le\int_{\mathbb{R}^{n}}\left(\abs{\nabla u}^{2}+Cu^{2}\right)\dd^{n}x\le\left(1+C\right)\norm u_{H^{1,2}}^{2}
\end{align*}
\begin{align*}
\abs{B\left(u,u\right)} & \ge\int\left(\abs{\nabla u}^{2}+\varepsilon u^{2}\right)\ge\min\left\{ 1,\varepsilon\right\} \norm u_{H^{1,2}}^{2}
\end{align*}
Thus the Lax-Milgram theorem applies and yields a unique weak solution
and then a regularity theorem says that $u$ is smooth.
\end{enumerate}
Consider a matrix equation
\begin{align*}
Au & =f
\end{align*}
with $A\in\text{Symm}\left(\mathbb{R}^{n}\right)$ and $f\in\mathbb{R}^{n}$.\\
For a general existence and uniqueness result one needs that $A$
is invertible or equivalently:
\begin{align*}
\fall_{u\in\mathbb{R}^{n}\setminus\left\{ 0\right\} }:\ Au & \not=0
\end{align*}
This follows from the condition:
\begin{align*}
\fall_{u\in\mathbb{R}^{n}\setminus\left\{ 0\right\} }:\ \underbrace{\left\langle u,Au\right\rangle }_{=B\left(u,u\right)} & \not=0
\end{align*}
In finite dimension this is equivalent to:
\begin{align*}
\fall_{u\in\mathbb{R}^{n}}:\ \abs{B\left(u,u\right)} & >b\norm u^{2}
\end{align*}


$\left(e_{i}\right)_{i\in I}$ is an orthonormal Hilbert space basis
of $H$ if
\begin{align*}
\left\langle e_{i},e_{j}\right\rangle  & =\delta_{ij}
\end{align*}
and:
\begin{align*}
\overline{\left\langle e_{i}\right\rangle } & =H
\end{align*}



\subsection{Theorem}

Let $\left(e_{i}\right)_{i\in\mathbb{N}}$ be an orthonormal system.
Then the mapping
\begin{align*}
\ell_{2} & \to\overline{\left\langle e_{i}\right\rangle }\stackrel{\text{closed}}{\subseteq}H\\
\left(\lambda_{i}\right) & \mapsto\sum_{i\in\mathbb{N}}\lambda_{i}e_{i}
\end{align*}
is a Hilbert space isomorphism.


\subsubsection{Proof}

The mapping is well-defined and isometric:\\
For $\left(\lambda_{i}\right)\in\ell_{2}$, i.e. $\sum_{i\in\mathbb{N}}\abs{\lambda_{i}}^{2}<\infty$
we construct:
\begin{align*}
u_{N} & :=\sum_{i=1}^{N}\lambda_{i}e_{i}\in H
\end{align*}
Without loss of generality take $M<N$, then follows:
\begin{align*}
\norm{u_{N}-u_{M}}^{2} & =\norm{\sum_{i=M}^{N}\lambda_{i}e_{i}}^{2}=\left\langle \sum_{i=M}^{N}\lambda_{i}e_{i},\sum_{i=M}^{N}\lambda_{i}e_{i}\right\rangle =\sum_{i,j=M}^{N}\overline{\lambda_{i}}\lambda_{j}\underbrace{\left\langle e_{i},e_{j}\right\rangle }_{=\delta_{ij}}=\sum_{i=M}^{N}\abs{\lambda_{i}}^{2}
\end{align*}
Thus $u_{N}$ is a Cauchy sequence and converges since $\overline{\left\langle e_{i}\right\rangle }$
is complete as a closed subset of a complete space.
\begin{align*}
u & :=\lim_{N\to\infty}u_{N}=\sum_{i=1}^{N}\lambda_{i}e_{i}
\end{align*}
\begin{align*}
\norm u^{2} & =\lim_{N\to\infty}\norm{u_{N}}^{2}=\lim_{N\to\infty}\sum_{i=1}^{N}\abs{\lambda_{i}}^{2}=\norm{\left(\lambda_{i}\right)}_{\ell_{2}}
\end{align*}
The mapping is also surjective:\\
Let $u\in\overline{\left\langle e_{i}\right\rangle }$ and $\varepsilon>0$.
So there exists a $v=\sum_{i=1}^{N}\lambda_{i}e_{i}\in\left\langle e_{i}\right\rangle $
with $\norm{v-u}<\varepsilon$.\\
In other words there exists a finite $J\subseteq\mathbb{N}$ such
that $d\left(\left\langle \left(e_{i}\right)_{i\in J}\right\rangle ,u\right)<\varepsilon$.
The vector which minimizes this distance is the orthogonal projection
of $u$ on $\left\langle \left(e_{i}\right)_{i\in J}\right\rangle $
since this is a finite-dimensional subspace, which is automatically
closed.
\begin{align*}
u_{J} & =\sum_{i\in J}e_{i}\left\langle e_{i},u\right\rangle 
\end{align*}
Choose an increasing sequence $J_{1}\subsetneq J_{2}\subsetneq\ldots$
of finite sets such that:
\begin{align*}
\norm{u_{J_{k}}-u} & \to0 & \Rightarrow\quad u_{J_{k}} & \to u
\end{align*}
Thus $u_{J_{k}}$ is bounded by a $C\in\mathbb{R}_{>0}$.
\begin{align*}
u_{J_{k}} & =\sum_{i\in J_{k}}e_{i}\underbrace{\left\langle e_{i},u\right\rangle }_{=\lambda_{i}}\\
C>\norm{u_{J_{k}}} & =\sum_{i\in J_{k}}\abs{\lambda_{i}}^{2}
\end{align*}
This gives:
\begin{align*}
\sum_{i\in\mathbb{N}}\abs{\lambda_{i}}^{2} & <\infty
\end{align*}
And so we get:
\begin{align*}
u & =\sum_{i\in\mathbb{N}}\lambda_{i}e_{i}
\end{align*}
\qqed


\subsection{Theorem \textmd{(Existence of Hilbert space basis)}}

In every Hilbert space $H$ exists an orthonormal Hilbert space basis.


\subsubsection*{Proof}

Consider $\left(u_{i}\right)_{i\in I}$ with $I=H$ and $u_{h}=h$
for all $h\in H$. $\left(u_{i}\right)_{i\in I}$ is obviously a generating
system of $H$. On the set
\begin{align*}
X & :=\left\{ \tilde{I}\subseteq I\big|\left(u_{i}\right)_{i\in\tilde{I}}\text{ is an orthonormal system}\right\} 
\end{align*}
defines „$\subseteq$“ a partial ordering.\\
Let $U\subseteq X$ be a totally ordered subset and define:
\begin{align*}
I_{U} & :=\bigcup_{\tilde{I}\in U}\tilde{I}\subseteq I
\end{align*}
$I_{U}$ is an upper bound of $U$ in $X$ if $I_{U}\in X$. Assume
$\left(u_{i}\right)_{i\in I_{U}}$ would not be orthonormal. Then
there would exist $j,k\in I_{U}$ with $\left\langle u_{j},u_{k}\right\rangle \not=\delta_{jk}$.\\
For $j=k$ would hold $\left\langle u_{j},u_{j}\right\rangle \not=1$,
but $j$ lies in $\tilde{I}\in U\subseteq X$ and therefor has to
hold$\left\langle u_{j},u_{j}\right\rangle =1$.\\
 For $j\not=k$ we would get $\left\langle u_{j},u_{k}\right\rangle \not=0$.
But $j$ lies in $\tilde{I}_{j}\in U$ and $k$ in $\tilde{I}_{k}\subseteq U$
and $U$ is totally ordered, i.e. either holds $\tilde{I}_{j}\subseteq\tilde{I}_{k}$
or $\tilde{I}_{k}\subseteq\tilde{I}_{j}$.\\
Without loss of generality assume $\tilde{I}_{j}\subseteq\tilde{I}_{k}$
(otherwise exchange $j$ and $k$). Then $j,k\in\tilde{I}_{k}\in U\subseteq X$
and hence $\left(u_{i}\right)_{i\in\tilde{I}_{j}}$ is an orthonormal
system in contradiction to $\left\langle u_{j},u_{k}\right\rangle \not=0$.
Therefore holds $I_{U}\in X$ and thus $I_{U}$ is an upper bound
of $U$.\\
Using Zorn's lemma we get a maximal element $I_{\text{max}}$ in $X$.
Because $\left(u_{i}\right)_{i\in I_{\text{max}}}$ is an orthonormal
system and thus especially linearly independent, it suffices to show
that this is an generating system of $H$.\\
Assume there exists a $i_{0}\in I$ with $u_{i_{0}}\not\in K:=\overline{\left\langle \left(u_{i}\right)_{i\in I_{\text{max}}}\right\rangle _{\text{alg.}}}$.
Since $K\subseteq H$ is closed and convex, there is an unique projection
$v$ of $u_{i_{0}}$ on $K$ and thus $h:=u_{i_{0}}-v\in K^{\perp}$.
It holds $h=u_{h}$ with $h\in H=I$.\\
Because $I_{\text{max}}$ is maximal, holds then $I_{\text{max}}\cup\left\{ h\right\} \not\in X$
and hence there is a $j\in I_{\text{max}}$ with$\left\langle h,u_{j}\right\rangle \not=0$,
because $h=j$ cannot hold due to $h\not\in I_{\text{max}}$. This
is a contradiction to $h\in K^{\perp}$ and thus holds $K=H$.\\
Therefore $\left(u_{i}\right)_{i\in I_{\text{max}}}$ is an orthonormal
Hilbert space basis of $H$.\qqed


\subsection{Theorem}

Let $H$ be a Hilbert space.
\begin{enumerate}[label=\roman*)]
\item For any $v\in H$ and for any orthonormal system $\left\{ e_{j}\big|j\in J\right\} $,
the set of elements $j\in J$ for which $\left\langle e_{j},v\right\rangle =0$
is finite or countable.
\item Any two Hilbert space bases of $H$ have the same cardinality (\foreignlanguage{ngerman}{Mächtigkeit}).
\end{enumerate}

\subsubsection*{Proof}
\begin{enumerate}[label=\roman*)]
\item Consider $v\in J$. First we show that every $n\in\mathbb{N}$, the
set $J_{n}:=\left\{ j\in J\big|\left\langle e_{j},v\right\rangle >\frac{1}{n}\right\} $
is finite. Indeed, by Bessel’s inequality, for every finite number
of elements $e_{j_{1}},\ldots,e_{j_{N}}$ of the given orthonormal
system, we have:
\begin{align*}
\sum_{k=1}^{N}\abs{\left\langle e_{j_{k}},v\right\rangle }^{2} & \le\norm v^{2}
\end{align*}
Now suppose that for some $n\in\mathbb{N}$, the set $J_{n}$ were
not finite. Then for any $N\in\mathbb{N}$ we could find elements
$e_{j_{1}},\ldots,e_{j_{N}}$ such that $\left\langle e_{j_{k}},v\right\rangle >\frac{1}{n}$
for all $k\in\left\{ 1,\ldots,N\right\} $. Hence, for these elements
holds:
\begin{align*}
\sum_{k=1}^{N}\abs{\left\langle e_{j_{k}},v\right\rangle }^{2} & >N\cdot\frac{1}{n}
\end{align*}
Clearly these becomes larger than $\norm v$ if we make $N$ sufficiently
large. Hence all the sets $J_{n}$ must be finite. But then, we see
that the set
\begin{align*}
\left\{ j\in J\big|\left\langle e_{j},v\right\rangle \not=0\right\}  & =\bigcup_{n\in\mathbb{N}}J_{n}
\end{align*}
is a countable union of finite sets, and as such can be at most countable.\qqed[\roman{enumi})]
\item If $H$ has is finite-dimensional, every Hilbert basis is a Hamel
basis of $H$ and thus the claim follows from linear algebra.\\
If $H$ is infinite-dimensional, let $\left(e_{i}\right)_{i\in I}$
and $\left(b_{j}\right)_{j\in J}$ be two Hilbert bases of $H$. ($I$
and $J$ have infinitely many elements.)\\
For $x\in H=\overline{\left\langle \left(e_{i}\right)_{i\in I}\right\rangle }=\overline{\left\langle \left(b_{j}\right)_{j\in J}\right\rangle }$
define:
\begin{align*}
B_{x} & :=\left\{ j\in J\big|\left\langle x,b_{j}\right\rangle \not=0\right\} 
\end{align*}
By i), the set $B_{x}$ is at most countable for any $x\in H$. Next,
let $j\in J$ be given. Since $\overline{\left\langle \left(e_{i}\right)_{i\in I}\right\rangle }=H$,
we must have $\left\langle b_{j},e_{i}\right\rangle \not=0$ for some
$i\in I$. Otherwise, $b_{j}\in\overline{\left\langle \left(e_{i}\right)_{i\in I}\right\rangle }^{\perp}=\left\{ 0\right\} $,
which is not possible since $b_{j}\not=0$. Therefore, we have $j\in B_{e_{i}}$
for some $i\in I$, and since $j\in J$ was arbitrary, it follows
that $J\subseteq\bigcup_{i\in I}B_{e_{i}}\subseteq I\times\mathbb{N}$.
Here the second inclusion uses that all the sets $B_{e_{j}}$ are
at most countable. It follows:
\begin{align*}
\abs J & \le\abs I\cdot\abs{\mathbb{N}}=\abs I
\end{align*}
If we exchange the roles of $I$ and $J$ above, we also obtain $\abs I\le\abs J$.
By the Schröder-Bernstein theorem, we can combine both estimates to
obtain that $\abs I=\abs J$.\qqed[\roman{enumi})]
\end{enumerate}
\qqed


\subsection{Theorem}

If $H$ is separable, then there exists a countable orthonormal Hilbert
space basis $\left(e_{i}\right)_{i\in\mathbb{N}}$.\\
Thus $H$ is Hilbert space isomorphic to $\ell_{2}$.


\subsubsection{Proof}

Since $H$ is separable, there is a countable dense subset $\left(x_{i}\right)_{i\in\mathbb{N}}$.
\begin{enumerate}
\item Arrange that the $x_{i}$ are linearly independent:\\
Start with $n=1$ and $k=1$ set:
\begin{align*}
y_{1} & =x_{1}
\end{align*}
If the $y_{1},\ldots,y_{n-1},x_{k}$ are linearly independent, we
set $y_{n}=x_{k}$ and increase $n$ and $k$ by one.\\
If the $y_{1},\ldots,y_{n-1},x_{k}$ are linearly dependent, we only
increase $k$ by one.\\
Then the $y_{i}$ are linearly independent and $\left\langle \left(y_{i}\right)\right\rangle =\left\langle \left(x_{i}\right)\right\rangle $.
\item Gram-Schmidt procedure for orthonormalization:
\begin{align*}
e_{1} & :=y_{1}\\
e_{2} & :=\frac{y_{2}-e_{1}\left\langle u_{1},y_{2}\right\rangle }{\norm{y_{2}-e_{1}\left\langle u_{1},y_{2}\right\rangle }}\\
e_{n} & :=\frac{y_{n}-\text{Pr}_{\left\langle e_{1},\ldots,e_{n-1}\right\rangle }y_{n}}{\norm{y_{n}-\text{Pr}_{\left\langle e_{1},\ldots,e_{n-1}\right\rangle }y_{n}}}
\end{align*}
Since the $y_{i}$ are linearly independent, $y_{n}-\text{Pr}_{\left\langle e_{1},\ldots,e_{n-1}\right\rangle }y_{n}$
is never zero.\\
Then by construction the $e_{i}$ are orthonormal and $\left\langle e_{i}\right\rangle =\left\langle x_{i}\right\rangle \subseteq H$
is dense and so $\left(e_{i}\right)_{i\in\mathbb{N}}$ is a Hilbert
space basis.\qqed
\end{enumerate}

\section{Weak Compactness of the Closed Unit Ball}

For a Banach space $E$ \emph{weak convergence} for $\left(u_{i}\right)_{i\in\mathbb{N}}$
with $u_{i}\in E$ means:
\begin{align*}
u_{n} & \rightharpoondown u & \Leftrightarrow\quad\fall_{\varphi\in E^{*}}:\varphi\left(u_{n}\right) & \to\varphi\left(u\right)
\end{align*}
In Hilbert spaces, we can identify $H^{*}$ with $H$ via the Fréchet-Riesz
theorem.


\subsection{Definition \textmd{(weak (sequential) compactness)}}

$x_{n}\rightharpoondown x$ \emph{converges weakly} if $\left\langle y,x_{n}\right\rangle \to\left\langle y,x\right\rangle $
converges for all $y\in H$.

Weak compactness is for us by definition the same as \emph{weak sequential
compactness} (\foreignlanguage{ngerman}{schwache Folgenkompaktheit}):\\
$K\subseteq H$ is \emph{weakly compact} if every sequence $\left(x_{n}\right)$
with $x_{n}\in K$ has a weakly convergent subsequence.


\subsection{Proposition}

Let $H$ be \emph{separable} and infinite-dimensional and let $\left(e_{i}\right)_{i\in\mathbb{N}}$
be an orthonormal Hilbert space basis.

Then $e_{n}\rightharpoondown0$ converges weakly.


\subsubsection*{Proof}

Take $y\in H$ and expand it in the basis:
\begin{align*}
y & =\sum_{i=1}^{\infty}y_{i}e_{i}\\
y_{i} & =\left\langle e_{i},y\right\rangle 
\end{align*}
We know $\left(y_{i}\right)_{i\in\mathbb{N}}\in\ell_{2}$ and in particular
$y_{i}\xrightarrow{i\to\infty}0$, since the elements of an absolutely
convergent series converge to zero. Therefore holds:
\begin{align*}
\left\langle y,e_{n}\right\rangle  & =\overline{y_{n}}\xrightarrow{n\to\infty}0
\end{align*}
Thus $e_{n}\rightharpoondown0$ converges weakly.\qqed


\subsection{Theorem \textmd{(Weak Compactness of the Closed Unit Ball)}}

If $H$ is \emph{separable}, then the closed unit ball $\overline{B_{1}\left(0\right)}=\left\{ u\big|\norm u\le1\right\} $
is weakly compact.


\subsubsection{Proof}

Let $\left(u_{l}\right)$ be a sequence with $u_{l}\in\overline{B_{1}\left(0\right)}$.
Choose an orthonormal Hilbert space basis $\left(e_{n}\right)_{n\in\mathbb{N}}$.
\begin{align*}
u_{l} & =\sum_{n=1}^{\infty}u_{ln}e_{n} & u_{ln} & =\left\langle e_{n},u_{l}\right\rangle  & \left(u_{l,n}\right)_{n\in\mathbb{N}} & \in\ell_{2}
\end{align*}
\begin{align*}
\abs{u_{ln}} & =\abs{\left\langle e_{n},u_{l}\right\rangle }\le\underbrace{\norm{e_{n}}}_{=1}\cdot\norm{u_{l}}\le1
\end{align*}
For $n=1$: $\left(u_{l,1}\right)_{l\in\mathbb{N}}$ is a bounded
sequence of complex or real numbers. Therefore there exists a convergent
subsequence of $u_{l}$, which we denote by $u_{l}^{\left(1\right)}\in H$.
Then follows:
\begin{align*}
u_{l,1}^{\left(1\right)} & =\left\langle e_{1},u_{l}^{\left(1\right)}\right\rangle \xrightarrow{l\to\infty}v_{1}
\end{align*}
For $n=2$: Next we choose a subsequence $u_{l}^{\left(2\right)}$
of $u_{l}^{\left(1\right)}$ such that:
\begin{align*}
\left\langle e_{2},u_{l}^{\left(2\right)}\right\rangle  & \xrightarrow{l\to\infty}v_{2}
\end{align*}
Proceed inductively to obtain:
\begin{align*}
\left\langle e_{n},u_{l}^{\left(n\right)}\right\rangle  & \to v_{n}
\end{align*}
Then $w_{l}=u_{l}^{\left(l\right)}\in\overline{B_{1}\left(0\right)}$
for a sequence $\left(w_{l}\right)$ in $\overline{B_{1}\left(0\right)}$.
\begin{description}
\item [{Claim:}] $w_{l}\stackrel{l\to\infty}{\rightharpoondown}v:=\sum_{n}v_{n}e_{n}$
\item [{Proof:}] We proceed as follows:
\begin{align*}
v_{n}=\lim_{l\to\infty}\left\langle e_{n},u_{l}^{\left(n\right)}\right\rangle  & =\lim_{l\to\infty}\left\langle e_{n},u_{l}^{\left(l\right)}\right\rangle =\lim_{l\to\infty}\left\langle e_{n},w_{l}\right\rangle 
\end{align*}
This is because $u_{l}^{\left(l\right)}=u_{l'}^{\left(n\right)}$
for $l'\ge l$.

\begin{enumerate}
\item $\left(v_{n}\right)\in\ell_{2}$:
\begin{align*}
\sum_{n=1}^{N}\abs{v_{n}}^{2} & =\sum_{n=1}^{N}\abs{\lim_{l\to\infty}\left\langle e_{n},w_{l}\right\rangle }^{2}\stackrel{\text{finite sum}}{=}\lim_{l\to\infty}\underbrace{\sum_{n=1}^{N}\abs{\left\langle e_{n},w_{l}\right\rangle }^{2}}_{\sr{\le}{\text{Bessel's}}{\text{inequality}}\norm{w_{l}}^{2}\le1}
\end{align*}
So we get for all $N\in\mathbb{N}$:
\begin{align*}
\sum_{n=1}^{N}\abs{v_{n}}^{2} & \le1
\end{align*}
And thus $\left(v_{n}\right)\in\ell_{2}$ and $v:=\sum_{n=1}^{\infty}v_{n}e_{n}$
is well-defined and has $\norm v\le1$.
\item $w_{l}\rightharpoondown v$, i.e. $\left\langle y,w_{l}-v\right\rangle \xrightarrow{l\to\infty}0$
for all $y\in H$:
\begin{align*}
y & =\sum_{n=1}^{\infty}y_{n}e_{n}
\end{align*}
\begin{align*}
y_{n} & =\left\langle e_{n},y\right\rangle \\
y_{<} & :=\sum_{n\le N}y_{n}e_{n}\\
y_{>} & :=\sum_{n>N}y_{n}e_{n}\\
\norm y^{2} & =\norm{y_{<}}^{2}+\norm{y_{>}}^{2}
\end{align*}
\begin{align*}
\left\langle y,w_{l}-v\right\rangle  & =\sum_{n=1}^{\infty}y_{n}\left\langle e_{n},w_{l}-v\right\rangle 
\end{align*}
Choose $N\in\mathbb{N}$ so large that
\begin{align*}
\norm{y_{>}}=\left(\sum_{n>N}\abs{y_{n}}^{2}\right)^{\frac{1}{2}} & <\frac{\varepsilon}{4}
\end{align*}
to get:
\begin{align*}
\abs{\left\langle y,w_{l}-v\right\rangle } & \le\abs{\left\langle y_{<},w_{l}-v\right\rangle }+\abs{\left\langle y_{>},w_{l}-v\right\rangle }\le\\
 & \le\sum_{n=1}^{N}\abs{y_{n}}\abs{\left\langle e_{n},w_{l}-v\right\rangle }+\underbrace{\norm{y_{>}}}_{<\frac{\varepsilon}{4}}\cdot\underbrace{\norm{w_{l}-v}}_{\le2}<\sum_{n=1}^{N}\abs{y_{n}}\abs{\left\langle e_{n},w_{l}-v\right\rangle }+\frac{\varepsilon}{2}
\end{align*}
We know $\abs{\left\langle e_{n},w_{l}-v\right\rangle }\xrightarrow{l\to\infty}0$
for each $n$. So we can choose $\abs{\left\langle e_{n},w_{l}-v\right\rangle }\le\frac{\varepsilon}{2}$
for $n\le N$ and for all $l>L\left(\varepsilon\right)$ for a sufficiently
large $L\left(\varepsilon\right)$ and therefore:
\begin{align*}
\abs{\left\langle y,w_{l}-v\right\rangle } & \le\varepsilon\qquad\fall_{l>L\left(\varepsilon\right)}
\end{align*}
Therefore $\left\langle y,w_{l}\right\rangle \to\left\langle y,v\right\rangle $
converges, which means $w_{l}\rightharpoondown v$.\qqed[Claim]
\end{enumerate}
\end{description}
\qqed

%DATE: Fr 16.11.12

The corresponding statement in Banach spaces is the \emph{Banach-Alaoglu
theorem}:

Banach proved it in 1932 for separable Banach spaces using diagonal
sequences.

Alaoglu proved it in 1938 for any Banach space. The proof is based
on Tychonov's theorem.

We have $E$, $E^{*}$, $E^{**}$ and an injection $\iota:E\to E^{**}$.


\subsubsection*{Theorem \textmd{(Banach-Alaoglu)}}

The closed unit ball in $E^{*}$ is \emph{weak-$*$-sequentially compact}.

I.e. in simple terms:

If $\varphi_{n}\in\overline{B_{1}\left(0\right)}\subseteq E^{*}$,
then there exists a subsequence $\varphi_{n_{l}}$ such that $\varphi_{n_{l}}\left(u\right)$
converges for all $u\in E$.

Application: Consider
\begin{align*}
E & =C^{0}\left(\mathbb{R}^{n}\right)
\end{align*}
with the sup-norm:
\begin{align*}
\norm f & =\sup_{x\in\mathbb{R}^{n}}\abs{f\left(x\right)}
\end{align*}
\begin{align*}
E^{*} & =\left\{ \text{regular Borel measures}\right\} 
\end{align*}
Suppose $\mu_{n}$ is a sequence of measures with $\norm{\mu_{n}}\le C$
for all $n\in\mathbb{N}$. Then there exists a measure $\mu$ such
that $\mu_{n_{l}}\to\mu$ converges as a measure.


\chapter{Operators on Hilbert spaces}

\setcounter{subsection}{0}

Let $H$ be a Hilbert space.
\begin{align*}
L\left(H\right) & :=L\left(H,H\right)
\end{align*}
is the Banach space of bounded linear operators. (An linear map on
an infinite dimensional space is usually called \emph{linear operator}.)
For $A\in L\left(H\right)$ define the norm:
\begin{align*}
\opnorm A & :=\sup_{\norm u=1}\norm{Au}
\end{align*}



\subsection{Example}

$H=L^{2}\left(\mathbb{R},\dd x\right)$ with the Lebesgue measure
$\dd x$.
\begin{align*}
\left\langle f,g\right\rangle  & =\int_{\mathbb{R}}\overline{f}g\dd x
\end{align*}
\begin{align*}
A & :=\frac{\dd}{\dd x}
\end{align*}
We would like to introduce this as an operator on $H$.\\
The inequality $\norm{Au}\le C\norm u$ is violated even for $u\in C_{0}^{\infty}\left(\mathbb{R}\right)$
for any constant $C\in\mathbb{R}$.\\
Namely consider
\begin{align*}
u_{n}\left(x\right) & =\eta\left(x\right)\sin\left(nx\right)
\end{align*}
with $\eta\in C_{0}^{\infty}\left(\mathbb{R}\right)$ and $\eta\big|_{\left[-1,1\right]}=1$.
Then $\norm{u_{n}}<\infty$ and $\norm{Au_{n}}\xrightarrow{n\to\infty}\infty$.

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
 \begin{axis}[height=7cm, axis x line=middle, axis y line=middle,
			x tick label style={/pgf/number format/dec sep={,}},
			xtick={0}, ytick={0}, xlabel=$x$, ylabel=$y$, samples=300, ymax=1.2, ymin=-0.07]
   \addplot[domain=-2.99:-1.01] {exp(-1/(3+x)^2)/(exp(-1/(3+x)^2)+exp(-1/(-x-1)^2))};
   \addplot[domain=-1.01:1.01] {1};
   \addplot[domain=1.01:2.99] {exp(-1/(3-x)^2)/(exp(-1/(3-x)^2)+exp(-1/(x-1)^2))};
  \addlegendentry{$\eta$}
 \end{axis}
\end{tikzpicture}\caption{$\eta\in C_{0}^{\infty}\left(\mathbb{R}\right)$ with $\eta\big|_{\left[-1,1\right]}=1$}
\end{figure}


Moreover $\frac{\dd}{\dd x}f$ makes no sense for every vector $f$
in $H$, because $f$ does not need to be differentiable.

Way out: Define $A$ only on a suitable subspace $\mathcal{D}\left(A\right)$
of $H$, called \emph{domain} of definition.\\
For example: Choose $\mathcal{D}\left(A\right)=C_{0}^{\infty}\left(\mathbb{R}\right)\subseteq H$
and:
\begin{align*}
A:\mathcal{D}\left(A\right) & \xrightarrow{\text{linear}}H
\end{align*}
$\mathcal{D}\left(A\right)$ is dense in $H$, i.e. $\overline{\mathcal{D}\left(A\right)}=H$.


\subsection{Definition \textmd{(linear operator, domain, bounded)}}
\begin{enumerate}[label=\roman*)]
\item Let $\mathcal{D}\subseteq H$ be a dense subspace. A linear map $A:\mathcal{D}\to H$
is called a \emph{linear operator} on $H$ with domain (of definition)
$\mathcal{D}$.
\item $A$ is called \emph{bounded}, if there exists a $C\in\mathbb{R}_{>0}$
such that for all $u\in\mathcal{D}$ holds:
\begin{align*}
\norm{Au} & \le C\norm u
\end{align*}
Otherwise $A$ is called unbounded.
\end{enumerate}

\subsection{Lemma}

If $A$ is a bounded operator with dense domain $\mathcal{D}\subseteq H$,
then it can be extended by continuity to a unique operator $A\in L\left(H\right)$.


\subsubsection{Proof}

Let $u\in H$, not necessarily in $\mathcal{D}$. Since $\overline{\mathcal{D}}=H$,
there is a sequence $\left(u_{l}\right)$ in $\mathcal{D}$ with $u_{l}\to u$.
\begin{align*}
\norm{Au_{i}-Au_{j}} & =\norm{A\left(u_{i}-u_{j}\right)}\le C\cdot\norm{u_{i}-u_{j}}\xrightarrow{i,j\to\infty}0
\end{align*}
Therefore we can set:
\begin{align*}
Au & :=\lim_{l\to\infty}Au_{l}
\end{align*}
Since $Au_{l}$ converges for any sequence $u_{l}\to u$, this is
well-defined.
\begin{align*}
\norm{Au}\leftarrow\norm{Au_{i}} & \le C\norm{u_{i}}\to C\norm u
\end{align*}
So there exists a $C$ such that $\norm{Au}\le C\norm u$ for all
$u\in H$ and therefore $A\in L\left(H\right)$.\qqed


\section{Isometric and unitary operators}


\subsection{Definition \textmd{(isometric operator)}}

A operator $V:\mathcal{D}\left(V\right)\to H$ with dense domain $\mathcal{D}\left(V\right)\subseteq H$
is called \emph{isometric} if for all $u\in\mathcal{D}\left(V\right)$
holds:
\begin{align*}
\left\langle Vu,Vu\right\rangle  & =\left\langle u,u\right\rangle 
\end{align*}
This operator is bounded, because:
\begin{align*}
\norm{Vu} & =\sqrt{\left\langle Vu,Vu\right\rangle }=\sqrt{\left\langle u,u\right\rangle }=\norm u\stackrel{C:=1}{\le}C\norm u
\end{align*}
Therefore we can extend it by continuity to $H$ and
\begin{align*}
V:H & \to H
\end{align*}
is again isometric.


\subsubsection*{The ``Hilbert hotel''}

Consider $H=\ell_{2}$ and $\left(a_{i}\right)=\left(a_{1},a_{2},\ldots\right)\in\ell_{2}$.
\begin{align*}
A\left(u_{1},u_{2},\ldots\right) & :=\left(0,u_{1},u_{2},\ldots\right)
\end{align*}
$A$ is isometric, but it is no bijection.

Suppose you have a hotel with an infinite number of rooms and an infinite
number of guest, in every room one guest.\\
If a new guest arrives, just move the guest from room $n$ to room
$n+1$ and the first room gets unoccupied, so the new guest can use
it.


\subsection{Proposition}

For an isometric operator $V$ the subspace $V\left(H\right)\subseteq H$
is closed.


\subsubsection*{Proof}

Consider $y\in\overline{V\left(H\right)}$ and show $y\in V\left(H\right)$:\\
There exists a $\left(y_{n}\right)$ with $y_{n}\in V\left(H\right)$
and $y_{n}\to y$ and a $\left(x_{n}\right)$ with $V\left(x_{n}\right)=y_{n}$.
Then holds:
\begin{align*}
\norm{x_{i}-x_{j}} & \stackrel{V\text{ isometric}}{=}\norm{V\left(x_{i}-x_{j}\right)}=\norm{y_{i}-y_{j}}\xrightarrow{i,j\to\infty}0
\end{align*}
Thus $x_{i}\to x$ converges. By continuity we get:
\begin{align*}
V\left(x\right) & =\lim_{i\to\infty}V\left(x_{i}\right)=\lim_{i\to\infty}y_{i}=y
\end{align*}
\qqed


\subsection{Definition \textmd{(unitary operator)}}

If $V:H\to H$ is an isometric operator and $V\left(H\right)=H$,
then $V$ is called \emph{unitary} (\foreignlanguage{ngerman}{unitär}).


\section{The Closure of an Operator}

Let $E$ and $F$ be Banach spaces and $A:\mathcal{D}\left(A\right)\subseteq E\to F$
be a densely defined linear operator.
\begin{align*}
\text{graph}\left(A\right) & :=\left\{ \left(u,Au\right)\big|u\in\mathcal{D}\left(A\right)\right\} \subseteq E\times F\\
\overline{\text{graph}\left(A\right)} & \subseteq E\times F
\end{align*}
Try to realize this as the graph of a new operator $\overline{A}$.
\begin{align*}
\mathcal{D}\left(\overline{A}\right) & :=\text{pr}_{1}\left(\overline{\text{graph}A}\right)=\left\{ u\bigg|\exs_{v\in F}:\left(u,v\right)\in\overline{\text{graph}A}\right\} 
\end{align*}
For $u\in\mathcal{D}\left(\overline{A}\right)$ and $\left(u,v\right)\in\overline{\text{graph}A}$
define:
\begin{align*}
\overline{A}u & :=v
\end{align*}
$v$ exists by definition of $\mathcal{D}\left(\overline{A}\right)$.
Is $v$ unique?\\
Suppose $\left(u,v\right)\in\overline{\text{graph}A}$. Then there
exists a sequence $\left(u_{n},v_{n}\right)\in\text{graph}\left(A\right)$,
with $\left(u_{n},v_{n}\right)\to\left(u,v\right)$. Equivalently:
\begin{align*}
\fall_{n\in\mathbb{N}}\ \exs_{u_{n}\in\mathcal{D}\left(A\right)}: & \left(u_{n}\to u\right)\wedge\left(Au_{n}\to v\right)
\end{align*}
Then we set $\overline{A}u:=v$.
\begin{description}
\item [{Problem:}] There might be two different series $\left(u_{n}\right)$
and $\left(\tilde{u}_{n}\right)$ with $u_{n}\to u$, $\tilde{u}_{n}\to u$,
$Au_{n}\to v$ and $A\tilde{u}_{n}\to\tilde{v}\not=v$.
\end{description}

\subsection{Definition \textmd{(closable operator)}}

A densely defined operator $A$ is called closable (\foreignlanguage{ngerman}{abschließbar})
if $\overline{\text{graph}A}$ is the graph of an operator $B$.\\
$B$ is called the \emph{closure} of $A$, symbolically $B=\overline{A}$.


\subsection{Definition \textmd{(closed)}}

$A$ is called \emph{closed} if $\text{graph}A$ is a closed subset
of $E\times F$.


\subsection{Theorem \textmd{(closed graph theorem)}}

Reformulation of \ref{sub:Thm-Closed-graph}:

If $\mathcal{D}\left(A\right)=E$, then $A$ is closed if and only
if $A$ is bounded.


\subsection{Example}

Consider $E=C^{0}\left(\left[0,1\right]\right)$ with the norm $\norm f=\sup_{x\in\left[0,1\right]}\abs{f\left(x\right)}$.
\begin{align*}
\mathcal{D}\left(A\right) & =C^{1}\left(\left[0,1\right]\right)\subseteq E
\end{align*}
\begin{align*}
A:\mathcal{D}\left(A\right) & \to E\\
f & \mapsto f'
\end{align*}
$A$ is a densely defined, unbounded operator. Is $A$ closed?

Consider $\left(u,v\right)\in\overline{\text{graph}A}$, i.e. there
exists a sequence $\left(u_{n}\right)\subseteq\mathcal{D}\left(A\right)$
with $u_{n}\to u$ and $Au_{n}\to v$.\\
$u_{n}\to u$ means uniform convergence of $u_{n}\rightrightarrows u$,
so $u$ is continuous as a uniform limit of continuous functions.\\
$Au_{n}\to u$ means uniform convergence of $Au_{n}\rightrightarrows v$,
so $v$ is also continuous.\\
It follows that $u\in C^{1}$ and $u'=v$.\\
So $\left(u,v\right)\in\text{graph}A$ and therefore $A$ is closed.

Consider $F:=C^{1}\left(\left[0,1\right]\right)$ with $\norm u=\sup_{\left[0,1\right]}\abs u+\sup_{\left[0,1\right]}\abs{u'}$.
This is a Banach space.


\subsubsection*{Remark}

The closure of a closable operator is always closed.\\
This is obvious, because $\text{graph}\overline{A}\stackrel{\text{def.}}{=}\overline{\text{graph}A}$,
which is closed.


\subsection{Theorem \textmd{(Criterion for closable)}\label{sub:Thm-Criterion-closable}}

$A$ is closable if and only if:
\begin{align*}
\left(u_{n}\in\mathcal{D}\left(A\right)\right)\wedge\left(u_{n}\to0\right)\wedge\left(Au_{n}\to v\right) & \quad\Rightarrow\quad v=0
\end{align*}



\subsubsection*{Proof}

``$\Rightarrow$'': Suppose $A$ is closable. Thus there is an operator
$\overline{A}$ such that $\text{graph}\overline{A}=\overline{\text{graph}A}$.\\
Suppose that $u_{n}\in\mathcal{D}\left(A\right)$, $u_{n}\to0$ and
$Au_{n}\to v$. Then $\left(u_{n},Au_{n}\right)\to\left(0,v\right)\in\overline{\text{graph}A}=\text{graph}\overline{A}$
and thus $v=\overline{A}\left(0\right)=0$.

``$\Leftarrow$'': Suppose that the implication
\begin{align*}
\left(u_{n}\in\mathcal{D}\left(A\right)\right)\wedge\left(u_{n}\to0\right)\wedge\left(Au_{n}\to v\right) & \quad\Rightarrow\quad v=0
\end{align*}
holds.\\
Define $\mathcal{D}\left(\overline{A}\right)$ by: $u_{n}\in\mathcal{D}\left(A\right)$
with $u_{n}\to u$ and $Au_{n}\to v$. Then for $u\in\mathcal{D}\left(\overline{A}\right)$
set $\overline{A}\left(u\right)=v$.\\
This is well-defined: Suppose $u_{n},\tilde{u}_{n}\to u$, $Au_{n}\to v$
and $A\tilde{u}_{n}\to\tilde{v}$. Then $u_{n}-\tilde{u}_{n}\to0$
and $A\left(u_{n}-\tilde{u}_{n}\right)\to v-\tilde{v}$. By assumption
follows $v-\tilde{v}=0$.\qqed

%DATE: Do 22.11.12
%Prof. Finster vertreten durch Dr. Müller


\section{The adjoint of a densely defined operator}

Let $A:\mathcal{D}\left(A\right)\to H$ be a linear operator with
$\overline{\mathcal{D}\left(A\right)}=H$.\\
In finite-dimensional linear algebra the definition of the adjoint
$A^{*}$ is:
\begin{align*}
\left\langle u,Av\right\rangle  & =:\left\langle A^{*}u,v\right\rangle \quad\fall_{u,v\in H}
\end{align*}
Here it is more complicated, since in general $\mathcal{D}\left(A\right)\not=H$.
\begin{align*}
M & :=\left\{ \left(u,w\right)\in H\times H\bigg|\fall_{v\in\mathcal{D}\left(A\right)}:\left\langle u,Av\right\rangle =\left\langle w,v\right\rangle \right\} 
\end{align*}

\begin{description}
\item [{Claim:}] $M$ is the graph of a linear map $A^{*}$.
\item [{Proof:}] $M\not=\emptyset$ since $\left(0,0\right)\in M$.

\begin{itemize}
\item The image is unique: $u\mapsto w$ is well-defined, as from $\left(u,w\right),\left(u,w'\right)\in M$
follows for all $v\in\mathcal{D}\left(A\right)$:
\begin{align*}
\left\langle w-w',v\right\rangle =\left\langle u-u,Av\right\rangle  & =0
\end{align*}
Since $\mathcal{D}\left(A\right)$ is dense, $w-w'=0$ follows.
\item $A^{*}$ is linear: For $\left(u,w\right),\left(u',w'\right)\in M$
and $\lambda\in\mathbb{K}$ follows $\left(u+\lambda u',w+\lambda w'\right)\in M$,
which is obvious from the definition of $M$.\qqed[Claim]
\end{itemize}
\end{description}

\subsection{Theorem}

$A^{*}$ is closed.


\subsubsection*{Proof}

Let $x_{n}\in\mathcal{D}\left(A^{*}\right)$ converge to $x\in H$
and $A^{*}x_{n}\to y\in H$. For $z\in\mathcal{D}\left(A\right)$
holds:
\begin{align*}
\left\langle x,Az\right\rangle  & \stackrel{\left\langle .,.\right\rangle \text{ continuous}}{=}\lim_{n\to\infty}\left\langle x_{n},Az\right\rangle =\lim_{n\to\infty}\left\langle A^{*}x_{n},z\right\rangle \stackrel{\left\langle .,.\right\rangle \text{ continuous}}{=}\left\langle y,z\right\rangle 
\end{align*}
This shows $x\in\mathcal{D}\left(A^{*}\right)$ and $A^{*}x=y$, so
$A^{*}$ is closed.\qqed


\subsection{Theorem}

$A^{*}$ is the maximal, i.e. not extensible, operator $S$ with the
property that for all $u\in\mathcal{D}\left(A\right)$ and $v\in\mathcal{D}\left(S\right)$:
\begin{align*}
\left\langle Au,v\right\rangle  & =\left\langle u,Sv\right\rangle 
\end{align*}



\subsubsection*{Proof}

\begin{align*}
\text{graph}\left(S\right) & =\left\{ \left(v,w\right)\in\mathcal{D}\left(S\right)\times H\bigg|Sv=w\right\} =\\
 & =\left\{ \left(v,w\right)\in\mathcal{D}\left(S\right)\times H\bigg|\fall_{u\in\mathcal{D}\left(A\right)}\left\langle Au,v\right\rangle =\left\langle u,w\right\rangle \right\} =\\
 & =\left\{ \left(v,w\right)\in H\times H\bigg|\fall_{u\in\mathcal{D}\left(A\right)}\left\langle v,Au\right\rangle =\left\langle w,u\right\rangle \right\} =\text{graph}\left(A^{*}\right)
\end{align*}
\qqed


\section{Symmetric and self-adjoint densely defined operators}


\subsection{Definition \textmd{(symmetric, (essentially) self-adjoint)}}
\begin{enumerate}[label=\roman*)]
\item $A$ is \emph{symmetric} $:\Leftrightarrow$ $\fall_{u,v\in\mathcal{D}\left(A\right)}:$
$\left\langle Au,v\right\rangle =\left\langle u,Av\right\rangle $
\item $A$ is \emph{self-adjoint} $:\Leftrightarrow$ $A^{*}=A$ (in particular,
$\mathcal{D}\left(A^{*}\right)=\mathcal{D}\left(A\right)$)
\item $A$ is \emph{essentially self-adjoint} $:\Leftrightarrow$ $\overline{A}$
is self-adjoint
\end{enumerate}
For bounded $A$ with $\mathcal{D}\left(A\right)=H$ all these notions
coincide.


\subsection{Example}

Consider the operator $A:=\Delta=\sum_{i=1}^{n}\partial_{i}^{2}$
on $L^{2}\left(\Omega\right)$ for a bounded open region $\mbox{\ensuremath{\Omega\subseteq}}\mathbb{R}^{n}$
with $\mathcal{D}\left(A\right)=C_{0}^{\infty}\left(\Omega\right)\stackrel{\text{dense}}{\subseteq}L^{2}\left(\Omega\right)$.
\begin{itemize}
\item $A$ is symmetric:
\begin{align*}
\left\langle Af,g\right\rangle  & \stackrel{\text{integration by parts}}{=}\left\langle f,Ag\right\rangle 
\end{align*}

\item Adjoint of $\Delta$ on $L^{2}$:
\begin{align*}
\int\dd^{n}r\left(\Delta f\right)\cdot g & =\int\dd^{n}rf\cdot\underbrace{h}_{\in L^{2}}
\end{align*}
Here $h:=A^{*}g$. It is sufficient to consider $g\in H^{2,2}\left(\Omega\right)$
(Sobolev space). $\mathcal{D}\left(A^{*}\right)\supsetneq\mathcal{D}\left(A\right)$
\end{itemize}

\subsection{Lemma}

Let $A$ be a symmetric operator. Then $A$ is closable and $\overline{A}$
and $A^{*}$ are extensions of $A$ and $\mathcal{D}\left(A\right)\stackrel{\text{i)}}{\subseteq}\mathcal{D}\left(\overline{A}\right)\stackrel{\text{ii)}}{\subseteq}\mathcal{D}\left(A^{*}\right)$.


\subsubsection{Proof}

Let $u_{n}\in\mathcal{D}\left(A\right)$ with $u_{n}\to0$ and $Au_{n}\to w$.
\begin{align*}
\left\langle Au,v\right\rangle  & =\left\langle u,Av\right\rangle \quad\fall_{u,v\in\mathcal{D}\left(A\right)}\\
\left\langle w,v\right\rangle \leftarrow\left\langle Au_{n},v\right\rangle  & =\left\langle u_{n},Av\right\rangle \to\left\langle 0,Av\right\rangle =0
\end{align*}
Since this holds for all $v\in\mathcal{D}\left(A\right)$ now $w=0$
follows. From the criterion \ref{sub:Thm-Criterion-closable} follows
that $A$ is closable.
\begin{enumerate}[label=\roman*)]
\item is obvious from the definition of $\overline{A}$.
\item Take $u\in\mathcal{D}\left(\overline{A}\right)$. Then there is a
sequence $u_{n}\in\mathcal{D}\left(A\right)$ with $u_{n}\to u$ and
$Au_{n}\to\overline{A}u$.\\
For all $v\in\mathcal{D}\left(A\right)$ holds:
\begin{align*}
\left\langle \overline{A}u,v\right\rangle \leftarrow\left\langle Au_{n},v\right\rangle  & =\left\langle u_{n},Av\right\rangle \to\left\langle u,Av\right\rangle 
\end{align*}
So $u\in\mathcal{D}\left(A^{*}\right)$ and $A^{*}u=\overline{A}u$.
\end{enumerate}
\qqed

„The smaller one chooses $\mathcal{D}\left(A\right)$, the larger
becomes $\mathcal{D}\left(A^{*}\right)$.“
\begin{align*}
B\subseteq\mathcal{D}\left(A\right) & \quad\Rightarrow\quad\mathcal{D}\left(\left(A\big|_{B}\right)^{*}\right)\supseteq\mathcal{D}\left(A^{*}\right)
\end{align*}


\emph{Difficulty:} Construct $\mathcal{D}\left(A\right)$ such that
$\mathcal{D}\left(A\right)=\mathcal{D}\left(A^{*}\right)$. (More
on this later in the lecture.)


\section{Heisenberg's uncertainty principle}

In quantum mechanics:\\
The Hilbert space for one dimensional problems is usually $H=L^{2}\left(\mathbb{R}\right)$.\\
The position operator is $x=:B$ and the momentum operator is $\frac{\hbar}{\ii}\frac{\dd}{\dd x}=:A$.
\begin{align*}
\left[A,B\right] & :=AB-BA=\frac{\hbar}{\ii}\mathbbm{1}
\end{align*}



\subsection{Theorem \textmd{(Winter-Wieland)}}

For two continuous operators $A$ and $B$ with $\left[A,B\right]=c\cdot\mathbbm{1}$
and $B^{n}=B$ for all $n\in\mathbb{N}_{\ge1}$, i.e. $B$ is idempotent,
follows $c=0$.


\subsubsection{Proof}

Consider:
\begin{align*}
B^{k}AB^{n-k} & =B^{k}\left(AB\right)B^{n-k-1}=B^{k}\left(BA+c\mathbbm{1}\right)B^{n-k-1}=B^{k+1}AB^{n-k-1}+cB^{n-1}
\end{align*}
\begin{align*}
\Rightarrow\quad cB^{n-1} & =B^{k}AB^{n-k}-B^{k+1}AB^{n-k-1}
\end{align*}
Sum this from $k=0$ to $k=n-1$:
\begin{align*}
ncB^{n-1} & =\sum_{k=0}^{n-1}B^{k}AB^{n-k}-B^{k+1}AB^{n-k-1}\sr ={\text{telescope}}{\text{sum}}AB^{n}-B^{n}A
\end{align*}
\begin{align*}
n\abs c\opnorm{B^{n-1}} & =\opnorm{AB^{n}-B^{n}A}\stackrel{\Delta\text{-inequality}}{\le}\norm{AB^{n}}+\norm{B^{n}A}\le\left(\norm{AB}+\norm{BA}\right)\cdot\norm{B^{n-1}}
\end{align*}
Since this must hold for all $n$ either $c=0$ or there exists a
$n\in\mathbb{N}_{>1}$ with $\norm{B^{n-1}}=0$, i.e. $B^{n-1}=0$.
Since $B$ is idempotent follows $B=0$ and therefore $\left[A,B\right]=0$
and also $c=0$.\qqed

Consider $u\in\mathcal{D}\left(A\right)$ with $\norm u=1$, which
represents a quantum mechanical state.\\
The expectation value of $A$ in $u$ is after the probabilistic interpretation:
\begin{align*}
E_{u}\left(A\right) & :=\left\langle u,Au\right\rangle 
\end{align*}
The “uncertainty”, i.e. the variance, is:
\begin{align*}
\Delta_{u}\left(A\right) & :=\norm{\left(A-E_{u}\left(A\right)\mathbbm{1}\right)u}
\end{align*}



\subsection{Theorem \textmd{(Heisenberg's uncertainty principle)}}

Let $H$ be a $\mathbb{C}$-Hilbert space and $A:\mathcal{D}\left(A\right)\to H$,
$B:\mathcal{D}\left(B\right)\to H$ be two symmetric operators with
$\overline{\mathcal{D}\left(A\right)}=H=\overline{\mathcal{D}\left(B\right)}$.
Assume for the image domains $\mathcal{R}$:
\begin{align*}
\mathcal{R}\left(A\right) & \subseteq\mathcal{D}\left(B\right) & \mathcal{R}\left(B\right) & \subseteq\mathcal{D}\left(A\right)
\end{align*}
So $\left[A,B\right]$ is well-defined on $\mathcal{D}\left(A\right)\cap\mathcal{D}\left(B\right)$.\\
Assume furthermore that $\left[A,B\right]=\frac{\hbar}{\ii}\mathbbm{1}$
with $\hbar>0$.

Then for all $u\in\mathcal{D}\left(A\right)\cap\mathcal{D}\left(B\right)$
with $\norm u=1$ holds:
\begin{align*}
\Delta_{u}\left(A\right)\cdot\Delta_{u}\left(B\right) & \ge\frac{\hbar}{2}
\end{align*}



\subsubsection{Proof}

Replace $A$ by $\tilde{A}:=A-E_{u}\left(A\right)\cdot\mathbbm{1}$
and $\tilde{B}:=B-E_{u}\left(B\right)\cdot\mathbbm{1}$. Then holds:
\begin{align*}
\left[\tilde{A},\tilde{B}\right] & =\frac{\hbar}{\ii}\mathbbm{1}
\end{align*}
\begin{align*}
\Delta_{u}\left(A\right) & =\norm{\tilde{A}u}\\
\Delta_{u}\left(B\right) & =\norm{\tilde{B}u}
\end{align*}
We have to show:
\begin{align*}
\Delta_{u}\left(A\right)\cdot\Delta_{u}\left(B\right)=\norm{\tilde{A}u}\cdot\norm{\tilde{B}u} & \ge\frac{\hbar}{2}
\end{align*}
\begin{align*}
\frac{\hbar}{2} & =\frac{\hbar}{2}\left\langle u,u\right\rangle =\frac{\ii}{2}\left\langle u,\left(\tilde{A}\tilde{B}-\tilde{B}\tilde{A}\right)u\right\rangle \stackrel{\text{symmetry}}{=}\frac{\ii}{2}\left(\left\langle \tilde{A}u,\tilde{B}u\right\rangle -\left\langle \tilde{B}u,\tilde{A}u\right\rangle \right)=\\
 & =-\text{Im}\left(\left\langle \tilde{A}u,\tilde{B}u\right\rangle \right)\sr{\le}{\text{Cauchy-Schwarz}}{}\norm{\tilde{A}u}\cdot\norm{\tilde{B}u}
\end{align*}
\qqed


\section{Spectrum and resolvent}

Let $A:\mathcal{D}\left(A\right)\to H$ be a closed, densely defined
operator.


\subsection{Definition \textmd{(continuously invertible, resolvent, spectrum)}}

$A$ is \emph{continuously invertible} if and only if $A:\mathcal{D}\left(A\right)\to H$
is bijective and $A^{-1}:H\to\mathcal{D}\left(A\right)$ is continuous.
\begin{align*}
\varrho\left(A\right) & :=\left\{ \lambda\in\mathbb{K}\big|\left(\lambda\mathbbm{1}-A\right)\text{ is continously invertible}\right\} 
\end{align*}
The \emph{resolvent} (\foreignlanguage{ngerman}{Resolvente}) is defined
for $\lambda\in\varrho\left(A\right)$ as
\begin{align*}
\mathcal{R}_{\lambda}\left(A\right) & =\left(\lambda\mathbbm{1}-A\right)^{-1}\in L\left(H\right)
\end{align*}
and the \emph{spectrum} of $A$ as:
\begin{align*}
\sigma\left(A\right) & =\mathbb{K}\setminus\varrho\left(A\right)
\end{align*}



\subsection{Lemma}

$\varrho\left(A\right)$ is open and $\sigma\left(A\right)$ is closed.


\subsubsection{Proof}

For bounded operators cf. Theorem \ref{sub:Thm-set-cont-invertible-->open}.

It's method works even for unbounded operators:

Take $\lambda,\mu\in\varrho\left(A\right)$.
\begin{align*}
\left(A-\mu\right) & =\left(A-\lambda\right)+\left(\lambda-\mu\right)=\\
 & =\underbrace{\left(A-\lambda\right)}_{\text{continuously invertible}}\cdot\left(\mathbbm{1}+\left(A-\lambda\right)^{-1}\left(\lambda-\mu\right)\right)
\end{align*}
$\mathbbm{1}+\left(A-\lambda\right)^{-1}\left(\lambda-\mu\right)$
is continuously invertible using the Neumann series if:
\begin{align*}
\abs{\lambda-\mu} & <\frac{1}{\opnorm{\left(A-\lambda\right)^{-1}}}
\end{align*}
So $\varrho\left(A\right)$ is open and therefore the complement $\sigma\left(A\right)$
is closed.\qqed


\subsection{Theorem \textmd{(resolvent equation)\label{sub:Thm-resolvent-equation}}}

The map $\lambda\mapsto\mathcal{R}_{\lambda}\left(A\right)$ is complex
analytic on $\varrho\left(A\right)$.

We have the \emph{resolvent equation} (\foreignlanguage{ngerman}{Resolventengleichung}):
\begin{align*}
\mathcal{R}_{\lambda}-\mathcal{R}_{\mu} & =-\left(\lambda-\mu\right)\mathcal{R}_{\lambda}\cdot\mathcal{R}_{\mu}
\end{align*}



\subsubsection{Proof}

Analogy with $\mathbb{C}$-numbers:
\begin{align*}
\frac{1}{\lambda-x}-\frac{1}{\mu-x} & =\frac{\mu-\lambda}{\left(\lambda-x\right)\left(\mu-x\right)}\\
\left(\mu-x\right)-\left(\lambda-x\right) & =\mu-\lambda
\end{align*}
Same thing for operators:
\begin{align*}
\left(\mu-A\right)-\left(\lambda-A\right) & =\mu-\lambda\\
\mathcal{R}_{\mu}^{-1}-\mathcal{R}_{\lambda}^{-1} & =\mu-\lambda\qquad/\mathcal{R}_{\mu}\cdot\quad/\cdot\mathcal{R}_{\lambda}\\
\mathcal{R}_{\lambda}-\mathcal{R}_{\mu} & =\left(\mu-\lambda\right)\mathcal{R}_{\mu}\mathcal{R}_{\lambda}\\
\mathcal{R}_{\lambda} & =\mathcal{R}_{\mu}+\left(\mu-\lambda\right)\mathcal{R}_{\mu}\mathcal{R}_{\lambda}
\end{align*}
Assume $\abs{\mu-\lambda}<\frac{1}{\opnorm{\mathcal{R}_{\lambda}}}$.
\begin{align*}
\mathcal{R}_{\mu} & =\mathcal{R}_{\lambda}\left(1+\left(\mu-\lambda\right)\mathcal{R}_{\lambda}\right)^{-1}=\mathcal{R}_{\lambda}\sum_{n=0}^{\infty}\left(-1\right)^{n}\left(\mu-\lambda\right)^{n}\mathcal{R}_{\lambda}
\end{align*}
This series converges absolutely and so the map is analytic in $L\left(H\right)$.\qqed

%DATE: Fr 23.11.12
%Prof. Finster vertreten durch Dr. Müller


\chapter{Compact Operators}

Let $E$ and $F$ be Banach spaces and $A\in L\left(E,F\right)$.
\begin{description}
\item [{Remember:}] There exists a $C\in\mathbb{R}_{>0}$ such that for
all $u\in E$ holds:
\begin{align*}
\norm{Au} & \le C\norm u
\end{align*}
$A$ maps bounded sets in $E$ to bounded sets in $F$.
\item [{But:}] Bounded sets are not precompact in general.
\end{description}

\section{Definition \textmd{(compact operator)}}

$A$ is called \emph{compact} operator if and only if $A$ maps bounded
sets to relatively compact sets, i.e. the closure is compact.\\
(In complete spaces relatively compact is equivalent to precompact.)


\section{Example \textmd{(integral operator)}}

Let $E=\left(C^{0}\left(\left[0,1\right]\right),\norm ._{\infty}\right)$
and consider an integral kernel $K\in C^{0}\left(\left[0,1\right]\times\left[0,1\right]\right)$,
$K:E\to E$.
\begin{align*}
\left(K\varphi\right)\left(x\right) & :=\int_{0}^{1}K\left(x,y\right)\varphi\left(y\right)\dd y
\end{align*}
\begin{align*}
\abs{\left(K\varphi\right)\left(x\right)} & \le\sup_{y}\abs{K\left(x,y\right)}\norm{\varphi}\qquad/\sup_{x}\\
\norm{K\varphi} & \le C\norm{\varphi}
\end{align*}
So $K\in L\left(E\right)$. Furthermore the integral kernel $K$ is
continuous and defined on a compact set. Therefore $K$ is uniformly
continuous after the Heine-Cantor theorem.
\begin{align*}
\fall_{\varepsilon\in\mathbb{R}_{>0}}\exs_{\delta\in\mathbb{R}_{>0}}:\abs{K\left(x,y\right)-K\left(x',y\right)} & <\varepsilon\qquad\fall_{\abs{x-x'}<\delta,\ y\in\left[0,1\right]}
\end{align*}
\begin{align*}
\abs{\left(K\varphi\right)\left(x\right)-\left(K\varphi\right)\left(x'\right)} & =\abs{\int_{0}^{1}\left(K\left(x,y\right)-K\left(x',y\right)\right)\varphi\left(y\right)\dd y}\le\varepsilon\norm{\varphi}_{\infty}
\end{align*}
Let now $B:=B_{M}\left(0\right)$ with $M\in\mathbb{R}_{>0}$. Then
$K\left(B\right)\subseteq E$.
\begin{itemize}
\item uniformly bounded $\left(\norm{\varphi}<CM\right)$
\item uniformly continuous
\end{itemize}
The Arzelà-Ascoli theorem yields, that $K\left(B\right)$ is precompact
and so $K$ is a compact operator.


\section{Theorem}

Let $H$ be a Hilbert space.\\
A compact operator $A:H\to H$ maps weakly convergent sequences to
convergent sequences.


\subsubsection*{Proof}

Let $x_{n}\rightharpoondown x$, then $\left(x_{n}\right)$ is bounded,
i.e. there is a $C\in\mathbb{R}_{>0}$ such that $\norm{x_{n}}<C$
for all $n\in\mathbb{N}$. Define $y_{n}:=Ax_{n}$. For all $z\in H$
holds:
\begin{align*}
\left\langle z,y_{n}-y\right\rangle  & =\left\langle z,A\left(x_{n}-x\right)\right\rangle =\left\langle A^{*}z,x_{n}-x\right\rangle \to0
\end{align*}
Therefore $y_{n}\rightharpoondown y$ converges weakly. Because $A$
is compact, every subsequence of $y_{n}$ contains a convergent subsequence
with limes $\tilde{y}$. For $z=\tilde{y}-y$ converges:
\begin{align*}
0\leftarrow\left\langle z,y_{n}-y\right\rangle  & \to\left\langle \tilde{y}-y,\tilde{y}-y\right\rangle =\norm{\tilde{y}-y}
\end{align*}
Therefore $\tilde{y}=y$.\\
Since this holds for every subsequence of $y_{n}$ follows $y_{n}\to y$.\qqed


\section{Lemma}

Consider operators $A,B:E\to F$.
\begin{enumerate}[label=\roman*)]
\item If $A$ and $B$ are compact, so are $A+B$ and $\lambda A$ for
all $\lambda\in\mathbb{K}$.
\item If $A:E\to F$ is compact (continuous) and $B:F\to E$ continuous
(compact), than $B\circ A$ is compact.\\
(In particular $A^{n}$ is compact for $A:E\to E$.)
\item The compact operators form a closed subspace of $L\left(E,F\right)$.
\end{enumerate}

\subsubsection{Proof}
\begin{enumerate}[label=\roman*)]
\item is obvious.\qqed[\roman{enumi})]
\item follows, since a continuous operator is bounded.\qqed[\roman{enumi})]
\item Let $\left(x_{n}\right)$ be bounded and $T_{k}$ a convergent sequence
of compact operators. By diagonal choice get a subsequence, also written
$x_{n}$, such that $T_{k}x_{n}$ converges for all $k\in\mathbb{N}$.
\begin{align*}
\norm{Tx_{n}-Tx_{m}} & \le\underbrace{\norm{Tx_{n}-T_{k}x_{n}}}_{\le\norm{T-T_{k}}\cdot\norm{x_{n}}}+\norm{T_{k}x_{n}-T_{k}x_{m}}+\underbrace{\norm{T_{k}x_{m}-Tx_{m}}}_{\le\norm{T-T_{k}}\cdot\norm{x_{m}}}\le\\
 & \le\norm{T-T_{k}}\cdot\norm{x_{n}}+\norm{T_{k}x_{n}-T_{k}x_{m}}+\norm{T-T_{k}}\cdot\norm{x_{m}}\xrightarrow{n,m,k\to\infty}0
\end{align*}
\qqed
\end{enumerate}

\section{Lemma \textmd{(Fredholm operator)}\label{sec:Lem-Ker-Im}}

Let $A:E\to E$ be compact and define $T:=\mathbbm{1}-A$. $T$ is
called \emph{Fredholm operator}.
\begin{enumerate}[label=\roman*)]
\item $\text{ker}\left(T\right)$ is finite-dimensional.
\item There exists a $i\in\mathbb{N}$ such that $\text{ker}\left(T^{k}\right)=\text{ker}\left(T^{i}\right)$
for all $k\in\mathbb{N}_{>i}$.
\item The image of $T$ is closed.
\end{enumerate}

\subsubsection*{Proof}
\begin{enumerate}[label=\roman*)]
\item $\text{ker}\left(T\right)=:Z=\left\{ u\big|u=Au\right\} $. Since
$Z\cap B_{1}\left(0\right)$ is bounded
\begin{align*}
A\left(Z\cap B_{1}\left(0\right)\right) & =Z\cap B_{1}\left(0\right)
\end{align*}
is precompact and therefore $Z$ is finite-dimensional.\qqed[\roman{enumi})]
\item Define $N_{i}:=\text{ker}\left(T^{i}\right)$, which are closed subspaces
of $E$, since the $T^{i}$ are continuous.\\
Suppose the claim is wrong, then $N_{j}\subsetneq N_{j+1}\subsetneq\ldots$,
so in particular all $N_{j}$ are proper subspaces. Choose $y_{j}\in N_{j}$
with:
\begin{align*}
\norm{y_{j}} & =1 & d\left(y_{j},N_{j-1}\right) & >\frac{1}{2}
\end{align*}
This is possible after Lemma \ref{sub:Lem-d>0.5}.\\
For all $m<n$ holds:
\begin{align*}
Ay_{n}-Ay_{m} & =y_{n}-\underbrace{T_{y_{n}}-y_{m}+T_{y_{m}}}_{\in N_{n-1}}
\end{align*}
Therefore follows:
\begin{align*}
\norm{Ay_{n}-Ay_{m}} & >\frac{1}{2}
\end{align*}
So $\left(Ay_{n}\right)$ has no accumulation value in contradiction
to the compactness of $A$.\qqed[\roman{enumi})]
\item Let $y_{k}\in\text{im}\left(T\right)$ with $y_{k}\to y$ and $y_{k}=Tx_{k}$.
We want to show $y\in\text{im}\left(T\right)$. Define:
\begin{align*}
d_{k} & :=d\left(x_{k},\text{ker}\left(T\right)\right)=\inf_{z\in\text{ker}\left(T\right)}\norm{x_{k}-z}
\end{align*}


\begin{description}
\item [{Claim:}] $\left(d_{k}\right)$ is bounded. Equivalently $\left(D_{k}\right)=\abs{\max\left\{ 1,d_{k}\right\} }$
is bounded.
\item [{Proof:}] Choose $z_{k}\in\text{ker}\left(T\right)$, $w_{k}:=x_{k}-z_{k}$
with $\norm{w_{k}}<2d_{k}$ and $Tw_{k}=y_{k}$.\\
Assume $D_{k}$ is unbounded. Since $y_{k}$ is convergent and thus
bounded, follows:
\begin{align*}
T\left(\frac{w_{k}}{D_{k}}\right) & =\frac{y_{k}}{D_{k}}\xrightarrow{k\to\infty}0
\end{align*}
Now consider $u_{k}:=\frac{w_{k}}{D_{k}}$. We know $\norm{u_{k}}<2$
and $T\left(u_{k}\right)\to0$.\\
Thus $u_{k}-Au_{k}\to0$. Since $A$ is compact, every subsequence
of $Au_{k}$ has a convergent subsequence, and therefore $u_{k}\to0$
converges.\\
The continuity of $T$ gives:
\begin{align*}
T\left(u\right) & =\lim_{k\to\infty}T\left(u_{k}\right)=0
\end{align*}
So $u\in\text{ker}\left(T\right)$.\\
On the other hand we have for all $z\in\text{ker}\left(T\right)$:
\begin{align*}
\norm{w_{k}-z} & \ge D_{k}\\
\Rightarrow\quad\norm{u_{k}-\frac{z}{D_{k}}} & \ge1
\end{align*}
Since $T$ is a subspace this means, that for all $z\in\text{ker}\left(T\right)$
holds:
\begin{align*}
\norm{u_{k}-z} & \ge1
\end{align*}
This is a contradiction to $u\in\text{ker}\left(T\right)$.\qqed[Claim]
\end{description}

So $u_{k}$ is bounded and $T\left(w_{k}\right)=T\left(x_{k}\right)=y_{k}\to y$.
So we get:
\begin{align*}
w_{k}-Aw_{k} & \to y
\end{align*}
Since $A$ is compact $Aw_{k}$ converges and with this follows, that
$w_{k}\to w$ also converges.\\
By continuity we get:
\begin{align*}
T\left(w\right) & =\lim_{k\to\infty}T\left(w_{k}\right)=y
\end{align*}
So $w\in\text{im}\left(T\right)$.\qqed

\end{enumerate}

\section{Theorem \textmd{(Fredholm Alternative)\label{sec:Thm-Fredholm-Alternative}}}

Let $A:E\to E$ be compact and define $T:=\mathbbm{1}-A$.\\
If the kernel $\ker\left(T\right)=\left\{ 0\right\} $ is trivial,
then $T$ is continuously invertible.


\subsubsection*{Proof}

$\text{ker}\left(T\right)=\left\{ 0\right\} $ means, that $T$ is
injective. We only need to show, that $T$ is surjective, because
then $T$ is invertible and \ref{sub:Thm-Open-mapping} yields then,
that $T$ is open and therefore $T^{-1}$ continuous.

$\text{im}\left(T\right)$ is closed following \ref{sec:Lem-Ker-Im}
iii).\\
$\text{im}\left(T\right)=E$, since otherwise $T\left(E\right)\subsetneq E$.
Then the injectivity implies for all $k\in\mathbb{N}$:
\begin{align*}
T^{k+1}\left(E\right) & \subsetneq\underbrace{T^{k}\left(E\right)}_{=E_{k}}
\end{align*}
$E_{k}$ is closed for all $k\in\mathbb{N}$:
\begin{align*}
E_{k} & =\left(\mathbbm{1}-A\right)^{k}\left(E\right)=\bigg(\mathbbm{1}+\underbrace{\sum_{l=1}^{k}\left(-1\right)^{l}\left(\begin{array}{c}
k\\
l
\end{array}\right)A^{l}}_{A:=A_{k}}\bigg)\left(E\right)
\end{align*}
Now $A_{k}$ is compact, as the compact operators form a (closed)
ideal subalgebra $\text{CP}\left(E\right)$.\\
Choose $x_{k}\in E_{k}$ with $\norm{x_{k}}=1$ and $d\left(x_{k},E_{k}\right)>\frac{1}{2}$,
which is possible after Lemma \ref{sub:Lem-d>0.5}. Then holds for
all $m<n$:
\begin{align*}
Ax_{m}-Ax_{n} & =x_{m}-\underbrace{Tx_{m}-x_{n}+Tx_{n}}_{\in H_{m+1}}
\end{align*}
\begin{align*}
\Rightarrow\quad\norm{Ax_{m}-Ax_{n}} & >\frac{1}{2}
\end{align*}
This is a contradiction to the compactness of $A$.\\
Therefore $T$ is surjective and the theorem follows.\qqed


\section{Theorem \textmd{(Riesz-Schauder)}}

Let $A\in L\left(H\right)$ be compact.
\begin{enumerate}[label=\roman*)]
\item $\sigma\left(A\right)$ consists of a a finite or countable set of
complex numbers and $0$ is the only possible accumulation point.
\item Every $0\not=\lambda\in\sigma\left(A\right)$ is an eigenvalue of
finite multiplicity, i.e. $\text{ker}\left(A-\lambda\right)$ is finite-dimensional.
That means, there exists a $i\in\mathbb{N}$ such that for all $k>i$
holds:
\begin{align*}
\text{ker}\left(A-\lambda\right)^{k} & =\text{ker}\left(A-\lambda\right)^{i}
\end{align*}
One says also that the Jordan chains are finite.
\end{enumerate}

\subsubsection*{Proof}
\begin{enumerate}
\item [ii)]is an immediate consequence of the Lemmas \ref{sec:Lem-Ker-Im}
and \ref{sec:Thm-Fredholm-Alternative}. (Divide $A$ by $\lambda$.)
\item [i)]Assume $\lambda_{n}\not=0$ are pairwise different eigenvalues.
Choose eigenvectors $x_{n}\in H$ such that:
\begin{align*}
Ax_{n} & =\lambda_{n}x_{n}
\end{align*}
\begin{align*}
Y_{n} & :=\left\langle x_{1},\ldots,x_{n}\right\rangle 
\end{align*}
Since the eigenvalues are pairwise different $Y_{n}\subsetneq Y_{n+1}$
must hold, because the $x_{k}$ are linearly independent.\\
Assume $Y_{n}\subsetneq H$, since otherwise $H$ would be finite-dimensional
and therefore $\sigma\left(A\right)$ a finite set.\\
So following Lemma \ref{sub:Lem-d>0.5} we can choose $y_{n}\in Y_{n}$
with $\norm{y_{n}}=1$ and:
\begin{align*}
d\left(y_{n},Y_{n+1}\right) & >\frac{1}{2}
\end{align*}
Since $y_{n}\in Y_{n}$ one can find $\alpha_{j}\in\mathbb{K}$ such
that:
\begin{align*}
y_{n} & =\sum_{j}\alpha_{j}x_{j}
\end{align*}
Then follows:
\begin{align*}
\left(A-\lambda_{n}\right)y_{n} & =\sum_{i=1}^{n-1}\left(\lambda_{j}-\lambda_{n}\right)\alpha_{j}x_{j}=:\tilde{y}_{n}\in Y_{n-1}
\end{align*}
For all $n>m$ holds:
\begin{align*}
Ay_{n}-Ay_{m} & =\lambda_{n}y_{n}-\underbrace{\tilde{y}_{n}-Ay_{m}}_{\in Y_{n-1}}
\end{align*}
So we get:
\begin{align*}
\norm{Ay_{n}-Ay_{m}} & \ge\frac{\abs{\lambda_{n}}}{2}
\end{align*}
But $\left(Ay_{n}\right)$ is precompact and thus for all $\delta\in\mathbb{R}_{>0}$
exist only finitely many $\lambda_{n}$ with $\abs{\lambda_{n}}>\delta$.\\
Therefore 0 is the only accumulation point and $\sigma\left(A\right)$
is a countable union of finite sets and thus countable.\qqed
\end{enumerate}
%DATE: Do 29.11.12

Jordan decomposition:
\begin{align*}
A & =\left(\begin{array}{ccccccc}
\lambda_{1} &  &  &  &  &  & 0\\
1 & \ddots\\
 & 1 & \lambda_{1}\\
 &  &  & \lambda_{2}\\
 &  &  & 1 & \ddots\\
 &  &  &  & 1 & \lambda_{2}\\
0 &  &  &  &  &  & \ddots
\end{array}\right)
\end{align*}
\begin{align*}
\lambda_{1}-A & =\left(\begin{array}{ccccccc}
0 &  &  &  &  &  & 0\\
-1 & \ddots\\
 & -1 & 0\\
 &  &  & -\lambda_{2}\\
 &  &  & -1 & \ddots\\
 &  &  &  & -1 & -\lambda_{2}\\
0 &  &  &  &  &  & \ddots
\end{array}\right)
\end{align*}
So the first block is nilpotent. If it has $k$ dimensions this means:
\begin{align*}
\left(\lambda_{1}-A\right)^{k} & =\left(\begin{array}{ccc}
0 &  & 0\\
 & *\\
0 &  & *
\end{array}\right)
\end{align*}
So $k$ is the length of the Jordan chain.


\section{Theorem\label{sec:Thm-compact-operator-approximation}}

Let $A\in L\left(H\right)$ be compact and $H$ be a separable Hilbert
space.\\
Then $A$ can be approximated in $L\left(H\right)$ by operators of
finite rank.


\subsubsection{Proof}

Choose a countable orthonormal Hilbert basis $\left(\varphi_{j}\right)_{j\in\mathbb{N}}$
of $H$, which is possible, since $H$ is separable. Define:
\begin{align*}
\lambda_{n} & :=\sup_{\psi\in\left\langle \varphi_{1},\ldots,\varphi_{n}\right\rangle ^{\perp},\norm{\psi}=1}\norm{A\psi}
\end{align*}
Since $A$ is bounded, this supremum exists. Obviously $\lambda_{1}\ge\lambda_{2}\ge\ldots$.
Thus $\lambda_{n}\searrow\lambda\ge0$.
\begin{description}
\item [{Claim:}] $\lambda=0$
\item [{Proof:}] Choose $\psi_{n}\in\left\langle \varphi_{1},\ldots,\varphi_{n}\right\rangle ^{\perp}$
with $\norm{\psi_{n}}=1$ and $\norm{A\psi_{n}}\ge\frac{\lambda}{2}$
which is possible after Lemma \ref{sub:Lem-d>0.5}, since $\left\langle \varphi_{1},\ldots,\varphi_{n}\right\rangle $
is a proper closed subspace of $H$. Write:
\begin{align*}
\psi_{n} & =\sum_{j=1}^{\infty}\nu_{j}\varphi_{j}=\left(\nu_{1},\nu_{2},\ldots\right)
\end{align*}
Due to $\psi_{n}\in\left\langle \varphi_{1},\ldots,\varphi_{n}\right\rangle ^{\perp}$
follows:
\begin{align*}
\psi_{n} & =\left(0,\ldots0,\nu_{n+1},\nu_{n+2},\ldots\right)
\end{align*}
For $u\in H$ holds:
\begin{align*}
\left\langle u,\psi_{n}\right\rangle  & =\sum_{j=n+1}^{\infty}\nu_{j}\cdot\overline{u}_{j}\sr{\le}{\text{Schwarz }}{\text{inequality}}\underbrace{\left(\sum_{j=n+1}^{\infty}\abs{\nu_{j}}^{2}\right)^{\frac{1}{2}}}_{=\norm{\psi_{n}}}\cdot\left(\sum_{j=n+1}^{\infty}\abs{u_{j}}^{2}\right)^{\frac{1}{2}}\xrightarrow{n\to\infty}0
\end{align*}
So by construction $\psi_{n}\rightharpoondown0$. Therefore $A\psi_{n}\to0$
and thus $\norm{A\lambda_{n}}\to0$.\\
On the other hand we have $\norm{A\psi_{n}}\ge\frac{\lambda}{2}$
and so $\lambda=0$.\qqed[Claim]
\end{description}
Let $P_{n}$ be the orthogonal projection on $\left\langle \varphi_{1},\ldots,\varphi_{n}\right\rangle $.
\begin{align*}
P_{n}u & =\sum_{j=1}^{n}\varphi_{j}\left\langle \varphi_{j},u\right\rangle 
\end{align*}
$AP_{n}$ is an operator of finite rank $r\le n$, since $\text{rank}\left(P_{n}\right)=n$.
\begin{description}
\item [{Claim:}] $AP_{n}\xrightarrow{n\to\infty}A$ in $L\left(H\right)$.
\item [{Proof:}] Consider:
\begin{align*}
\opnorm{A-AP_{n}} & =\sup_{u\in H,\,\norm u=1}\norm{A\left(\mathbbm{1}-P_{n}\right)u}
\end{align*}
$\left(\mathbbm{1}-P_{n}\right)u\in\left\langle \varphi_{1},\ldots,\varphi_{n}\right\rangle ^{\perp}$
and $\norm{\left(\mathbbm{1}-P_{n}\right)u}\le\norm u=1$. ($\mathbbm{1}-P_{n}=P_{\left\langle \varphi_{1},\ldots,\varphi_{n}\right\rangle ^{\perp}}$)\\
Thus we get:
\begin{align*}
\opnorm{A-AP_{n}} & \le\sup_{v\in\left\langle \varphi_{1},\ldots,\varphi_{n}\right\rangle ^{\perp},\,\norm v\le1}\norm{Av}=\lambda_{n}\xrightarrow{n\to\infty}0
\end{align*}
\qqed[Claim]
\end{description}
\qqed


\section{Lemma}

Let $A\in L\left(H\right)$ be compact and symmetric. (This implies
that $A$ is bounded and self-adjoint.)\\
Then $\sigma\left(A\right)\subseteq\mathbb{R}$ and if $u$ is an
eigenvector, $Au=\lambda u$, then its orthogonal is invariant under
$A$.


\subsubsection*{Proof}

For $\lambda\in\sigma\left(A\right)$ holds $\text{ker}\left(A-\lambda\right)\not=\left\{ 0\right\} $.
Thus there exists a $u\in\text{ker}\left(\lambda-A\right)\setminus\left\{ 0\right\} $.
\begin{align*}
\lambda\left\langle u,u\right\rangle  & =\left\langle u,Au\right\rangle =\left\langle Au,u\right\rangle =\overline{\lambda}\left\langle u,u\right\rangle 
\end{align*}
Since $\norm u\not=0$ follows $\lambda=\overline{\lambda}$, which
means that $\lambda\in\mathbb{R}$.\\
For $v\in\left\langle u\right\rangle ^{\perp}$ holds:
\begin{align*}
\left\langle Av,u\right\rangle  & =\left\langle v,Au\right\rangle =\lambda\left\langle v,u\right\rangle =0
\end{align*}
Therefore $Av\in\left\langle u\right\rangle ^{\perp}$.\qqed


\section{Theorem \textmd{(Hilbert-Schmidt)\label{sec:Thm-Hilbert-Schmidt}}}

Let $A\in L\left(H\right)$ be a symmetric compact operator on the
separable Hilbert space $H$.\\
Then there exists an orthonormal Hilbert space basis of eigenvectors
$\left(u_{n}\right)_{n\in\mathbb{N}}$, so with the eigenvalues $\lambda_{n}\in\mathbb{R}$
holds:
\begin{align*}
Au_{n} & =\lambda_{n}u_{n}
\end{align*}



\subsubsection*{Proof}

$\sigma\left(A\right)$ is countable and therefore we can write $\sigma\left(A\right)\setminus\left\{ 0\right\} =\left\{ \lambda_{1},\lambda_{2},\ldots\right\} \subseteq\mathbb{R}$
with $\lambda_{i}\not=\lambda_{j}$ for $i\not=j$. $\text{ker}\left(\lambda_{j}-A\right)$
is finite-dimensional. So we choose a (finite) orthonormal basis of
the eigenspace. Taking these eigenvectors for all eigenvalues, we
obtain a countable orthonormal system $\left(u_{n}\right)_{n\in\mathbb{N}}$.
\begin{align*}
M & :=\overline{\left\langle u_{n}\right\rangle }\stackrel{\text{closed}}{\subseteq}H
\end{align*}
$M^{\perp}$ is an invariant subspace of $H$ under $A$, i.e.:
\begin{align*}
\tilde{A}:=A\big|_{M^{\perp}}:M^{\perp} & \to M^{\perp}
\end{align*}
This is again symmetric and compact. We know that $\sigma\left(\tilde{A}\right)=\left\{ 0\right\} $.
\begin{description}
\item [{Question:}] Why is $\tilde{A}=0$?\\
This is not true for a general operator, e.g.:
\begin{align*}
A & =\left(\begin{array}{cc}
0 & 0\\
1 & 0
\end{array}\right) & \sigma\left(A\right) & =\left\{ 0\right\} 
\end{align*}

\item [{Answer:}] If $A$ is symmetric and $\sigma\left(A\right)=\left\{ 0\right\} $,
then one can show $A=0$ using the following theorem \ref{sec:Thm-SpectralRadiusFinite}:\\
From $\sigma\left(\tilde{A}\right)=0$ follows $r\left(\tilde{A}\right)=0$
and since $\tilde{A}$ is self-adjoint theorem \ref{sec:Thm-SpectralRadiusFinite}
gives $\norm{\tilde{A}}=0$ and thus $\tilde{A}=0$. In other words
$A\big|_{M^{\perp}}=0$.\\
Now choose an orthonormal Hilbert basis $\left(v_{n}\right)_{n\in\mathbb{N}_{\le N}}$
of $M^{\perp}$ for an $N\in\mathbb{N}\cup\left\{ \infty\right\} $.
Therefore $\left\{ u_{n}\right\} \cup\left\{ v_{n}\right\} $ is the
desired orthonormal Hilbert basis of $H$.\qqed
\end{description}

\section{Definition \textmd{(spectral radius)}}

Let $A:\mathcal{D}\left(A\right)\subset H\to H$ be a densely defined
operator. Then the \emph{spectral radius} $r\left(A\right)$ of $A$
is defined by:
\begin{align*}
r\left(A\right) & =\sup_{\lambda\in\sigma\left(A\right)}\abs{\lambda}\in\mathbb{R}_{\ge0}\cup\left\{ \infty\right\} 
\end{align*}
\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[arr/.style={decoration={markings,mark=at position 1 with {\arrow[thick]{>}}},postaction={decorate}}]
\draw (0,0) circle (3);
\draw plot[smooth cycle,tension=.7,scale=2.85] coordinates{(0,-1) (0.5,-0.3) (1,0) (0.5,0.8) (0,1) (-0.3,0.3) (-1,0)};
\node at (0.5,1) {$\sigma(A)$};
\draw[arr] (0,0) -- node [below]{$r(A)$} (-3,0);
\end{tikzpicture}\caption{$\sigma\left(A\right)\subseteq\overline{B_{r\left(A\right)}\left(0\right)}$}
\end{figure}



\section{Theorem\label{sec:Thm-SpectralRadiusFinite}}

For $A\in L\left(H\right)$ holds:
\begin{align*}
r\left(A\right) & =\limsup_{n\to\infty}\opnorm{A^{n}}^{\frac{1}{n}}
\end{align*}
If $A$ is symmetric, then:
\begin{align*}
r\left(A\right) & =\opnorm A
\end{align*}



\subsubsection*{Proof}

%DATE: Fr 30.11.12

Recall for a power series
\begin{align*}
\sum_{n=0}^{\infty}a_{n}z^{n}
\end{align*}
with $a_{n},z\in\mathbb{K}$ the root test (\foreignlanguage{ngerman}{Wurzelkriterium}):
\begin{itemize}
\item If
\begin{align*}
\limsup_{n\to\infty}\abs{a_{n}z^{n}}^{\frac{1}{n}} & =:c<1
\end{align*}
then $\abs{a_{n}z^{n}}<c^{n}$ and therefore is
\begin{align*}
\sum_{n=0}^{\infty}c^{n}
\end{align*}
a convergent dominating sequence. Thus $\sum_{n=0}^{\infty}a_{n}z^{n}$
converges as well.
\item If
\begin{align*}
\limsup_{n\to\infty}\abs{a_{n}z^{n}}^{\frac{1}{n}} & =:c>1
\end{align*}
then $\abs{a_{n}z^{n}}>c^{n}>1$ for an infinite number of $n$. Therefore
$a_{n}z^{n}$ does \emph{not} converge to zero, which implies that
$\sum_{n=0}^{\infty}a_{n}z^{n}$ does not converge as well.
\item If
\begin{align*}
\limsup_{n\to\infty}\abs{a_{n}z^{n}}^{\frac{1}{n}} & =1
\end{align*}
no conclusion is possible.
\end{itemize}
\begin{align*}
\limsup_{n\to\infty}\abs{a_{n}z^{n}}^{\frac{1}{n}} & =\abs z\cdot\limsup_{n\to\infty}\abs{a_{n}}^{\frac{1}{n}}
\end{align*}
The Radius of convergence (\foreignlanguage{ngerman}{Konvergenzradius})
is thus defined by:
\begin{align*}
R & :=\frac{1}{\limsup_{n\to\infty}\abs{a_{n}}^{\frac{1}{n}}}
\end{align*}
If $\abs z<R$ the sum converges absolutely and if $\abs z>R$ the
sum diverges.\\
In our setting for $A=0$ is nothing to prove. For $\lambda\in\varrho\left(A\right)\setminus\left\{ 0\right\} $
we make a formal expansion:
\begin{align*}
\mathcal{R}_{\lambda} & =\left(\lambda-A\right)^{-1}=\frac{1}{\lambda}\left(\mathbbm{1}-\frac{A}{\lambda}\right)^{-1}=\frac{1}{\lambda}\sum_{n=0}^{\infty}A^{n}\cdot\left(\frac{1}{\lambda}\right)^{n}
\end{align*}
This is a power series in $\frac{1}{\lambda}$, but the coefficients
are operators.
\begin{align*}
R & :=\frac{1}{\limsup_{n\to\infty}\opnorm{A^{n}}^{\frac{1}{n}}}
\end{align*}
For $\frac{1}{\abs{\lambda}}<R$
\begin{align*}
\opnorm{\sum_{n=0}^{\infty}A^{n}\left(\frac{1}{\lambda}\right)^{n}} & \le\sum_{n=0}^{\infty}\opnorm{A^{n}}\frac{1}{\lambda^{n}}
\end{align*}
converges absolutely and so
\begin{align*}
\sum_{n=0}^{\infty}A^{n}\left(\frac{1}{\lambda}\right)^{n}
\end{align*}
converges in $L\left(H\right)$. Thus the resolvent 
\begin{align*}
\mathcal{R}_{\lambda} & =\left(\lambda-A\right)^{-1}
\end{align*}
exists and $\sigma\left(A\right)\subseteq\overline{B_{\frac{1}{R}}\left(0\right)}$,
i.e.:
\begin{align*}
r\left(A\right) & \le\frac{1}{R}=\limsup_{n\to\infty}\opnorm{A^{n}}^{\frac{1}{n}}
\end{align*}
If $\frac{1}{\abs{\lambda}}>R$
\begin{align*}
\opnorm{\sum_{n=0}^{\infty}A^{n}\left(\frac{1}{\lambda}\right)^{n}}
\end{align*}
diverges.

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[arr/.style={decoration={markings,mark=at position 1 with {\arrow[thick]{>}}},postaction={decorate}}]
  \draw (0,0) circle (3);
  \draw[arr] (0,0) -- node [below]{$r(A)$} (-3,0);
  \draw (0,0) circle (5);
  \draw[arr] (0,0) -- node [left]{$\frac{1}{R}$} (0,-5);
  \draw[yshift=60,xshift=33] plot[smooth cycle,tension=.7,scale=2.85] coordinates{(0,-0.8) (0.5,-0.3) (0.2,0) (-0.3,0.1) (-1,0)};
  \node at (0.7,1) {$\sigma(A)$};
  \draw (0.7,4) node[below]{$\lambda$} circle (0.7);
  \draw (0.7,4) +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (0.7,4) -- node[above]{$\delta$} (0,4);
  \draw (0,0) +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw (1,4.1) node[above]{$\nu$} +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
\end{tikzpicture}\caption{$\frac{1}{R}>r\left(A\right)$ ?}
\end{figure}
Why is $r$ not smaller than $\frac{1}{R}$?\\
Assume that $r<\frac{1}{R}$ and choose $\lambda$ with $r<\abs{\lambda}<\frac{1}{R}$.
Then $\mathcal{R}_{\lambda}$ exists and is analytic. Consider a $\nu\in B_{\delta}\left(\lambda\right)$.
\begin{align*}
\mathcal{R}_{\nu} & =\left(\nu-A\right)^{-1}=\left(\left(\nu-\lambda\right)+\left(\lambda-A\right)\right)^{-1}=\\
 & =\left(\left(\left(\nu-\lambda\right)\mathcal{R}_{\lambda}+\mathbbm{1}\right)\left(\lambda-A\right)\right)^{-1}=\\
 & =\mathcal{R}_{\lambda}\left(\mathbbm{1}+\left(\nu-\lambda\right)\mathcal{R}_{\lambda}\right)^{-1}=\\
 & =\mathcal{R}_{\lambda}\sum_{n=0}^{\infty}\left(-\left(\nu-\lambda\right)\right)^{n}\mathcal{R}_{\lambda}^{n}
\end{align*}
For $\abs{\nu-\lambda}<\delta:=\frac{1}{\opnorm{\mathcal{R}_{\lambda}}}$
the Neumann series converges.\\
Thus $\mathcal{R}_{\lambda}$ can be expanded locally in a power series,
i.e. $\mathcal{R}_{\lambda}$ is complex analytic or holomorphic.\\
Furthermore for $\abs{\lambda}>\frac{1}{R}$ holds: 
\begin{align*}
\mathcal{R}_{\lambda} & =\sum_{n=0}^{\infty}A^{n}\frac{1}{\lambda^{n+1}}
\end{align*}


\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[arr/.style={decoration={markings,mark=at position 1 with {\arrow[thick]{>}}},postaction={decorate}}]
  \draw (0,0) circle (3.5);
  \draw (0,0) circle (2.33);
  \draw[arr] (0,0) -- node[left]{r(A)} (0,-2.33);
  \draw[arr] (0,0) -- node [below]{$\frac{1}{R}$} (-3.5,0);
  \draw[yshift=33,xshift=23] plot[smooth cycle,tension=.7,scale=2.85] coordinates{(-0.1,-0.8) (0.5,-0.3) (0.2,0) (-0.3,0.1) (-0.9,-0.1)};
  \node at (0.7,1) {$\sigma(A)$};
  \draw (0,0) +(-0.1,-0.1) -- +(0.1,0.1) +(0.1,-0.1) -- +(-0.1,0.1);
  \draw[red,thick] (0,0) circle (3) node[above=86]{$\Gamma$};
  \draw[red,thick,arr] (0,3) -- (-0.1,3);
  \draw[thick] (0,0) circle (4) node[above=115]{$C$};
  \draw[thick,arr] (0,4) -- (-0.1,4);
  \draw[red] (2.25,0.5) -- node[above]{$\delta$} (2.92,0.65);
\end{tikzpicture}\caption{Contours $\Gamma$ and $C$ for integration}
\end{figure}


Integrate along the contour $C$:
\begin{align*}
\frac{1}{2\pi\ii}\oint_{C}\lambda^{n}\mathcal{R}_{\lambda}\dd\lambda & =\sum_{k=0}^{\infty}A^{k}\underbrace{\frac{1}{2\pi\ii}\oint_{C}\frac{\lambda^{n}}{\lambda^{k+1}}\dd\lambda}_{=:I}
\end{align*}
Since the geometric series converges absolutely, the summation and
the integration can be interchanged. The residue theorem gives:
\begin{alignat*}{1}
I & =\begin{cases}
1 & \text{if }k=n\\
0 & \text{otherwise}
\end{cases}
\end{alignat*}
Therefore we get:
\begin{align*}
\frac{1}{2\pi\ii}\oint_{C}\lambda^{n}\mathcal{R}_{\lambda}\dd\lambda & =A^{n}
\end{align*}
Choose $\Gamma=\partial B_{r+\delta}\left(0\right)$. We know, that
$\mathcal{R}_{\lambda}$ is holomorphic outside $\Gamma$. Thus we
may continuously deform the contour to obtain:
\begin{align*}
\frac{1}{2\pi\ii}\oint_{\Gamma}\lambda^{n}\mathcal{R}_{\lambda}\dd\lambda & =A^{n}
\end{align*}
Thus we have:
\begin{align*}
\opnorm{A^{n}} & =\opnorm{\frac{1}{2\pi\ii}\oint_{\Gamma}\lambda^{n}\mathcal{R}_{\lambda}\dd\lambda}\le C\left(r+\delta\right)^{n}\left(r+\delta\right)
\end{align*}
\begin{align*}
C & :=\frac{1}{2\pi}\sup_{\lambda\in\Gamma}\opnorm{\mathcal{R}_{\lambda}}
\end{align*}
\begin{align*}
\Rightarrow\quad\opnorm{A^{n}}^{\frac{1}{n}} & \le\left(r+\delta\right)\left(C^{\frac{1}{n}}\left(r+\delta\right)^{\frac{1}{n}}\right)\xrightarrow{n\to\infty}r+\delta
\end{align*}
Therefore:
\begin{align*}
\limsup_{n\to\infty}\opnorm{A^{n}}^{\frac{1}{n}} & \le r+\delta
\end{align*}
Since $\delta$ is arbitrary, it follows that:
\begin{align*}
\frac{1}{R}=\limsup_{n\to\infty}\opnorm{A^{n}}^{\frac{1}{n}} & =r
\end{align*}
We even conclude:
\begin{align*}
\opnorm{A^{n}}^{\frac{1}{n}} & \xrightarrow{n\to\infty}r\left(A\right)
\end{align*}
Assume that $A$ is \emph{symmetric} (to show $\opnorm{A^{n}}^{\frac{1}{n}}=\opnorm A$).
The Schwarz inequality gives:
\begin{align*}
\opnorm{A^{2}} & \le\opnorm A\cdot\opnorm A=\opnorm A^{2}
\end{align*}
\begin{align*}
\opnorm A^{2} & =\sup_{\norm u=1}\left\langle Au,Au\right\rangle =\sup_{\norm u=1}\left\langle u,Au^{2}\right\rangle \le\sup_{\norm u=1}\underbrace{\norm u}_{=1}\cdot\norm{A^{2}u}
\end{align*}
Iteratively for $n\in\mathbb{N}$:
\begin{align*}
\opnorm{A^{2^{n}}} & =\opnorm A^{2^{n}}
\end{align*}
For arbitrary $m\in\mathbb{N}$ the Schwarz inequality gives:
\begin{align*}
\opnorm{A^{m}} & \le\opnorm A^{m}
\end{align*}
Choose $n$ such that $2^{n}>m$. THen:
\begin{align*}
\opnorm A^{2^{n}} & =\opnorm{A^{2^{n}}}=\opnorm{A^{m}\cdot A^{2^{n}-m}}\le\opnorm{A^{m}}\cdot\opnorm A^{2^{n}-m}\\
\Rightarrow\quad\opnorm A^{m} & \le\opnorm A^{m}
\end{align*}
\qqed


\section{Ritz method}

Let $A\in L\left(H\right)$ be a symmetric compact operator on the
separable Hilbert space $H$.\\
From the Hilbert-Schmidt theorem \ref{sec:Thm-Hilbert-Schmidt} we
know that there exists an orthonormal eigenvalue basis $\left(u_{n}\right)$
of $H$. 
\begin{align*}
Au_{n} & =\lambda_{n}u_{n}
\end{align*}
We now want to construct the $u_{n}$:

Consider the ``expectation value'' functional:
\begin{align*}
S:H & \to\mathbb{R}\\
u & \mapsto\left\langle u,Au\right\rangle 
\end{align*}
This is well defined, since:
\begin{align*}
\overline{S\left(u\right)} & =\overline{\left\langle u,Au\right\rangle }=\left\langle Au,u\right\rangle =\left\langle u,Au\right\rangle =S\left(u\right)
\end{align*}
$S$ is bounded, because:
\begin{align*}
\abs{S\left(u\right)} & =\abs{\left\langle u,Au\right\rangle }\le\opnorm A\cdot\norm u^{2}\stackrel{\norm u\le1}{\le}\opnorm A
\end{align*}
Maximize $\abs{S\left(u\right)}$ on $\left\{ u\in H\big|\norm u=1\right\} $:\\
Choose a maximizing sequence $\left(u_{n}\right)$ with $\norm{u_{n}}=1$
and:
\begin{align*}
\abs{S\left(u_{n}\right)} & \xrightarrow{n\to\infty}\sup_{\norm u=1}\abs{S\left(u\right)}
\end{align*}
Since $\overline{B_{1}\left(0\right)}$ is weakly compact, there is
a subsequence $u_{k_{l}}$, which converges weakly $u_{k_{l}}\rightharpoondown u$.\\
Since $A$ is compact, the sequence
\begin{align*}
v_{k_{l}} & :=Au_{k_{l}}\to v
\end{align*}
converges and $Au=v$. As a consequence:
\begin{align*}
S\left(u_{k_{l}}\right) & =\left\langle u_{k_{l}},Au_{k_{l}}\right\rangle =\left\langle u_{k_{l}},v_{k_{l}}\right\rangle =\underbrace{\left\langle u_{k_{l}},v\right\rangle }_{\to\left\langle u,v\right\rangle }+\left\langle u_{k_{l}},v_{k_{l}}-v\right\rangle \xrightarrow{l\to\infty}\left\langle u,v\right\rangle =\left\langle u,Au\right\rangle =S\left(u\right)
\end{align*}
This follows, because:
\begin{align*}
\abs{\left\langle u_{k_{l}},v_{k_{l}}-v\right\rangle } & \le\underbrace{\norm{u_{k_{l}}}}_{=1}\cdot\underbrace{\norm{v_{k_{l}}-v}}_{\to0}\xrightarrow{l\to\infty}0
\end{align*}
Thus $S$ is weakly continuous, i.e. for any $u_{k}\rightharpoondown u$
converges $S\left(u_{k}\right)\to S\left(u\right)$.\\
Because $\left(u_{n}\right)$ is a maximizing sequence, we get:
\begin{align*}
\abs{S\left(u\right)} & =\sup_{\norm{\tilde{u}}=1}\abs{S\left(\tilde{u}\right)}
\end{align*}
Therefore $u$ is the desired maximizer.
\begin{itemize}
\item $u$ is on the unit sphere:\\
The simple approach
\begin{align*}
\norm u^{2} & \not=\lim_{l\to\infty}\norm{u_{k_{l}}}^{2}
\end{align*}
does not work, because $u_{k_{l}}$ only converges weakly.\\
Example:\\
If $\left(e_{l}\right)$ is an orthonormal Hilbert basis in a separable
Hilbert space, then $e_{l}\rightharpoondown0$, but:
\begin{align*}
\lim_{l\to\infty}\norm{e_{l}} & =1\not=0=\norm 0
\end{align*}
But it holds:
\begin{align*}
\norm u^{2} & =\lim_{l\to\infty}\abs{\left\langle u,u_{k_{l}}\right\rangle }\le\lim_{l\to\infty}\norm{u_{k_{l}}}\cdot\norm u=\norm u\\
\Rightarrow\quad\norm u & \le1
\end{align*}
Assume $\norm u<1$, then the vector $\hat{u}:=\frac{u}{\norm u}$
would satisfy the equation:
\begin{align*}
\abs{S\left(\hat{u}\right)} & =\abs{\left\langle \hat{u},A\hat{u}\right\rangle }=\frac{1}{\norm u^{2}}\abs{\left\langle u,Au\right\rangle }=\frac{1}{\norm u^{2}}\sup_{\norm v=1}\abs{S\left(v\right)}\stackrel{\norm u<1}{>}\sup_{\norm v=1}\abs{S\left(v\right)}
\end{align*}
This is a contradiction. Therefore $u$ is in fact a unit vector.%DATE: Do 6.12.12
\item $u$ is an eigenvector corresponding to the eigenvalue $\lambda=\left\langle u,Au\right\rangle \in\mathbb{R}$:
Consider the variation for $v\in H$:
\begin{align*}
\tilde{u}\left(\tau\right) & =u+\tau v
\end{align*}
\begin{align*}
S\left(\frac{\tilde{u}}{\norm{\tilde{u}}}\right) & =\frac{\left\langle \tilde{u},A\tilde{u}\right\rangle }{\left\langle \tilde{u},\tilde{u}\right\rangle }=\frac{\left\langle u+\tau v,A\left(u+\tau v\right)\right\rangle }{\left\langle u+\tau v,u+\tau v\right\rangle }
\end{align*}
This is called \emph{Rayleigh quotient}. We know that $S\left(\tilde{u}\left(\tau\right)\right)$
is extremal at $\tau=0$:
\begin{align*}
0 & =\frac{\dd}{\dd\tau}S\left(\tilde{u}\left(\tau\right)\right)\bigg|_{\tau=0}=\\
 & =\frac{\left\langle u,Av\right\rangle +\left\langle v,Au\right\rangle +2\tau\left\langle v,v\right\rangle }{\left\langle u+\tau v,u+\tau v\right\rangle }-\frac{\left\langle u+\tau v,A\left(u+\tau v\right)\right\rangle }{\left\langle u+\tau v,u+\tau v\right\rangle ^{2}}\cdot\left(\left\langle v,u\right\rangle +\left\langle u,v\right\rangle +\tau\left\langle v,v\right\rangle \right)\bigg|_{\tau=0}=\\
 & \stackrel{A\text{ symmetric}}{=}2\frac{\text{Re}\left(\left\langle v,Au\right\rangle \right)}{\left\langle u,u\right\rangle }-2\text{Re}\left(\left\langle v,u\right\rangle \right)\frac{\left\langle u,Au\right\rangle }{\left\langle u,u\right\rangle ^{2}}=\\
 & \sr ={\lambda=\left\langle u,Au\right\rangle }{\left\langle u,u\right\rangle =1}2\left(\text{Re}\left(\left\langle v,Au\right\rangle \right)-\lambda\text{Re}\left(\left\langle v,u\right\rangle \right)\right)=2\text{Re}\left(\left\langle v,\left(A-\lambda\right)u\right\rangle \right)
\end{align*}
Set $v=e^{\ii\varphi}w$ for any $\varphi\in\mathbb{R}$ and $w\in H$.
So:
\begin{align*}
0 & =\text{Re}\left(\left\langle v,\left(A-\lambda\right)u\right\rangle \right)=\text{Re}\left(e^{-\ii\varphi}\left\langle w,\left(A-\lambda\right)u\right\rangle \right)\qquad\fall_{\varphi\in\mathbb{R}}
\end{align*}
\begin{align*}
\Rightarrow\quad\left\langle w,\left(A-\lambda\right)u\right\rangle  & =0\qquad\fall_{w\in H}\\
\left(A-\lambda\right)u & =0\\
Au & =\lambda u
\end{align*}

\item It holds $\abs{\lambda}=\opnorm A$:\\
There is no point $\nu$ in the spectrum of $A$ with $\abs{\nu}>\abs{\lambda}$,
because otherwise for all $v\in H$ with $Av=\nu v$ follows:
\begin{align*}
\frac{\abs{\left\langle v,Av\right\rangle }}{\left\langle v,v\right\rangle } & =\abs{\nu}>\abs{\lambda}=\abs{\left\langle u,Au\right\rangle }=\sup_{w\in H}\frac{\abs{\left\langle w,Aw\right\rangle }}{\left\langle w,w\right\rangle }
\end{align*}
This is a contradiction. Thus we get:
\begin{align*}
\abs{\lambda} & =\sup_{\nu\in\sigma\left(A\right)}\abs{\nu}\stackrel{\text{by definition}}{=}r\left(A\right)\stackrel{\ref{sec:Thm-SpectralRadiusFinite}}{=}\opnorm A
\end{align*}

\end{itemize}
Thus we have \emph{constructed} a $u\in H$ with $\norm u=1$, $Au=\lambda u$
and $\abs{\lambda}=\opnorm A$. Now one can proceed inductively:
\begin{align*}
H_{1} & :=\left\langle u\right\rangle ^{\perp}
\end{align*}
\begin{align*}
A\big|_{H_{1}}:H_{1} & \to H_{1}
\end{align*}
(We saw that $H_{1}$ is invariant under $A$.)\\
Repeat the above procedure to maximize $\abs{\left\langle v,Av\right\rangle }$
on $H_{1}\cap\left\{ v\in H\big|\norm v=1\right\} $. This gives $u_{1}$
with $\norm u_{1}=1$, $Au_{1}=\lambda_{1}u_{1}$ and:
\begin{align*}
\abs{\lambda_{1}} & =\opnorm{A\big|_{H_{1}}}\le\opnorm{A\big|_{H}}=\abs{\lambda}
\end{align*}
Now set $H_{2}=\left\langle u,u_{1}\right\rangle ^{\perp}$ and proceed
inductively.\\
This gives a sequence $u_{0}:=u,\ u_{1},\ u_{2},\ \ldots$ of orthonormal
eigenvectors, i.e. $Au_{j}=\lambda_{j}u_{j}$, with decreasing eigenvalues$\abs{\lambda_{j}}$.\\
These $\left(u_{j}\right)$ are an orthonormal basis. (Proof as in
Theorem \ref{sec:Thm-Hilbert-Schmidt})\qqed

Ritz, Galerkin: Finite element method\\
Example: Helium molecule wave function in $H=L^{2}\left(\mathbb{R}^{3},\mathbb{C}\right)$

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
  \draw[fill=black] (-1,0) circle (0.1);
  \draw[fill=black] (1,0) circle (0.1);
  \draw (-2,-0.3) -- (-2.5,-0.8) -- (-2.75,1) -- (-2,-0.3) -- (-1.8,2) -- (-2.75,1);
  \draw (-1.8,2) -- (-0.8,1) -- (-2,-0.3) -- (-1.5,-0.8) -- (-0.8,1);
  \draw (-1.5,-0.8) -- (-2.5,-0.8);
  \draw (-1.5,-0.8) -- (-0.5,0) -- (-0.8,1) -- (0.5,0.7) -- (-0.5,0) -- (0.8,-0.8) -- (2,-0.3) -- (0.5,0.7);
  \draw (0.5,0.7) -- (0.8,-0.8);
\end{tikzpicture}\caption{finite lattice for numerical approximation}
\end{figure}
\begin{align*}
A & =-\frac{\hbar^{2}}{2m}\Delta-\frac{ze^{2}}{\norm{x-x_{1}}}-\frac{ze^{2}}{\norm{x-x_{2}}}
\end{align*}
Now minimize
\begin{align*}
\frac{\left\langle u,Au\right\rangle }{\left\langle u,u\right\rangle }
\end{align*}
on a finite subspace of $H$.


\chapter{A few (technical) results}


\section{Dini's theorem}

Let $E$ be a metric space and $f_{n}:E\to\mathbb{R}$ a sequence
of real valued functions.


\subsection{Definition \textmd{(point-wise/uniform convergence)}}

$f_{n}$ \emph{converges point-wise} to $f$ if $f_{n}\left(x\right)\to f\left(x\right)$
converges for all $x\in E$, i.e.:
\begin{align*}
\fall_{x\in E}\ \fall_{\varepsilon\in\mathbb{R}_{>0}}\ \exs_{N\left(\varepsilon,x\right)}\ \fall_{n\in\mathbb{N}_{\ge N}}:\  & \abs{f_{n}\left(x\right)-f\left(x\right)}<\varepsilon
\end{align*}


$f_{n}$ \emph{converges uniformly} to $f$, in symbols $f_{n}\rightrightarrows f$,
if for all $\varepsilon\in\mathbb{R}_{>0}$ exists a $N\left(\varepsilon\right)$
such that for all $n\ge N$ and all $x\in E$ holds:
\begin{align*}
\abs{f_{n}\left(x\right)-f\left(x\right)} & <\varepsilon
\end{align*}
With quantifiers this is:
\begin{align*}
\fall_{\varepsilon\in\mathbb{R}_{>0}}\ \exs_{N\left(\varepsilon\right)}\ \fall_{n\in\mathbb{N}_{\ge N}}\ \fall_{x\in E}:\  & \abs{f_{n}\left(x\right)-f\left(x\right)}<\varepsilon
\end{align*}



\subsection{Theorem}

If $\left(f_{n}\right)$ is a sequence of continuous functions with
$f_{n}\rightrightarrows f$, then $f$ is also continuous.\\
This is not true in general for point wise convergence:
\begin{align*}
f_{n}\left(x\right) & =\begin{cases}
1 & \text{for }0\le x\le\frac{1}{2}\left(1-\frac{1}{n}\right)\\
0 & \text{for }x\ge\frac{1}{2}\\
n\left(1-2x\right) & \text{for }\frac{1}{2}\left(1-\frac{1}{n}\right)<x<\frac{1}{2}
\end{cases}
\end{align*}
$f_{n}\to f$ converges pointwise to:
\begin{align*}
f\left(x\right) & =\begin{cases}
1 & x<\frac{1}{2}\\
0 & x\ge\frac{1}{2}
\end{cases}
\end{align*}
This $f$ is \emph{not} continuous.

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
 \begin{axis}[width=10cm,
			axis x line=middle, axis y line=middle, xmax=1.15, ymax=1.15,
			xlabel=$x$, ylabel=$y$,samples=300]
%  \addplot[domain=0:0.25] {1};
  \addplot[domain=0.25:0.5] {1-4*(x-0.25)};
  \addlegendentry{$f_2(x)$}
  \addplot[domain=0:0.5,red,thick] {1};
  \addlegendentry{$f(x)$}
  \addplot[domain=0.5:1.15,red,thick] {0};
 \end{axis}
 \draw[red, thick, dashed,scale=7.34] (0.5,0) -- (0.5,0.83);
\end{tikzpicture}\caption{$f_{n}\left(x\right)$ is continuous, but not $f\left(x\right)$}
\end{figure}



\subsubsection*{Proof}

Show that for all $x\in E$ the $\varepsilon$-$\delta$-criterion
is satisfied:\\
Since $f_{n}\rightrightarrows f$ converges uniformly, there is a
$N\in\mathbb{N}$ such that for all $n\in\mathbb{N}_{\ge N}$ and
all $x\in E$ holds:
\begin{align*}
\abs{f_{n}\left(x\right)-f\left(x\right)} & <\frac{\varepsilon}{3}
\end{align*}
Because the $f_{n}$ are continuous, there exists a $\delta\in\mathbb{R}_{>0}$
such that for all $y\in B_{\delta}\left(x\right)$ holds:
\begin{align*}
\abs{f_{N}\left(x\right)-f_{N}\left(y\right)} & <\frac{\varepsilon}{3}
\end{align*}
Now follows for all $y\in B_{\delta}\left(x\right)$:
\begin{align*}
\abs{f\left(y\right)-f\left(x\right)} & \le\underbrace{\abs{f\left(y\right)-f_{N}\left(y\right)}}_{<\frac{\varepsilon}{3}}+\underbrace{\abs{f_{N}\left(y\right)-f_{N}\left(x\right)}}_{<\frac{\varepsilon}{3}}+\underbrace{\abs{f_{N}\left(x\right)-f\left(x\right)}}_{<\frac{\varepsilon}{3}}<\varepsilon
\end{align*}
Therefore $f$ is continuous.\qqed


\subsection{Definition \textmd{(monotonically increasing/decreasing)}}

The sequence of functions $\left(f_{n}\right)$, $f_{n}:E\to\mathbb{R}$
is called \emph{monotonically increasing (decreasing)} if for all
$x\in E$ the real sequence $f_{n}\left(x\right)$ is monotonically
increasing (decreasing).


\subsection{Theorem \textmd{(Dini)}}

Let $E$ be a \emph{compact} metric space, $\left(f_{n}\right)$ monotone
and $f_{n}\to f$.\\
If $f_{n}$ and $f$ are continuous, then the convergence $f_{n}\rightrightarrows f$
is uniform.


\subsubsection*{Proof}

Without loss of generality we assume $\left(f_{n}\right)$ is a monotonically
increasing sequence (otherwise consider $-f_{n}$), i.e. $f_{n}\left(x\right)\le f_{n+1}\left(x\right)$
for all $x\in E$ and all $n\in\mathbb{N}$.\\
Given $\varepsilon>0$ we want to show:
\begin{align*}
\exs_{N\in\mathbb{N}}\ \fall_{x\in E}\ \fall_{\in\mathbb{N}_{\ge N}}:\  & \abs{f\left(x\right)-f_{n}\left(x\right)}<\varepsilon
\end{align*}
For any $x\in E$ there exists an $N\left(x\right)$ such that $\abs{f_{n}\left(x\right)-f\left(x\right)}<\frac{\varepsilon}{2}$
for all $n\in\mathbb{N}_{\ge N}$ (point-wise convergence). Since
both $f_{N\left(x\right)}$ and $f$ are continuous functions, there
exists a neighborhood $U\left(x\right)=B_{\delta\left(x\right)}\left(x\right)$
of $x$ such that for all $z\in U\left(x\right)$ holds:
\begin{align*}
\abs{f_{N\left(x\right)}\left(z\right)-f_{N\left(x\right)}\left(x\right)} & \le\frac{\varepsilon}{4}\\
\abs{f\left(z\right)-f\left(x\right)} & \le\frac{\varepsilon}{4}
\end{align*}
Then follows:
\begin{align*}
\abs{f_{N\left(x\right)}\left(z\right)-f\left(z\right)} & \le\underbrace{\abs{f_{N\left(x\right)}\left(z\right)-f_{N\left(x\right)}\left(x\right)}}_{\le\frac{\varepsilon}{4}}+\underbrace{\abs{f_{N\left(x\right)}\left(x\right)-f\left(x\right)}}_{<\frac{\varepsilon}{2}}+\underbrace{\abs{f\left(x\right)-f\left(z\right)}}_{\le\frac{\varepsilon}{4}}<\varepsilon
\end{align*}
Since $f_{n}\left(z\right)$ is monotonically increasing, it follows
that $\abs{f_{n}\left(z\right)-f\left(z\right)}<\varepsilon$ for
all $z\in B_{\delta\left(x\right)}\left(x\right)$.\\
Now use a standard compactness argument: Since $E$ is compact, it
can be covered by a finite number of these balls $B_{\delta\left(x_{1}\right)}\left(x_{1}\right),\ldots,B_{\delta\left(x_{n}\right)}\left(x_{n}\right)$.
Define:
\begin{align*}
N & =\max\left\{ N\left(x_{1}\right),\ldots,N\left(x_{n}\right)\right\} 
\end{align*}
So for all $n\in\mathbb{N}_{\ge N}$ holds:
\begin{align*}
\abs{f_{n}\left(x\right)-f\left(x\right)} & <\varepsilon
\end{align*}


\qqed


\section{Stone-Weierstraß theorem}

We follow the nice (since constructive) proof by Bernstein.


\subsection{Definition \textmd{(polynomials)}}

Let $E=C^{0}\left(\left[0,1\right]\right)$ be the Banach space of
real valued functions with norm:
\begin{align*}
\norm f & =\sup_{x\in\left[0,1\right]}\abs{f\left(x\right)}
\end{align*}
$\mathcal{P}\left(\left[0,1\right]\right)$ are the \emph{real polynomials},
i.e. for $f\in\mathcal{P}\left(\left[0,1\right]\right)$ there are
$a_{j}\in\mathbb{R}$ such that:
\begin{align*}
f\left(x\right) & =a_{n}x^{n}+a_{n-1}x^{n-1}+\ldots+a_{0}
\end{align*}
Clearly $\mathcal{P}\left(\left[0,1\right]\right)\subseteq C^{0}\left(\left[0,1\right]\right)$
forms a subspace.

We want to show that $\mathcal{P}\left(\left[0,1\right]\right)$ is
dense in $C^{0}\left(\left[0,1\right]\right)$.


\subsection{Lemma}

For $x\in\left[0,1\right]$ holds:

\begin{align*}
\sum_{k=0}^{n}\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k} & =1
\end{align*}



\subsubsection{Proof}

\begin{align*}
\sum_{k=0}^{n}\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k} & =\left(x+1-x\right)^{n}=1
\end{align*}
\qqed


\subsection{Lemma}

For $x\in\left[0,1\right]$ holds:

\begin{align*}
\sum_{k=0}^{n}\left(nx-k\right)^{2}\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k} & =nx\left(1-x\right)\le\frac{n}{4}
\end{align*}
Obviously holds
\begin{align*}
\left(nx-k\right)^{2} & \le4n^{2}
\end{align*}
and therefore:
\begin{align*}
\sum_{k=0}^{n}\left(nx-k\right)^{2}\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k} & \le4n^{2}\sum_{k=0}^{n}\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k}=4n^{2}
\end{align*}



\subsubsection{Proof}

It holds:
\begin{align*}
\sum_{k=0}^{n}k\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k} & =\sum_{k=0}^{n}k\frac{n!}{k!\left(n-k\right)!}x^{k}\left(1-x\right)^{n-k}=\\
 & =0+\sum_{k=1}^{n}\frac{n\cdot\left(n-1\right)!}{\left(k-1\right)!\left(n-k\right)!}x^{k}\left(1-x\right)^{n-k}=\\
 & =n\sum_{k=1}^{n}\left(\begin{array}{c}
n-1\\
k-1
\end{array}\right)x^{k}\left(1-x\right)^{n-k}=\\
 & \sr ={j:=k-1}{}n\sum_{j=0}^{n-1}\left(\begin{array}{c}
n-1\\
j
\end{array}\right)x^{j+1}\left(1-x\right)^{n-j-1}=\\
 & =nx\sum_{j=0}^{n-1}\left(\begin{array}{c}
n-1\\
j
\end{array}\right)x^{j}\left(1-x\right)^{\left(n-1\right)-j}=nx\left(x+1-x\right)^{n-1}=nx
\end{align*}
Similarly one gets:
\begin{align*}
\sum_{k=0}^{n}k\left(k-1\right)\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k} & =n\left(n-1\right)\sum_{k=2}\left(\begin{array}{c}
n-2\\
k-2
\end{array}\right)x^{k}\left(1-x\right)^{n-k}=n\left(n-1\right)x^{2}
\end{align*}
Together this gives:
\begin{align*}
 & \sum_{k=0}^{n}\left(nx-k\right)^{2}\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k}=\sum_{k=0}^{n}\left(n^{2}x^{2}-2nxk+k^{2}\right)\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k}=\\
 & \qquad=\sum_{k=0}^{n}\left(n^{2}x^{2}-2nxk+k\left(k-1\right)+k\right)\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k}=\\
 & \qquad=n^{2}x^{2}-2nx\cdot nx+n\left(n-1\right)x^{2}+nx=\\
 & \qquad=-n^{2}x^{2}+n^{2}x^{2}-nx^{2}+nx=nx\left(1-x\right)
\end{align*}
\qqed

A more elegant method is to use derivatives:
\begin{align*}
\sum_{k=0}^{n}\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}y^{n-k} & =\left(x+y\right)^{n}\\
\sum_{k=0}^{n}k\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}y^{n-k} & =x\cdot\frac{\dd}{\dd x}\left(\sum_{k=0}^{n}\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}y^{n-k}\right)\\
\sum_{k=0}^{n}k^{2}\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}y^{n-k} & =\left(x\cdot\frac{\dd}{\dd x}\right)^{2}\left(\sum_{k=0}^{n}\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}y^{n-k}\right)
\end{align*}



\subsection{Definition}

For $f\in C^{0}\left(\left[0,1\right]\right)$ define:
\begin{align*}
B_{n}f\left(x\right) & :=\sum_{k=0}^{n}f\left(\frac{k}{n}\right)\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k}
\end{align*}



\subsection{Theorem \textmd{(Bernstein)}}

For any $f\in C^{0}\left(\left[0,1\right],\mathbb{R}\right)$, $B_{n}f\rightrightarrows f$
converges uniformly.

Example: $f\left(x\right)=10x\cdot e^{-3x}+\frac{1}{5}\cos\left(\left(4x\right)^{2}\right)$
\begin{align*}
B_{4}f\left(x\right) & \approx0,2\cdot\left(1-x\right)^{4}+5,2\cdot x\cdot\left(1-x\right)^{3}+5,9\cdot x^{2}\cdot\left(1-x\right)^{2}+2,4\cdot x^{3}\cdot\left(1-x\right)+0,3\cdot x^{4}\\
B_{10}f\left(x\right) & \approx0,2\cdot\left(1-x\right)^{10}+9,4\cdot x\cdot\left(1-x\right)^{9}+56,6\cdot x^{2}\cdot\left(1-x\right)^{8}+149,5\cdot x^{3}\cdot\left(1-x\right)^{7}+\\
 & \qquad+217,9\cdot x^{4}\cdot\left(1-x\right)^{6}+248,2\cdot x^{5}\cdot\left(1-x\right)^{5}+244,7\cdot x^{6}\cdot\left(1-x\right)^{4}+\\
 & \qquad+103,2\cdot x^{7}\cdot\left(1-x\right)^{3}+26,5\cdot x^{8}\cdot\left(1-x\right)^{2}+7,9\cdot x^{9}\cdot\left(1-x\right)+0,3\cdot x^{10}
\end{align*}


\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
 \begin{axis}[width=10cm,
			axis x line=middle, axis y line=middle, xmax=1.15, ymin=0,
			xlabel=$x$, ylabel=$y$,samples=300,domain=0:1]
  \addplot[domain=0:1] {10*exp(-3*x)*x+0.2*cos(16*x^2 r)};
  \addlegendentry{$f(x)$}
  \addplot[red,dotted,thick] {0.2*(1-x)^4+5.1559073721*x*(1-x)^3+5.90953245942*x^2*(1-x)^2 +2.43307252735*x^3*(1-x)+0.306338787614*x^4};
  \addlegendentry{$B_4f(x)$}
  \addplot[green,dashed,thick] {0.2*(1-x)^10 + 9.38263677357*x*(1-x)^9 + 56.6119090694*x^2*(1-x)^8 +
			149.495246516*x^3*(1-x)^7 + 217.908409367*x^4*(1-x)^6 + 248.200363295*x^5*(1-x)^5 +
			244.658345846*x^6*(1-x)^4 + 103.198948015*x^7*(1-x)^3 + 26.4871020479*x^8*(1-x)^2 +
			7.89554238831*x^9*(1-x) + 0.306338787614 *x^10};
  \addlegendentry{$B_{10}f(x)$}
  \addplot[blue,thick] {0.2*(x - 1)^100 - 29.7044297355*(x - 1)^99*x + 1922.32661312*(x - 1)^98*x^2 - 76671.4488442*(x - 1)^97*x^3 + 2175113.86842*(x - 1)^96*x^4 - 47445744.0975*(x - 1)^95*x^5 + 835426611.054*(x - 1)^94*x^6 - 12274511676.0*(x - 1)^93*x^7 + (1.54128159816e+11)*(x - 1)^92*x^8 - (1.68416809261e+12)*(x - 1)^91*x^9 + (1.62416346068e+13)*(x - 1)^90*x^10 - (1.39799905505e+14)*(x - 1)^89*x^11 + (1.08395744118e+15)*(x - 1)^88*x^12 - (7.62894913085e+15)*(x - 1)^87*x^13 + (4.90524281676e+16)*(x - 1)^86*x^14 - (2.89723345963e+17)*(x - 1)^85*x^15 + (1.57938018746e+18)*(x - 1)^84*x^16 - (7.97909365281e+18)*(x - 1)^83*x^17 + (3.74925611597e+19)*(x - 1)^82*x^18 - (1.64375304991e+20)*(x - 1)^81*x^19 + (6.742898184e+20)*(x - 1)^80*x^20 - (2.59454195168e+21)*(x - 1)^79*x^21 + (9.38534683558e+21)*(x - 1)^78*x^22 - (3.19807571697e+22)*(x - 1)^77*x^23 + (1.02840511571e+23)*(x - 1)^76*x^24 - (3.12601722657e+23)*(x - 1)^75*x^25 + (8.99540551127e+23)*(x - 1)^74*x^26 - (2.45384693521e+24)*(x - 1)^73*x^27 + (6.3535833129e+24)*(x - 1)^72*x^28 - (1.56329402068e+25)*(x - 1)^71*x^29 + (3.65918765199e+25)*(x - 1)^70*x^30 - (8.15630256136e+25)*(x - 1)^69*x^31 + (1.7329494044e+26)*(x - 1)^68*x^32 - (3.51288267659e+26)*(x - 1)^67*x^33 + (6.80009456156e+26)*(x - 1)^66*x^34 - (1.25811363872e+27)*(x - 1)^65*x^35 + (2.22666269336e+27)*(x - 1)^64*x^36 - (3.7730643047e+27)*(x - 1)^63*x^37 + (6.12656303633e+27)*(x - 1)^62*x^38 - (9.54121434063e+27)*(x - 1)^61*x^39 + (1.42639048452e+28)*(x - 1)^60*x^40 - (2.04882695285e+28)*(x - 1)^59*x^41 + (2.82997586185e+28)*(x - 1)^58*x^42 - (3.76214352396e+28)*(x - 1)^57*x^43 + (4.81728554268e+28)*(x - 1)^56*x^44 - (5.94543941083e+28)*(x - 1)^55*x^45 + (7.0766223624e+28)*(x - 1)^54*x^46 - (8.12653547869e+28)*(x - 1)^53*x^47 + (9.0056905284e+28)*(x - 1)^52*x^48 - (9.6308442906e+28)*(x - 1)^51*x^49 + (9.93701125777e+28)*(x - 1)^50*x^50 - (9.88794489827e+28)*(x - 1)^49*x^51 + (9.48295145921e+28)*(x - 1)^48*x^52 - (8.75834176186e+28)*(x - 1)^47*x^53 + (7.78277250071e+28)*(x - 1)^46*x^54 - (6.64705004092e+28)*(x - 1)^45*x^55 + (5.45033587088e+28)*(x - 1)^44*x^56 - (4.28565344267e+28)*(x - 1)^43*x^57 + (3.22776989136e+28)*(x - 1)^42*x^58 - (2.32579971336e+28)*(x - 1)^41*x^59 + (1.60149090844e+28)*(x - 1)^40*x^60 - (1.05260827225e+28)*(x - 1)^39*x^61 + (6.59659001145e+27)*(x - 1)^38*x^62 - (3.93748270015e+27)*(x - 1)^37*x^63 + (2.23625120007e+27)*(x - 1)^36*x^64 - (1.2072827702e+27)*(x - 1)^35*x^65 + (6.19022488168e+26)*(x - 1)^34*x^66 - (3.01225494685e+26)*(x - 1)^33*x^67 + (1.39035634551e+26)*(x - 1)^32*x^68 - (6.08541276274e+25)*(x - 1)^31*x^69 + (2.52599547528e+25)*(x - 1)^30*x^70 - (9.95022718871e+24)*(x - 1)^29*x^71 + (3.72450252857e+24)*(x - 1)^28*x^72 - (1.32760664266e+24)*(x - 1)^27*x^73 + (4.51994903095e+23)*(x - 1)^26*x^74 - (1.47516743127e+23)*(x - 1)^25*x^75 + (4.63264469906e+22)*(x - 1)^24*x^76 - (1.40412004325e+22)*(x - 1)^23*x^77 + (4.11230568962e+21)*(x - 1)^22*x^78 - (1.16208158162e+21)*(x - 1)^21*x^79 + (3.15481027286e+20)*(x - 1)^20*x^80 - (8.17300500354e+19)*(x - 1)^19*x^81 + (2.00415639672e+19)*(x - 1)^18*x^82 - (4.6119830604e+18)*(x - 1)^17*x^83 + (9.87622406444e+17)*(x - 1)^16*x^84 - (1.95242968902e+17)*(x - 1)^15*x^85 + (3.53637476861e+16)*(x - 1)^14*x^86 - (5.82579078166e+15)*(x - 1)^13*x^87 + (8.66482439273e+14)*(x - 1)^12*x^88 - (1.15456063319e+14)*(x - 1)^11*x^89 + (1.36674282068e+13)*(x - 1)^10*x^90 - (1.4240167171e+12)*(x - 1)^9*x^91 + (1.29209648425e+11)*(x - 1)^8*x^92 - 10086134970.2*(x - 1)^7*x^93 + 667798780.604*(x - 1)^6*x^94 - 36881544.6299*(x - 1)^5*x^95 + 1664862.88706*(x - 1)^4*x^96 - 59769.1901049*(x - 1)^3*x^97 + 1631.70663884*(x - 1)^2*x^98 - 30.797227045*(x - 1)*x^99 + 0.306338787614*x^100};
  \addlegendentry{$B_{100}f(x)$}
  \addplot[mark=x, samples=100, only marks, blue] {10*exp(-3*x)*x+0.2*cos(16*x^2 r)};
  \addplot[mark=*, samples=10, only marks, green] {10*exp(-3*x)*x+0.2*cos(16*x^2 r)};
  \addplot[mark=triangle*, samples=4, only marks, red] {10*exp(-3*x)*x+0.2*cos(16*x^2 r)};
 \end{axis}
\end{tikzpicture}\caption{Approximation of $f\left(x\right)$ by $B_{n}f\left(x\right)$}
\end{figure}



\subsubsection*{Proof}

Without loss of generality assume $f\not=0$ (otherwise $B_{n}f=0=f$).
\begin{align*}
M & :=\norm f>0
\end{align*}
Consider an arbitrary $\varepsilon\in\mathbb{R}_{>0}$. $f$ is continuous
on the compact set $\left[0,1\right]$ and thus uniformly continuous,
i.e. there exists a $\delta\in\mathbb{R}_{>0}$ such that:
\begin{align*}
\abs{x-y} & <\delta\quad\Rightarrow\qquad\abs{f\left(x\right)-f\left(y\right)}<\frac{\varepsilon}{2}
\end{align*}
Choose $\mathbb{N}\ni N\ge\frac{M}{\varepsilon\delta^{2}}$.
\begin{description}
\item [{Claim:}] $\abs{B_{n}f\left(x\right)-f\left(x\right)}<\varepsilon$
for all $x\in\left[0,1\right]$ and all $n\ge N$.
\item [{Proof:}] It holds:
\begin{align*}
f\left(x\right) & =\sum_{k=0}^{n}f\left(x\right)\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k}\\
B_{n}f\left(x\right) & =\sum_{k=0}^{n}f\left(\frac{k}{n}\right)\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k}
\end{align*}
\begin{align*}
\left(B_{n}f-f\right)\left(x\right) & =\sum_{k=0}^{\infty}\left(f\left(\frac{k}{n}\right)-f\left(x\right)\right)\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k}
\end{align*}
Define:
\begin{align*}
A & :=\left\{ k\Bigg|\abs{\frac{k}{n}-x}<\delta\right\}  & B & :=\left\{ k\Bigg|\abs{\frac{k}{n}-x}\ge\delta\right\} 
\end{align*}
We have:
\begin{align*}
\sum_{k\in A}\underbrace{\abs{f\left(\frac{k}{n}\right)-f\left(x\right)}}_{<\frac{\varepsilon}{2}}\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k} & <\frac{\varepsilon}{2}\sum_{k\in A}\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k}\le\frac{\varepsilon}{2}
\end{align*}
\begin{align*}
 & \sum_{k\in B}\underbrace{\abs{f\left(\frac{k}{n}\right)-f\left(x\right)}}_{\le2\norm f=2M}\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k}\le\\
 & \qquad\le2M\sum_{k\in B}\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k}\le\\
 & \qquad\sr{\le}{k\in B}{\Rightarrow n^{2}\delta^{2}\le\left(k-nx\right)^{2}}\frac{2M}{n^{2}\delta^{2}}\sum_{k=0}^{n}\underbrace{\left(k-nx\right)^{2}\left(\begin{array}{c}
n\\
k
\end{array}\right)x^{k}\left(1-x\right)^{n-k}}_{\le\frac{n}{4}}\le\\
 & \qquad\stackrel{n\ge N}{\le}\frac{M}{2n\delta^{2}}\le\frac{M}{2\frac{M}{\varepsilon\delta^{2}}\delta^{2}}=\frac{\varepsilon}{2}
\end{align*}
Therefore holds for all $x\in\left[0,1\right]$.
\begin{align*}
\abs{B_{n}f\left(x\right)-f\left(x\right)} & <\frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon
\end{align*}
\qqed[Claim]
\end{description}
Therefore $B_{n}f\rightrightarrows f$ converges uniformly.\qqed

%DATE: Fr 07.12.12

Now generalize: Let $E$ be a compact metric space. $C^{0}\left(E,\mathbb{R}\right)$
with
\begin{align*}
\norm f & =\sup_{x\in E}\abs{f\left(x\right)}
\end{align*}
is a Banach space. Moreover, it is an algebra with the point-wise
multiplication:
\begin{align*}
\left(f\cdot g\right)\left(x\right) & :=f\left(x\right)\cdot g\left(x\right)
\end{align*}
The multiplication is continuous:
\begin{align*}
\norm{f\cdot g} & \le\norm f\cdot\norm g
\end{align*}
In summary $\left(C^{0}\left(E,\mathbb{R}\right),\norm .,+,\cdot\right)$
is a \emph{Banach algebra}.


\subsection{Theorem \textmd{(Weierstraß)\label{sub:Thm-Weierstra=0000DF}}}

The polynomials are dense in $C^{0}\left(\left[0,1\right],\mathbb{R}\right)$.


\subsubsection*{Proof}

For any $f\in C^{0}\left(\left[0,1\right],\mathbb{R}\right)$, $B_{n}f\rightrightarrows f$
converges uniformly and since the $B_{n}f$ are polynomials, these
are dense.\qqed


\subsection{Theorem \textmd{(Stone-Weierstraß)\label{sub:Thm-Stone-Weierstra=0000DF}}}

Let $\mathcal{A}\subseteq C^{0}\left(E,\mathbb{R}\right)$ be a subalgebra
with the following properties:
\begin{enumerate}
\item $\mathcal{A}$ contains $f=1$ and so by scalar multiplication all
the constant functions.
\item $\mathcal{A}$ separates the points of $E$, i.e. for all $x,y\in E$
with $x\not=y$ there exists a $f\in\mathcal{A}$ such that $f\left(x\right)\not=f\left(y\right)$.
\end{enumerate}
Then $\mathcal{A}$ is dense in $C^{0}\left(E,\mathbb{R}\right)$.


\subsubsection*{Proof}
\begin{enumerate}[label=\roman*)]
\item There is a sequence of polynomials $u_{n}$ on $\left[0,1\right]$
such that $u_{n}\rightrightarrows f$ with $f\left(t\right)=\sqrt{t}$.
This follows immediately from theorem \ref{sub:Thm-Weierstra=0000DF}.
\item If $f\in\mathcal{A}$, then $\abs f$ defined by $\abs f\left(x\right):=\abs{f\left(x\right)}$
is in the closure $\overline{\mathcal{A}}$ of $\mathcal{A}$:\\
For $f\in\mathcal{A}$ define:
\begin{align*}
a & :=\norm f=\max_{x\in E}\abs{f\left(x\right)}
\end{align*}
\begin{align*}
\Rightarrow\quad\frac{f^{2}\left(x\right)}{a^{2}} & \in\left[0,1\right]
\end{align*}
Then converges:
\begin{align*}
u_{n}\left(\frac{f^{2}\left(x\right)}{a^{2}}\right) & \xrightarrow{n\to\infty}\sqrt{\frac{f^{2}\left(x\right)}{a^{2}}}=\frac{\abs{f\left(x\right)}}{a}
\end{align*}
The functions $u_{n}\left(\frac{f^{2}}{a^{2}}\right)$ lie in $\mathcal{A}$,
since these are a polynomials of $f$ and thus again elements of the
algebra $\mathcal{A}$. Moreover $u_{n}\left(\frac{f^{2}}{a^{2}}\right)$
converges uniformly to $\frac{\abs f}{a}$, because for a given $\varepsilon\in\mathbb{R}_{>0}$
exists a $N\in\mathbb{N}$ such that for all $n\in\mathbb{N}_{\ge N}$
and all $t\in\left[0,1\right]$ holds:
\begin{align*}
\abs{u_{n}\left(t\right)-\sqrt{t}} & <\varepsilon
\end{align*}
Then follows with $t=\frac{f^{2}\left(x\right)}{a^{2}}$:
\begin{align*}
\abs{u_{n}\left(\frac{f^{2}\left(x\right)}{a^{2}}\right)-\frac{\abs f}{a}} & <\varepsilon
\end{align*}
Thus $\frac{\abs f}{a}\in\overline{\mathcal{A}}$ and therefore also
$\abs f\in\overline{\mathcal{A}}$.
\item For $f,g\in\overline{\mathcal{A}}$ also $\min\left(f,g\right)$ and
$\max\left(f,g\right)$ (defined point-wise) are again in $\overline{\mathcal{A}}$:
\begin{align*}
\min\left(f,g\right) & =\frac{1}{2}\left(f+g-\abs{f-g}\right)\\
\max\left(f,g\right) & =\frac{1}{2}\left(f+g+\abs{f-g}\right)
\end{align*}
Choose $f_{n},g_{n}\in\mathcal{A}$ such that $f_{n}\rightrightarrows f$
and $g_{n}\rightrightarrows g$. By ii) follows $\abs{f_{n}-g_{n}}\in\overline{\mathcal{A}}$
and $\abs{f_{n}-g_{n}}\rightrightarrows\abs{f-g}$. Therefore holds:
\begin{align*}
\overline{\mathcal{A}}\ni\min\left(f_{n},g_{n}\right) & \rightrightarrows\min\left(f,g\right)\in\overline{\mathcal{A}}
\end{align*}
Similarly the claim follows for $\max$.
\item For all $x,y\in E$ with $x\not=y$ and $\alpha,\beta\in\mathbb{R}$
exists a $f\in\mathcal{A}$ such that $f\left(x\right)=\alpha$ and
$f\left(y\right)=\beta$:\\
For $\alpha=\beta$ we choose $f=\alpha$ as constant function.\\
For $\alpha\not=\beta$ there exists, since $\mathcal{A}$ separates
points of $E$, a $g\in\mathcal{A}$ with $g\left(x\right)\not=g\left(y\right)$.
Set $f=c_{0}+c_{1}g$ and choose:
\begin{align*}
\alpha & =c_{0}+c_{1}g\left(x\right)\\
\beta & =c_{0}+c_{1}g\left(y\right)\\
\Rightarrow\quad c_{1} & =\frac{\alpha-\beta}{g\left(x\right)-g\left(y\right)}\\
\Rightarrow\quad c_{0} & =\alpha-\frac{\alpha-\beta}{g\left(x\right)-g\left(y\right)}g\left(x\right)=\frac{\alpha g\left(x\right)-\alpha g\left(y\right)-\alpha g\left(x\right)+\beta g\left(x\right)}{g\left(x\right)-g\left(y\right)}=\\
 & =\frac{\beta g\left(x\right)-\alpha g\left(y\right)}{g\left(x\right)-g\left(y\right)}
\end{align*}

\item For all $f\in C^{0}$, $x\in E$ and $\varepsilon\in\mathbb{R}_{>0}$
there is a $g\in\overline{\mathcal{A}}$ such that
\begin{align*}
g\left(x\right) & =f\left(x\right)
\end{align*}
and for all $y\in\overline{\mathcal{A}}$ holds:
\begin{align*}
g\left(y\right) & \le f\left(y\right)+\varepsilon
\end{align*}
\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
 \begin{axis}[width=10cm,
			axis x line=middle, axis y line=middle, xmax=1.15, ymin=0, ymax=1.15,
			samples=300,domain=0:1]
  \addplot[domain=0:1] {0.5+0.3*sin(x*180)};
  \addlegendentry{$f(x)$}
  \addplot[red,dashed,thick] {0.6+0.3*sin(x*180)};
  \addlegendentry{$f(x)+\varepsilon$}
  \addplot[blue,dotted,thick] {0.5+0.3*sin(x*180)+0.07*exp(-x)*cos(10*x^2 r)};
  \addlegendentry{$g(x)$}
 \end{axis}
  \draw[dashed] (5.05,0) -- (5.05,4.6);
  \draw (5.05,0) -- (5.05,-0.1) node[below] {$x$};
\end{tikzpicture}\caption{$g\left(x\right)\le f\left(x\right)+\varepsilon$}
\end{figure}
To show this, choose for any $z\in E$ a $h_{z}\in\overline{\mathcal{A}}$
with $h_{z}\left(x\right)=f\left(x\right)$ and $h_{z}\left(z\right)\le f\left(z\right)+\frac{\varepsilon}{2}$,
which is possible after iv).\\
Since $h_{z}$ is continuous, there is a neighborhood $U_{z}$ of
$z$ such that $h_{z}\le f+\varepsilon$ on $U_{z}$.
\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
 \begin{axis}[width=10cm,
			axis x line=middle, axis y line=middle,
			xmax=1.15, ymin=0, ymax=1.15, xtick={0,0.5,1},
			samples=300,domain=0:1]
  \addplot[domain=0:1] {0.5+0.3*sin(x*180)};
  \addlegendentry{$f(x)$}
  \addplot[red,dashed,thick] {0.6+0.3*sin(x*180)};
  \addlegendentry{$f(x)+\varepsilon$}
  \addplot[blue,dotted,thick] {0.5+0.3*sin(x*180)+0.1*(exp(-x)*cos(10*x^2 r)-1) + 0.05 + 0.5*x*sin(x^2*360)};
  \addlegendentry{$h_z(x)$}
 \end{axis}
  \draw[dashed] (5.05,0) -- (5.05,4.6);
  \draw (5.05,0) -- (5.05,-0.1) node[below] {$x$};
  \draw[dashed] (0.8,0) -- (0.8,3.7);
  \draw (0.8,0) -- (0.8,-0.1) node[below] {$z$};
  \draw[red,thick] (0.2,0) -- node[above right]{$U_z$} (1.6,0);
  \draw[red,thick] (0.2,0.1) -- (0.2,-0.1) (1.6,0.1) -- (1.6,-0.1);
\end{tikzpicture}\caption{$h_{z}\le f+\varepsilon$ on $U_{z}$}
\end{figure}
Since $E$ is compact, we can cover it by a finite number of such
neighborhoods $U_{z_{1}},\ldots,U_{z_{N}}$. Define:
\begin{align*}
g & :=\min\left\{ h_{z_{1}},\ldots,h_{z_{N}}\right\} \in\overline{\mathcal{A}}
\end{align*}
It holds $g\left(x\right)=f\left(x\right)$, because $h_{z_{i}}\left(x\right)=f\left(x\right)$.
We also know:
\begin{align*}
g\big|_{U_{j}} & \le h_{z_{j}}\big|_{U_{j}}\le f+\varepsilon
\end{align*}

\item $\overline{\mathcal{A}}=C^{0}$: Denote the function $g$ constructed
in step v) by $g_{x}$.
\begin{align*}
g_{x}\left(x\right) & =f\left(x\right)\\
g_{x} & \le f+\varepsilon
\end{align*}
By continuity of $g_{x}$ there exists a neighborhood $U_{x}$ of
$x$ such that $g_{x}\ge f-\varepsilon$ on $U_{x}$. By compactness
we can cover $E$ by a finite number of such neighborhoods $U_{x_{1}},\ldots,U_{x_{k}}$
and define:
\begin{align*}
g & :=\max\left\{ g_{x_{1}},\ldots,g_{x_{k}}\right\} 
\end{align*}
Then follows:
\begin{align*}
f-\varepsilon\le & g\le f+\varepsilon\\
\norm{f-g} & <\varepsilon
\end{align*}
\qqed
\end{enumerate}
Counterexample in the complex case:
\begin{align*}
E & =\left[0,1\right]\times\left[0,1\right]\subseteq\mathbb{C}
\end{align*}
Consider the set $\mathcal{A}=\mathcal{P}\left(z\right)$ of polynomials
in $z$.
\begin{itemize}
\item The constant functions are in $\mathcal{A}$.
\item $\mathcal{A}$ separates points:\\
If $z_{1}\not=z_{2}$ take $f\left(z\right)=z$ then $f\left(z_{1}\right)\not=f\left(z_{2}\right)$.
\begin{align*}
\overline{\mathcal{A}} & =?
\end{align*}
By Morera's theorem we get:
\begin{align*}
\overline{\mathcal{A}} & =\left\{ f\in C^{0}\left(\left[0,1\right]^{2}\right)\bigg|\big|f\big|_{\left(0,1\right)^{2}}\text{ is holomorphic}\right\} \not=C^{0}\left(\left[0,1\right]^{2}\right)
\end{align*}
For example $f\left(x+\ii y\right)=x-\ii y$. We have $f\in C^{0}\left(\left[0,1\right]^{2}\right)$,
but $f\not\in\overline{\mathcal{A}}$.
\end{itemize}

\subsection{Theorem \textmd{(Stone-Weierstraß, complex version)}}

Let $\mathcal{A}\subseteq C^{0}\left(E,\mathbb{C}\right)$ be a subalgebra
with the properties 1. and 2. from theorem \ref{sub:Thm-Stone-Weierstra=0000DF}
and additionally:
\begin{enumerate}
\item [3.]$f\in\mathcal{A}\Rightarrow\overline{f}\in\mathcal{A}$
\end{enumerate}
Then $\mathcal{A}$ is dense in $C^{0}\left(E,\mathbb{C}\right)$.


\subsubsection*{Proof}

Consider the algebras:
\begin{align*}
\text{Re}\left(\mathcal{A}\right) & =\left\{ f+\overline{f}\Big|f\in\mathcal{A}\right\} \subseteq\mathcal{A}\\
\text{Im}\left(\mathcal{A}\right) & =\left\{ \frac{1}{\ii}\left(f-\overline{f}\right)\bigg|f\in\mathcal{A}\right\} \subseteq\mathcal{A}
\end{align*}
These are subalgebras of $C^{0}\left(E,\mathbb{R}\right)$. By the
real Stone-Weierstraß theorem we get:
\begin{align*}
\overline{\text{Re}\left(\mathcal{A}\right)} & =\overline{\text{Im}\left(\mathcal{A}\right)}=C^{0}\left(E,\mathbb{R}\right)
\end{align*}
For given $f\in C^{0}\left(E,\mathbb{C}\right)$ approximate $\text{Re}\left(f\right)$
and $\text{Im}\left(f\right)$.\qqed


\section{Arzelà-Ascoli theorem}

Let $K$ be a compact metric space and $E$ a Banach space.

$C^{0}\left(K,E\right)$ is the Banach space of continuous functions
$f:K\to E$ with norm:
\begin{align*}
\norm f & :=\sup_{x\in K}\norm{f\left(x\right)}_{E}
\end{align*}
Let $\mathcal{F}\subseteq C^{0}\left(K,E\right)$ be a subset. Is
$\mathcal{F}$ compact?


\subsection{Definition \textmd{(relatively compact)}}

A subset $A$ of a metric space is called \emph{relatively compact},
if $\overline{A}$ is compact.


\subsection{Definition \textmd{(equicontinuous)}}

A family $\mathcal{F}\subseteq C^{0}\left(K,E\right)$ is called \emph{equicontinuous}
(\foreignlanguage{ngerman}{gleichgradig stetig}) if for all $x\in K$
and all $\varepsilon\in\mathbb{R}_{>0}$ there exists a $\delta\in\mathbb{R}_{>0}$
such that for all $y\in B_{\delta}\left(x\right)$ and for all $f\in\mathcal{F}$
holds:
\begin{align*}
\norm{f\left(x\right)-f\left(y\right)} & <\varepsilon
\end{align*}
(Thus $\delta$ is independent of $f\in\mathcal{F}$.)


\subsection{Theorem \textmd{(Arzelà-Ascoli)}}

$\mathcal{F}\subseteq C^{0}\left(K,E\right)$ is relatively compact
if and only if the following two conditions holds:
\begin{enumerate}[label=\roman*)]
\item $\mathcal{F}$ is equicontinuous.
\item For every $x\in K$ the set
\begin{align*}
\mathcal{F}\left(x\right) & :=\left\{ f\left(x\right)\big|f\in\mathcal{F}\right\} 
\end{align*}
is relatively compact in $E$.
\end{enumerate}

\subsubsection*{Proof}

„$\Rightarrow$“: Assume that $\mathcal{F}\subseteq C^{0}\left(K,E\right)$
is relatively compact.
\begin{enumerate}[label=\roman*)]
\item Assume that $\mathcal{F}$ is \emph{not} equicontinuous. Then there
exists an $\varepsilon\in\mathbb{R}_{>0}$ and sequences $x_{n}\in K$,
$f_{n}\in\mathcal{F}$ and $y_{n}\in B_{\frac{1}{n}}\left(x_{n}\right)$
such that:
\begin{align*}
\norm{f_{n}\left(x_{n}\right)-f_{n}\left(y_{n}\right)} & \ge\varepsilon
\end{align*}
After choosing subsequences (with the same notation), we can arrange:
\begin{align*}
x_{n} & \to x & y_{n} & \to x &  & \left(\text{use that }K\text{ is compact}\right)\\
f_{n} & \to f &  &  &  & \left(\text{use that }\mathcal{F}\text{ is relatively compact}\right)
\end{align*}
This means that there is a $N\in\mathbb{N}$ such that for all $n\in\mathbb{N}_{>N}$
holds for all $y\in K$:
\begin{align*}
\norm{f_{n}\left(y\right)-f\left(y\right)} & <\frac{\varepsilon}{3}
\end{align*}
(Since convergence in $C^{0}\left(K,E\right)$ is the same as uniform
convergence $f_{n}\rightrightarrows f$.)\\
Since $f$ is continuous there exists a $\delta\in\mathbb{R}_{>0}$
such that for all $y\in B_{\delta}\left(x\right)$:
\begin{align*}
\norm{f\left(x\right)-f\left(y\right)} & <\frac{\varepsilon}{3}
\end{align*}
With this we get:
\begin{align*}
\norm{f_{n}\left(x\right)-f_{n}\left(y\right)} & \le\underbrace{\norm{f_{n}\left(x\right)-f\left(x\right)}}_{<\frac{\varepsilon}{3}}+\underbrace{\norm{f\left(x\right)-f\left(y\right)}}_{<\frac{\varepsilon}{3}}+\underbrace{\norm{f\left(y\right)-f_{n}\left(y\right)}}_{<\frac{\varepsilon}{3}}<\varepsilon
\end{align*}
This is a contradiction to $\norm{f_{n}\left(x_{n}\right)-f_{n}\left(y_{n}\right)}\ge\varepsilon$.\qqed[\roman{enumi})]
\item Consider $y_{n}\in\mathcal{F}\left(x\right)\subseteq E$ (to show
that $y_{n}$ has a convergent subsequence in $E$).\\
Then there are functions $f_{n}\in\mathcal{F}$ with $f_{n}\left(x\right)=y_{n}$.
Since $\mathcal{F}$ is relatively compact, a subsequence is a Cauchy
sequence in $C^{0}\left(K,E\right)$, i.e. $\norm{f_{n_{l}}\to f_{n_{l'}}}\xrightarrow{l,l'\to\infty}0$.
\begin{align*}
\norm{f_{n_{l}}-f_{n_{l'}}} & =\sup_{z\in K}\norm{f_{n_{l}}\left(z\right)-f_{n_{l'}}\left(z\right)}_{E}\ge\norm{f_{n_{l}}\left(x\right)-f_{n_{l'}}\left(x\right)}_{E}=\norm{y_{n_{l}}-y_{n_{l'}}}
\end{align*}
Therefore we get+:
\begin{align*}
\norm{y_{n_{l}}-y_{n_{l'}}} & \xrightarrow{l,l'\to\infty}0
\end{align*}
Thus $\left(y_{n_{l}}\right)$ is a Cauchy sequence in $E$.\qqed[\roman{enumi})]
\end{enumerate}
%DATE: Do 13.12.12

„$\Leftarrow$“: Let $\left(f_{l}\right)$ be a sequence in $\mathcal{F}$
and show that a subsequence $\left(g_{l}\right)$ converges in $C^{0}\left(K,E\right)$:\\
Since $K$ is compact, there is a countable dense subset $\left\{ x_{1},x_{2},\ldots\right\} \subseteq K$.
Since $\mathcal{F}\left(x_{1}\right)$ is relatively compact, there
is a subsequence $f_{l}^{\left(1\right)}\in\mathcal{F}$ of $\left(f_{l}\right)$
such that $f_{l}^{\left(1\right)}\left(x_{1}\right)$ converges in
$E$. Since $\mathcal{F}\left(x_{2}\right)$ is relatively compact,
there is a subsequence $f_{l}^{\left(2\right)}$ of $f_{l}^{\left(1\right)}$
such that $f_{l}^{\left(2\right)}\left(x_{2}\right)$ converges.\\
Inductively choose a subsequence $\left(f_{l}^{\left(n+1\right)}\right)$
of $\left(f_{l}^{\left(n\right)}\right)$ such that $f_{l}^{\left(n+1\right)}\left(x_{n+1}\right)$
converges in $E$. Take the diagonal sequence $g_{l}:=f_{l}^{\left(l\right)}$.
This is for $l\ge n$ a subsequence of $f_{l}^{\left(n\right)}$,
so for all $n\in\mathbb{N}$ converges $g_{l}\left(x_{n}\right)\xrightarrow{l\to\infty}y_{n}$.
\begin{description}
\item [{Claim:}] $g_{n}$ is a Cauchy sequence in $C^{0}\left(K,E\right)$,
i.e. for all $\varepsilon\in\mathbb{R}_{>0}$ exists a $N\in\mathbb{N}$
such that for all $n,m\in\mathbb{N}_{>N}$ and all $x\in K$ holds:
\begin{align*}
\abs{g_{n}\left(x\right)-g_{m}\left(x\right)} & \le\varepsilon
\end{align*}

\item [{Proof:}] Since $\mathcal{F}$ is equicontinuous, for all $x\in E$
exists a $\delta\in\mathbb{R}_{>0}$ such that for all $z,z'\in B_{\delta\left(x\right)}\left(x\right)$
and all $f\in\mathcal{F}$ holds:
\begin{align*}
\norm{f\left(z\right)-f\left(z'\right)} & <\frac{\varepsilon}{3}
\end{align*}
We cover $K$ by a finite number of such balls $B_{1},\ldots,B_{L}$.
In every Ball $B_{l}$ there is at least one point of $\left\{ x_{1},x_{2},\ldots\right\} $.
We choose such a point $\xi_{l}\in B_{l}$. Since $\left(g_{n}\left(\xi_{l}\right)\right)$
converges for every $l\in\left\{ 1,\ldots,L\right\} $ we can choose
a $N\in\mathbb{N}$ such that for all $l\in\left\{ 1,\ldots,L\right\} $
and all $m,n\in\mathbb{N}_{>N}$ holds:
\begin{align*}
\norm{g_{n}\left(\xi_{l}\right)-g_{m}\left(\xi_{l}\right)} & <\frac{\varepsilon}{3}
\end{align*}
For every $x\in K$ exists a $l\in\left\{ 1,\ldots,L\right\} $ with
$x\in B_{l}$.
\begin{align*}
\norm{g_{n}\left(x\right)-g_{m}\left(x\right)} & \le\underbrace{\norm{g_{n}\left(x\right)-g_{n}\left(\xi_{l}\right)}}_{<\frac{\varepsilon}{3}}+\underbrace{\norm{g_{n}\left(\xi_{l}\right)-g_{m}\left(\xi_{l}\right)}}_{<\frac{\varepsilon}{3}}+\underbrace{\norm{g_{m}\left(\xi_{l}\right)-g_{m}\left(x\right)}}_{<\frac{\varepsilon}{3}}
\end{align*}
\qqed[Claim]
\end{description}
Therefore the subsequence $\left(g_{l}\right)$ for $\left(f_{l}\right)$
converges in $C^{0}\left(K,E\right)$, since $C^{0}\left(K,E\right)$
is complete, because $E$ is a Banach space.\qqed


\subsubsection*{Application to integral operators}

Let $K\subseteq\mathbb{R}^{n}$ be compact. Consider an integral operator
$A:C^{0}\left(K,\mathbb{R}\right)\to C^{0}\left(K,\mathbb{R}\right)$,
i.e.:
\begin{align*}
\left(Af\right)\left(x\right) & =\int_{K}A\left(x,y\right)f\left(y\right)\dd^{n}y
\end{align*}
$\mathcal{F}:=A\left(C^{0}\left(K,\mathbb{R}\right)\right)$ is equicontinuous
provided that $A\left(.,y\right)$ is continuous. 


\section{The Riesz representation theorem}

Let $K$ again be a compact metric space. $E=C^{0}\left(K,\mathbb{R}\right)$
with the sup-norm is a Banach space.
\begin{description}
\item [{Question:}] What is $E^{*}$?
\end{description}
Consider $l\in E^{*}$, i.e.
\begin{align*}
l:E & \to\mathbb{R}
\end{align*}
and for all $f\in C^{0}\left(K\right)$ holds:
\begin{align*}
\abs{l\left(f\right)} & \le C\norm f
\end{align*}
This means $f$ is bounded or equivalently continuous.


\subsection{Examples}

Consider $K=\left[0,1\right]\subseteq\mathbb{R}$. For any $\varphi\in L^{1}\left(\left[0,1\right]\right)$,
the functional
\begin{align*}
l\left(f\right) & :=\int_{0}^{1}\varphi\left(x\right)f\left(x\right)\dd x
\end{align*}
is linear and bounded:
\begin{align*}
\abs{l\left(f\right)} & \le\int_{0}^{1}\abs{\varphi\left(x\right)}\cdot\abs{f\left(x\right)}\dd x\le\underbrace{\sup_{x\in\left[0,1\right]}\abs f}_{=\norm f}\cdot\underbrace{\int_{0}^{1}\abs{\varphi\left(x\right)}\dd x}_{=\norm{\varphi}_{L^{1}}}
\end{align*}
It is convenient to identify $l\in E^{*}$ with the function $\varphi\in L^{1}$.
We have represented $l$ by an $L^{1}$-function $\varphi$.\\
This can also be written as a \emph{signed measure} (\foreignlanguage{ngerman}{signiertes
Maß}):
\begin{align*}
\dd\mu & :=\varphi\left(x\right)\dd x
\end{align*}
But not every $l\in E^{*}$ can be represented in this form.


\subsubsection*{Example}

\begin{align*}
l\left(f\right) & :=f\left(\frac{1}{2}\right)
\end{align*}
is bounded:
\begin{align*}
\abs{l\left(f\right)} & =\abs{f\left(\frac{1}{2}\right)}\le\sup_{\left[0,1\right]}\abs f=\norm f
\end{align*}
It can be represented by the Dirac measure:
\begin{align*}
l\left(f\right) & =\int_{0}^{1}f\left(x\right)\delta\left(x-\frac{1}{2}\right)\dd x=\int_{0}^{1}f\left(x\right)\dd\mu
\end{align*}
Here $\delta\left(x\right)$ is the $\delta$-Distribution. $\mu=\delta_{\frac{1}{2}}$
is the Dirac measure.
\begin{align*}
\delta_{x_{0}}\left(\Omega\right) & =\begin{cases}
1 & \text{if }x_{0}\in\Omega\\
0 & \text{otherwise}
\end{cases}
\end{align*}



\subsection{Definition \textmd{(bounded, positive, regular measure)}}

Let $X\not=\emptyset$ be a set. A $\sigma$-algebra $\mathcal{M}$
over $X$ is a set of subsets of $X$ such that holds:
\begin{enumerate}[label=\roman*)]
\item $\emptyset\in\mathcal{M}$
\item $A\in\mathcal{M}\ \Rightarrow\ \complement A:=X\setminus A\in\mathcal{M}$
\item For a countable family $\left(A_{j}\right)_{j\in\mathbb{N}}$ holds:
\begin{align*}
\bigcup_{j=1}^{\infty}A_{j} & \in\mathcal{M}
\end{align*}

\end{enumerate}
The elements of $\mathcal{M}$ are called \emph{measurable sets} (\foreignlanguage{ngerman}{messbare
Mengen}).

Let $K$ be a compact metric space. Denote by $\mathfrak{M}$ the
\emph{Borel algebra}, i.e. the smallest $\sigma$-algebra over $K$,
which contains all open and therefore all closed subsets of $K$.

A \emph{bounded (signed) measure} is a mapping
\begin{align*}
\mu:\mathfrak{M} & \to\mathbb{R}
\end{align*}
(not $\mu:\mathfrak{M}\to\mathbb{R}^{+}\cup\left\{ 0\right\} \cup\left\{ \infty\right\} $
as before in measure theory) with the following properties:
\begin{itemize}
\item The empty set measures zero:
\begin{align*}
\mu\left(\emptyset\right) & =0
\end{align*}

\item $\sigma$-additivity: For $M_{j}\in\mathfrak{M}$ with $M_{i}\cap M_{j}=\emptyset$
for all $i\not=j$ holds:
\begin{align*}
\mu\left(\bcupd_{j=1}^{\infty}M_{j}\right) & =\sum_{j=1}^{\infty}\mu\left(M_{j}\right)
\end{align*}

\end{itemize}
$\mu$ is \emph{positive}, if $\mu\left(M\right)\ge0$ for all $M\in\mathfrak{M}$.\\
$\mu$ is \emph{regular}, if for all $A\in\mathfrak{M}$ holds:
\begin{align*}
\mu\left(A\right) & =\sup_{\sr{}{B\subseteq A}{B\text{ compact}}}\mu\left(B\right)=\inf_{\sr{}{\Omega\supseteq A}{\Omega\text{ open}}}\mu\left(\Omega\right)
\end{align*}



\subsubsection*{Example}

The Lebesgue measure $\dd^{n}x$ restricted to the Borel algebra on
$\left[0,1\right]^{n}$ is a bounded, positive and regular measure.


\subsection{Theorem \textmd{(Riesz representation theorem)\label{sub:Thm-Riesz-representation}}}

Consider $l\in C^{0}\left(K,\mathbb{R}\right)^{*}$. Then there is
a unique bounded regular Borel measure $\mu$ (i.e. a measure on the
Borel algebra $\mathfrak{M}$) such that for all $f\in C^{0}\left(K,\mathbb{R}\right)$
holds:
\begin{align*}
l\left(f\right) & =\int_{K}f\dd\mu
\end{align*}
Here we only prove the case $K=\left[0,1\right]$. (We also need it
for $K=\left[0,1\right]^{2}$.)

How can one construct positive regular Borel measures on $\left[0,1\right]$?


\subsubsection*{Lebesgue-Stieltjes integral}

Let $\alpha:\left[0,1\right]\to\mathbb{R}$ be monotonically increasing
(not necessarily continuous).

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
 \begin{axis}[width=10cm,
			axis x line=middle, axis y line=middle,
			ymin=0, ymax=1.25,
			xmin =0 , xmax=1.15]
  \addplot[domain=0.2:0.5] {0.2+x^2};
  \addlegendentry{$\alpha(x)$}
  \addplot[domain=0.5:0.7] {0.1+x};
  \addplot[domain=0.7:1,samples=70] {0.9+0.3*sqrt(x-0.7)};
  \draw[dashed] (axis cs:0.2,0) -- (axis cs:0.2,0.24);
  \draw[dashed] (axis cs:0.5,0.45) -- (axis cs:0.5,0.6);
  \draw[dashed] (axis cs:0.7,0.8) -- (axis cs:0.7,0.9);
 \end{axis}
\end{tikzpicture}\caption{$\alpha$ is monotonically increasing, but not continuous}
\end{figure}


The two one-sided limits
\begin{align*}
\lim_{x\nearrow x_{0}}\alpha\left(x\right),\ \lim_{x\searrow x_{0}}\alpha\left(x\right)
\end{align*}
exist. In general:
\begin{align*}
\lim_{x\nearrow x_{0}}\alpha\left(x\right) & \le\alpha\left(x_{0}\right)\le\lim_{x\searrow x_{0}}\alpha\left(x\right)
\end{align*}
But equality does not need to hold. Define:
\begin{align*}
\mu\left(\left(a,b\right)\right) & :=\lim_{x\nearrow b}\alpha\left(x\right)-\lim_{x\searrow a}\alpha\left(x\right)
\end{align*}
By $\sigma$-additivity, this measure can be extended to a positive
regular bounded Borel measure. (This can be proven exactly as for
the Lebesgue integral.) The corresponding integral
\begin{align*}
\int_{0}^{1}f\dd\mu
\end{align*}
is called Lebesgue-Stieltjes integral. If $\alpha\left(x\right)=x+c$,
the Lebesgue-Stieltjes integral reduces to the Lebesgue integral


\subsection{Example}

Let $\alpha\in C^{1}\left(\left[0,1\right]\right)$ be monotonically
increasing. Then holds:
\begin{align*}
\mu\left(\left(a,b\right)\right) & =\alpha\left(b\right)-\alpha\left(a\right)=\int_{a}^{b}\alpha'\left(x\right)\dd x=\int_{0}^{1}\chi_{\left(a,b\right)}\alpha'\left(x\right)\dd x
\end{align*}
The corresponding Lebesgue-Stieltjes integral is:
\begin{align*}
\int f\dd\mu & =\int_{0}^{1}f\left(x\right)\cdot\alpha'\left(x\right)\dd x
\end{align*}
The following short notation is used in general:
\begin{align*}
\dd\mu & =\alpha'\left(x\right)\dd x\\
\dd\mu & =\dd\alpha
\end{align*}
If $\alpha\in C^{1}\left(\left[0,1\right]\right)$ is not monotone,
we can still set:
\begin{align*}
\int_{0}^{1}f\dd\mu & :=\int_{0}^{1}f\cdot\alpha'\left(x\right)\dd x
\end{align*}
$\dd\mu$ is a signed measure.

In order to extend the Lebesgue-Stieltjes construction to functions
$\alpha$, which are \emph{not} monotone (such as to obtain signed
measures), we need to assume, that $\alpha$ has bounded variation.


\subsection{Definition \textmd{(total variation)}}

Let $\alpha:\left[0,1\right]\to\mathbb{R}$ be a function (not necessarily
continuous).\\
The \emph{total variation} (\foreignlanguage{ngerman}{Totalvariation})
is defined by:
\begin{align*}
\left(\text{TV}\left(\alpha\right)\right)\left(x\right) & :=\sup_{\sr{}{N\in\mathbb{N}}{0=x_{0}<\ldots<x_{N}=x}}\sum_{i=1}^{N}\abs{\alpha\left(x_{1}\right)-\alpha\left(x_{i-1}\right)}\in\mathbb{R}_{\ge0}\cup\left\{ \infty\right\} 
\end{align*}
$\alpha$ is of \emph{bounded variation} (\foreignlanguage{ngerman}{beschränkte
Totalvariation}), $\alpha\in\mathcal{BV}\left(\left[0,1\right]\right)$,
if $\left(\text{TV}\left(f\right)\right)\left(1\right)<\infty$.

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
 \begin{axis}[width=10cm,
			axis x line=middle, axis y line=middle,
			ymin=-0.1, ymax=1.05, xtick=0,
			xmin =-0.02, xmax=1.05, ytick=0, samples=100]
  \addplot[domain=0:1] {0.7+0.3*exp(-2*x)*cos(700*x+20)};
  \addlegendentry{$\alpha(x)$}
  \draw[thick] (axis cs:0,0.025) -- (axis cs:0,-0.025) node[below right]{$x_0$};
  \draw[thick] (axis cs:0.2,0.025) -- (axis cs:0.2,-0.025) node[below]{$x_1$};
  \draw[dashed] (axis cs:0.2,0) -- (axis cs:0.2,0.51);
  \draw[thick] (axis cs:0.4,0.025) -- (axis cs:0.4,-0.025) node[below]{$x_2$};
  \draw[dashed] (axis cs:0.4,0) -- (axis cs:0.4,0.765);
  \draw[thick] (axis cs:0.6,0.025) -- (axis cs:0.6,-0.025) node[below]{$x_3$};
  \draw[dashed] (axis cs:0.6,0) -- (axis cs:0.6,0.715);
  \draw[dashed] (axis cs:1,0) -- (axis cs:1,0.74);
  \draw[thick] (axis cs:1,0.025) -- (axis cs:1,-0.025) node[below]{$x_N$};
 \end{axis}
\end{tikzpicture}\caption{total variation of $\alpha$}
\end{figure}


\emph{Note:} If $\alpha$ is monotonically increasing, then holds:
\begin{align*}
\left(\text{TV}\left(\alpha\right)\right)\left(x\right) & =\alpha\left(x\right)-\alpha\left(0\right)<\infty
\end{align*}
Thus every monotonically function has bounded variation.

But there are even continuous functions, which have unbounded variation,
e.g. for large enough $p\in\mathbb{R}_{>0}$:
\begin{align*}
\alpha\left(x\right) & =x\sin\left(\frac{1}{x^{p}}\right)
\end{align*}


For $\alpha\in C^{1}\left(\left[0,1\right]\right)$ holds:
\begin{align*}
\text{TV}\left(\alpha\right)\left(x\right) & =\int_{0}^{x}\abs{\alpha'\left(\tau\right)}\dd\tau
\end{align*}



\subsubsection*{Lemma \textmd{(Properties of the total variation)}}

$\text{TV}\left(\alpha\right)\left(x\right)$ is monotonically increasing
and:
\begin{align*}
\text{TV}\left(\alpha\right)\left(0\right) & =0
\end{align*}
$\text{TV}\left(\alpha\right)\left(x\right)\pm\alpha\left(x\right)$
is also monotonically increasing.

%DATE: Fr 14.12.12


\subsubsection*{Proof}

Assume that $y\in\mathbb{R}_{>x}$.
\begin{align*}
\text{TV}\left(\alpha\right)\left(y\right) & =\sup_{\sr{}{N\in\mathbb{N}}{0=x_{0}<\ldots<x_{N}=y}}\sum_{i=1}^{N}\abs{\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)}\ge\sup_{\sr{}{N\in\mathbb{N}_{\ge2}}{0=x_{0}<\ldots<x_{N-1}=x<x_{N}=y}}\sum_{i=1}^{N}\abs{\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)}\ge\\
 & \ge\sup_{\sr{}{N\in\mathbb{N}_{\ge2}}{0=x_{0}<\ldots<x_{N-1}=x<x_{N}=y}}\sum_{i=1}^{N-1}\abs{\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)}=\text{TV}\left(\alpha\right)\left(x\right)
\end{align*}
\begin{align*}
\text{TV}\left(\alpha\right)\left(x\right)\pm\alpha\left(x\right) & =\pm\alpha\left(0\right)+\sup_{\sr{}{N\in\mathbb{N}}{0=x_{0}<\ldots<x_{N}=x}}\sum_{i=1}^{N}\underbrace{\abs{\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)}\pm\left(\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)\right)}_{\ge0}
\end{align*}
Just as before this implies that 
\begin{align*}
\text{TV}\left(\alpha\right)\left(x\right)\pm\alpha\left(x\right)
\end{align*}
is monotonically increasing.\qqed

Suppose that $f\in\mathcal{BV}\left(\left[0,1\right]\right)$. Then
the functions
\begin{align*}
f_{+} & =\frac{1}{2}\left(\text{TV}\left(f\right)+f\right)\\
f_{-} & =\frac{1}{2}\left(\text{TV}\left(f\right)-f\right)
\end{align*}
are monotonically increasing and:
\begin{align*}
f & =f_{+}-f_{-}
\end{align*}
Let $\dd\mu_{\pm}=\dd f_{\pm}$ be the bounded positive regular Borel
measures of the corresponding Lebesgue-Stieltjes integrals. Then
\begin{align*}
\mu & :=\mu_{+}-\mu_{-}
\end{align*}
defines a bounded regular Borel measure with the property:
\begin{align*}
\mu\left(\left(a,b\right)\right) & =\mu_{+}\left(\left(a,b\right)\right)-\mu_{-}\left(\left(a,b\right)\right)=\lim_{x\nearrow b}f_{+}\left(x\right)-\lim_{x\searrow a}f_{+}\left(x\right)-\lim_{x\nearrow b}f_{-}\left(x\right)+\lim_{x\searrow a}f_{-}\left(x\right)=\\
 & =\lim_{x\nearrow b}f\left(x\right)-\lim_{x\searrow a}f\left(x\right)
\end{align*}



\subsection{Example}

Consider the Heaviside function:
\begin{align*}
f & :=\begin{cases}
0 & \text{if}\ x\le\frac{1}{2}\\
1 & \text{if}\ x>\frac{1}{2}
\end{cases}
\end{align*}
$\dd\mu:=\dd f$ has the form $\mu=\delta_{\frac{1}{2}}$.


\subsubsection*{Proof of Theorem \ref{sub:Thm-Riesz-representation} in the case
$K=\left[0,1\right]$}

$\mathcal{PC}\left(\left[0,1\right]\right)$ are the piecewise continuous
functions, i.e. for all $f\in\mathcal{PC}\left(\left[0,1\right]\right)$
exists a $N\in\mathbb{N}$ and points $0=x_{0}<\ldots<x_{N}=1$ such
that $f\big|_{\left(x_{i-1},x_{i}\right)}$ is continuous and has
a continuous continuation to $\left[x_{i-1},x_{i}\right]$ for all
$i\in\left\{ 1,\ldots,N\right\} $.\\
On $\mathcal{PC}$ we introduce the norm:
\begin{align*}
\norm f & =\sup_{x\in\left[0,1\right]}\abs{f\left(x\right)}
\end{align*}
This makes $\mathcal{PC}\left(\left[0,1\right]\right)$ a Banach space.
\begin{align*}
C^{0}\left(\left[0,1\right]\right) & \subseteq\mathcal{PC}\left(\left[0,1\right]\right)
\end{align*}
is a subspace, which is closed, since it is complete.\\
Consider $l\in C^{0}\left(\left[0,1\right]\right)^{*}$, i.e.
\begin{align*}
l:C^{0}\left(\left[0,1\right]\right) & \to\mathbb{R}
\end{align*}
with:
\begin{align*}
\abs{l\left(f\right)} & \le C\norm f_{C^{0}}
\end{align*}
According to the Hahn-Banach theorem, there is an extension
\begin{align*}
\tilde{l}:\mathcal{PC}\left(\left[0,1\right]\right) & \to\mathbb{R}
\end{align*}
with $\tilde{l}\big|_{C^{0}}=l$ and $\abs{l\left(f\right)}\le C\norm f_{\mathcal{PC}\left(\left[0,1\right]\right)}$.
Define $\alpha:\left[0,1\right]\to\mathbb{R}$ by:
\begin{align*}
\alpha\left(x\right) & :=\begin{cases}
\tilde{l}\left(\chi_{[0,x)}\right) & \text{if }x<1\\
\tilde{l}\left(\chi_{\left[0,1\right]}\right) & \text{if }x=1
\end{cases}
\end{align*}


\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
 \begin{axis}[width=8cm,
			axis x line=middle, axis y line=middle,
			ymin=-0.1, ymax=1.15, xtick=0,
			xmin =-0.02, xmax=1.05, ytick={1}, samples=100]
  \addplot[domain=0:0.7] {1};
  \addlegendentry{$\chi_{[0,x)}$}
  \draw[dashed] (axis cs:0.7,0) -- (axis cs:0.7,1);
  \draw[thick] (axis cs:0.7,0.025) -- (axis cs:0.7,-0.025) node[below]{$x$};
 \end{axis}
\end{tikzpicture}\caption{$\chi_{[0,x)}$}
\end{figure}


$l\left(\chi_{[0,x)}\right)$ is ill-defined, because $\chi_{[0,x)}$
is \emph{not} continuous.

$\tilde{l}\left(\chi_{[0,x)}\right)$ is well-defined, because $\chi_{[0,x)}$
is piecewise-continuous.
\begin{itemize}
\item $\alpha$ has bounded variation: Consider:
\begin{align*}
0=x_{0}<\ldots<x_{N}=1
\end{align*}
We need to show:
\begin{align*}
\sum_{i=1}^{N}\abs{\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)} & <C
\end{align*}
$C$ has to be independent of $N$ and the $\left(x_{i}\right)$.\\
Define $s_{i}\in\left\{ \pm1\right\} $ by:
\begin{align*}
s_{i} & :=\begin{cases}
+1 & \text{if }\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)\ge0\\
-1 & \text{if }\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)<0
\end{cases}
\end{align*}
Then holds:
\begin{align*}
\sum_{i=1}^{N}\abs{\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)} & =\sum_{i=1}^{N}s_{i}\left(\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)\right)=\tilde{l}\left(\sum_{i=1}^{N-1}s_{i}\chi_{[x_{i-1},x_{i})}+s_{N}\chi_{\left[x_{N-1},1\right]}\right)
\end{align*}
Since $\tilde{l}$ is bounded by construction, we know:
\begin{align*}
\sum_{i=1}^{N}\abs{\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)} & \le\abs{\tilde{l}\left(\sum_{i=1}^{N-1}s_{i}\chi_{[x_{i-1},x_{i})}+s_{N}\chi_{\left[x_{N-1},1\right]}\right)}\le\\
 & \le C\norm{\sum_{i=1}^{N-1}s_{i}\chi_{[x_{i-1},x_{i})}+s_{N}\chi_{\left[x_{N-1},1\right]}}=C
\end{align*}
Therefore we have $\alpha\in\mathcal{BV}\left(\left[0,1\right]\right)$.
\item Consider $\dd\mu:=\dd\alpha_{+}-\dd\alpha_{-}$ for the corresponding
bounded regular Borel measure, where $\alpha=\alpha_{+}-\alpha_{-}$
and $\alpha_{\pm}$ are monotonically increasing.

\begin{description}
\item [{Claim:}] For all $f\in C^{0}\left(\left[0,1\right]\right)$ holds:
\begin{align*}
l\left(f\right) & =\int_{0}^{1}f\dd\mu
\end{align*}

\item [{Proof:}] Consider $f\in C^{0}\left(\left[0,1\right]\right)$. Set:
\begin{align*}
f_{n}\left(x\right) & :=\begin{cases}
\sum_{i=1}^{n}f\left(\frac{i}{n}\right)\cdot\chi_{\big[\frac{i-1}{n},\frac{i}{n}\big)} & \text{if }x<1\\
f\left(1\right) & \text{if }x=1
\end{cases}
\end{align*}
\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
 \begin{axis}[width=10cm,
			axis x line=middle, axis y line=middle,
			ymin=-0.2, ymax=1.6, xtick=0,
			xmin =-0.05, xmax=1.15, ytick=0, samples=100]
  \addplot[domain=0:1] {-4*x^3+2*x^2+2*x+0.4};
  \addlegendentry{$f(x)$}
  \addplot[domain=0:0.2, dashed] {0.4};
  \addlegendentry{$f_n(x)$}
  \draw[dashed] (axis cs:0.2,0) -- (axis cs:0.2,0.85) -- (axis cs:0.4,0.85);
  \draw[thick] (axis cs:0.2,0.025) -- (axis cs:0.2,-0.025) node[below]{$\frac{1}{n}$};
  \draw[dashed] (axis cs:0.4,0) -- (axis cs:0.4,1.265) -- (axis cs:0.6,1.265);
  \draw[thick] (axis cs:0.4,0.025) -- (axis cs:0.4,-0.025) node[below]{$\frac{2}{n}$};
  \draw[dashed] (axis cs:0.6,0) -- (axis cs:0.6,1.45) -- (axis cs:0.8,1.45);
  \draw[thick] (axis cs:0.6,0.025) -- (axis cs:0.6,-0.025) node[below]{$\frac{3}{n}$};
  \draw[dashed] (axis cs:0.8,0) -- (axis cs:0.8,1.45) (axis cs:0.8,1.23) -- (axis cs:1,1.23);
  \draw[thick] (axis cs:0.8,0.025) -- (axis cs:0.8,-0.025) node[below]{$\frac{4}{n}$};
  \draw[dashed] (axis cs:1,0) -- (axis cs:1,1.23);
  \draw[thick] (axis cs:1,0.025) -- (axis cs:1,-0.025) node[below]{$\frac{n}{n}=1$};
 \end{axis}
\end{tikzpicture}\caption{Approximation of $f$ by $f\left(\frac{i}{n}\right)$ for $n=5$}
\end{figure}
Since $f_{n}$ is uniformly continuous, i.e. $f_{n}\rightrightarrows f$,
we get:
\begin{align*}
l\left(f\right) & =\tilde{l}\left(f\right)=\tilde{l}\left(\lim_{n\to\infty}f_{n}\right)\stackrel{\tilde{l}\text{ continuous}}{=}\lim_{n\to\infty}\tilde{l}\left(f_{n}\right)=\\
 & \stackrel{\text{by construction}}{=}\lim_{n\to\infty}\int_{0}^{1}f_{n}\dd\mu\stackrel{\left(*\right)}{=}\int_{0}^{1}\lim_{n\to\infty}f_{n}\dd\mu=\int_{0}^{1}f\dd\mu
\end{align*}
For $\left(*\right)$ consider:
\begin{align*}
\abs{\int_{0}^{1}\left(f_{n}-f\right)\dd\mu} & \le\underbrace{\sup\abs{f-f_{n}}}_{\to0}\cdot\underbrace{\text{TV}\left(\alpha\right)\left(1\right)}_{<\infty}\xrightarrow{n\to\infty}0
\end{align*}
\qqed[Claim]
\end{description}
\end{itemize}
\qqed[\ref{sub:Thm-Riesz-representation}]


\subsubsection*{Remarks}
\begin{itemize}
\item Our proof only works in the case $K=\left[a,b\right]\subseteq\mathbb{R}$.
(see Reed, Simon: Appendix ``The Riesz-Markov Theorem'')
\item In general dimension the idea would be:
\begin{align*}
\mu\left(\Omega\right) & :=\tilde{l}\left(\chi_{\Omega}\right)
\end{align*}
But how to extend $l$? So choose $f_{n}\to\chi_{\Omega}$ and define:
\begin{align*}
\mu\left(\Omega\right) & :=\lim_{n\to\infty}l\left(f_{n}\right)
\end{align*}
(see Rudin: \emph{Real and complex analysis})
\item Total variation of a bounded Borel measure:
\begin{align*}
\abs{\mu}\left(\Omega\right) & :=\sup_{\sr{\Omega_{1},\ldots,\Omega_{N}}{N\in\mathbb{N}}{\text{with }\Omega_{1}\dot{\cup}\ldots\dot{\cup}\Omega_{N}=\Omega}}\sum_{i=1}^{N}\abs{\mu\left(\Omega_{i}\right)}
\end{align*}
$\abs{\mu}$ is a positive bounded Borel measure. (see Rudin)\\
Then we can write:
\begin{align*}
\abs{\int_{K}\left(f-f_{n}\right)\dd\mu} & \le\int_{K}\abs{f-f_{n}}\cdot\dd\abs{\mu}\le\sup_{K}\abs{f-f_{n}}\cdot\abs{\mu}\left(K\right)
\end{align*}

\end{itemize}

\chapter{The Spectral Theorem for symmetric bounded operators}

Let $A\in L\left(H\right)$ be symmetric and $H$ be a separable Hilbert
space. Let $p\left(A\right)$ be a polynomial in $A$, for example
the characteristic polynomial for $A\in L\left(\mathbb{C}^{N}\right)$
with $p\left(A\right)=0$.\\
Extend this idea to functions $f\left(A\right)$ with $f\in C^{0}\left(\sigma\left(A\right)\right)$.
(Stone-Weierstraß)\\
Then for
\begin{align*}
\left\langle u,f\left(A\right)u\right\rangle  & =:l\left(f\right)
\end{align*}
holds $l\in C^{0}\left(\sigma\left(A\right)\right)^{*}$. Using the
Riesz representation theorem we can write:
\begin{align*}
\left\langle u,f\left(A\right)u\right\rangle  & =\int_{\sigma\left(A\right)}f\left(\lambda\right)\dd\mu_{u}\left(\lambda\right)
\end{align*}
\begin{align*}
\dd\mu_{u}\left(\lambda\right) & =\left\langle u,\dd E_{\lambda}u\right\rangle 
\end{align*}
$\dd E_{\lambda}$ is the so-called \emph{spectral measure}. Then
holds the spectral theorem:
\begin{align*}
A & =\int_{\sigma\left(A\right)}\lambda\dd E_{\lambda}
\end{align*}



\section{The Spectrum of symmetric bounded operators}

Let $A\in L\left(H\right)$ be symmetric, i.e. $\left\langle u,Av\right\rangle =\left\langle Au,v\right\rangle $
for all $u,v\in H$. The resolvent set is:
\begin{align*}
\varrho\left(A\right) & =\left\{ \lambda\in\mathbb{C}\big|\left(\lambda-A\right)\text{ has a continuous inverse}\right\} \\
\sigma\left(A\right) & =\mathbb{C}\setminus\varrho\left(A\right)
\end{align*}
$\varrho\left(A\right)\subseteq\mathbb{C}$ is open and so the spectrum
$\sigma\left(A\right)\subseteq\mathbb{C}$ is closed. The spectral
radius is:
\begin{align*}
r\left(A\right) & =\sup_{\lambda\in\sigma\left(A\right)}\abs{\lambda}=\opnorm A
\end{align*}



\subsubsection*{Warning}

Consider $\lambda\in\sigma\left(A\right)$, i.e. $\lambda-A$ has
no continuous inverse. This does not mean $\ker\left(\lambda-A\right)$
is non-trivial. Thus $\lambda$ does \emph{not} need to be an eigenvalue!


\subsection{Theorem}

Let $A\in L\left(H\right)$ be self-adjoint. Then $\sigma\left(A\right)\subseteq\mathbb{R}$.


\subsubsection*{Proof}

Consider $\lambda=\alpha+\ii\beta$ with $\alpha,\beta\in\mathbb{R}$
and $\beta\not=0$. We need to show that $\lambda-A$ has a continuous
inverse. Introduce the following bilinear form:
\begin{align*}
B\left(x,y\right) & =\left\langle x,\left(A-\overline{\lambda}\right)y\right\rangle =\left\langle \left(A-\lambda\right)x,y\right\rangle 
\end{align*}
This bilinear form satisfies the assumptions of the Lax-Milgram theorem:
\begin{enumerate}[label=\roman*)]
\item The sesquilinearity is clear, since the scalar product is sesquilinear.
\item $B$ is bounded:
\begin{align*}
\abs{\left\langle x,\left(A-\overline{\lambda}\right)y\right\rangle } & \le\norm x\cdot\underbrace{\norm{A-\overline{\lambda}}}_{\le\norm A+\abs{\lambda}}\cdot\norm y\le C\norm x\norm y
\end{align*}

\item $B$ is bounded from below, i.e. there exists an $\varepsilon\in\mathbb{R}_{>0}$
such that for all $x\in H$ holds:
\begin{align*}
\abs{B\left(x,x\right)} & \ge\varepsilon\norm x^{2}
\end{align*}
We know:
\begin{align*}
B\left(x,x\right) & =\left\langle x,\left(A-\overline{\lambda}\right)x\right\rangle =\underbrace{\left\langle x,Ax\right\rangle }_{\text{real}}-\underbrace{\text{Re}\left(\lambda\left\langle x,x\right\rangle \right)}_{\text{real}}-\underbrace{\ii\text{Im}\left(\lambda\left\langle x,x\right\rangle \right)}_{\text{imaginary}}
\end{align*}
\begin{align*}
\abs{B\left(x,x\right)} & \ge\abs{\text{Im}\left(\lambda\left\langle x,x\right\rangle \right)}=\abs{\beta}\cdot\norm x^{2}
\end{align*}
Set $\varepsilon:=\abs{\beta}\not=0$.
\end{enumerate}
The Lax-Milgram theorem yields that the linear functional $l\left(x\right)=\left\langle z,x\right\rangle $
can be represented as
\begin{align*}
l\left(x\right) & =B\left(y,x\right)
\end{align*}
with a unique $y=y\left(z\right)\in H$. Thus we get for all $x\in H$:
\begin{align*}
\left\langle z,x\right\rangle  & =\left\langle \left(A-\lambda\right)y,x\right\rangle \\
\Rightarrow\quad z & =\left(A-\lambda\right)y
\end{align*}
Therefore, for all $z\in H$ exists a unique $y\in H$ su ch that
$\left(A-\lambda\right)y=x$. Thus $A-\lambda$ is invertible. The
inverse $\left(A-\lambda\right)^{-1}$ is continuous due to the open
mapping theorem (see Corollary \ref{sub:Cor-open-mapping}).\qqed

%DATE: Do 20.12.12


\subsection{Theorem}

It holds $\sigma\left(A\right)\subseteq\left[a,b\right]$ and $a,b\in\sigma\left(A\right)$
with:
\begin{align*}
a & :=\inf_{\norm u=1}\left\langle u,Au\right\rangle \\
b & :=\sup_{\norm u=1}\left\langle u,Au\right\rangle 
\end{align*}


\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[scale=2]
  \draw[->] (-1,0) -- (2,0) node[right] {$\lambda$};
  \draw (-0.65,0.1) -- (-0.7,0.1) -- (-0.7,-0.1) node[below] {$a$} -- (-0.65,-0.1);
  \draw (1.65,0.1) -- (1.7,0.1) -- (1.7,-0.1) node[below] {$b$} -- (1.65,-0.1);
  \node[blue] at (0.5,0.15) {$\sigma(A)$};
  \draw[blue, very thick] (1,0) -- (1.7,0) (-0.5,0) -- (0.5,0);
  \draw[blue,fill=blue] (-0.7,0) circle (0.03);
  \draw[blue,fill=blue] (1.7,0) circle (0.03);
\end{tikzpicture}\caption{$\sigma\left(A\right)\subseteq\left[a,b\right]$ and $a,b\in\sigma\left(A\right)$}
\end{figure}



\subsubsection*{Proof}

For $\lambda\in\mathbb{R}_{<a}$ holds:
\begin{align*}
\left\langle x,\left(A-\lambda\right)x\right\rangle  & =\left\langle x,Ax\right\rangle -\lambda\norm x^{2}\ge a\norm x^{2}-\lambda\norm x^{2}=\underbrace{\left(a-\lambda\right)}_{>0}\norm x^{2}
\end{align*}
Thus
\begin{align*}
\left\langle .,.\right\rangle _{A} & :=\left\langle .,\left(A-\lambda\right).\right\rangle 
\end{align*}
is a scalar product on $H$. The corresponding norm
\begin{align*}
\norm u_{A} & :=\sqrt{\left\langle u,u\right\rangle _{A}}
\end{align*}
is equivalent to the norm $\norm .$, because it holds:
\begin{align*}
\left(a-\lambda\right)\norm u^{2} & \le\norm u_{A}=\left\langle u,\left(A-\lambda\right)u\right\rangle \le\left(\opnorm A-\lambda\right)\norm u^{2}
\end{align*}
For $u\in H$ and $l\left(w\right):=\left\langle u,w\right\rangle $
is $l\in H^{*}$. According to the Fréchet-Riesz theorem \ref{sub:Thm-Frechet-Riesz}
(for the scalar product $\left\langle .,.\right\rangle _{A}$) there
is a unique vector $v\in H$, such that for all $w\in H$ holds:
\begin{align*}
l\left(w\right) & =\left\langle v,w\right\rangle _{A}
\end{align*}
Thus we get for all $w\in H$:
\begin{align*}
\left\langle u,w\right\rangle  & =l\left(w\right)=\left\langle v,w\right\rangle _{A}=\left\langle v,\left(A-\lambda\right)w\right\rangle \stackrel{A-\lambda\text{ symmetric}}{=}\left\langle \left(A-\lambda\right)v,w\right\rangle 
\end{align*}
\begin{align*}
\Rightarrow\quad u & =\left(A-\lambda\right)v
\end{align*}
Thus there exists a
\begin{align*}
\varphi:H & \to H\\
u & \mapsto v
\end{align*}
such that $u=\left(A-\lambda\right)\varphi\left(u\right)$, i.e. $A-\lambda\in L\left(H\right)$
is surjective. $\varphi$ is linear and bounded according to the open
mapping theorem \ref{sub:Cor-open-mapping}. Thus we have
\begin{align*}
\varphi & =\left(A-\lambda\right)^{-1}\in L\left(H\right)
\end{align*}
and therefore $\lambda\in\varrho\left(A\right)$.\\
Applying the same argument to the operator $\left(-A\right)$, one
sees that $\left(b,\infty\right)\subseteq\varrho\left(A\right)$.\\
Therefore holds $\sigma\left(A\right)\subseteq\left[a,b\right]$.

Only prove that $b\in\sigma\left(A\right)$. For $a\in\sigma\left(A\right)$
consider similarly the operator $-A$. Furthermore replace $A\to A-a$
to get $\sigma\left(A\right)\subseteq\left[0,b\right]$. We know:
\begin{align*}
\opnorm A & =r\left(A\right)=\sup_{\lambda\in\sigma\left(A\right)}\abs{\lambda}=\sup_{\lambda\in\sigma\left(A\right)}\lambda=\sup\sigma\left(A\right)
\end{align*}
As a consequence we get $\opnorm A\le b$. On the other hand we have:

\begin{align*}
b & =\sup_{\norm u=1}\left\langle u,Au\right\rangle \le\sup_{\norm u=1}\norm{Au}\cdot\underbrace{\norm u}_{=1}=\opnorm A
\end{align*}
Thus we have $b=\opnorm A=r\left(A\right)$, especially $b$ is a
limit point of the spectrum of $A$. Since $\sigma\left(A\right)$
is closed, it follows that $b\in\sigma\left(A\right)$.\qqed


\section{The continuous functional calculus}


\subsection{Theorem \textmd{(continuous functions of operators)}\label{sub:Thm-spectral-mapping-theorem}}

Let $A\in L\left(H\right)$ be symmetric. Then there is a unique mapping
$\Phi:C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)\to L\left(H\right)$
(remember $\sigma\left(A\right)\subseteq\left[a,b\right]$) with the
following properties:
\begin{enumerate}[label=\roman*)]
\item $\Phi$ is an involutive algebra homomorphism, i.e.:

\begin{itemize}
\item $\Phi$ is linear.
\item $\Phi\left(f\cdot g\right)=\Phi\left(f\right)\cdot\Phi\left(g\right)$
\item $\Phi\left(\overline{f}\right)=\left(\Phi\left(f\right)\right)^{*}$
(involution)
\end{itemize}
\item $\Phi$ is continuous:
\begin{align*}
\norm{\Phi\left(f\right)}_{L\left(H\right)} & \le C\norm f_{\infty}
\end{align*}

\item If $f\left(t\right)=t$, then $\Phi\left(f\right)=A$.
\item If $Au=\lambda u$, i.e. $u\in H$ is an eigenvector of $A$, then
$\Phi\left(f\right)u=f\left(\lambda\right)u$.
\item If $f\ge0$, then $\Phi\left(f\right)\ge0$, meaning that $\Phi\left(f\right)$
is a positive semi-definite operator, i.e. $\left\langle u,\Phi\left(f\right)u\right\rangle \ge0$
for all $u\in H$.
\item $\sigma\left(\Phi\left(f\right)\right)=f\left(\sigma\left(A\right)\right)$
(spectral mapping theorem (\foreignlanguage{ngerman}{spektraler Abbildungssatz}))
\item $\norm{\Phi\left(f\right)}_{L\left(H\right)}=\norm f_{\infty}$
\end{enumerate}
Often we just write $\Phi\left(f\right)=f\left(A\right)$.

What if $f\left(t\right)=p\left(t\right)=a_{n}t^{n}+a_{n-1}t^{n-1}+\ldots+a_{0}$
is a polynomial?
\begin{align*}
\Phi\left(t\right) & \stackrel{\text{iii)}}{=}A
\end{align*}
From i) follows:
\begin{align*}
\Phi\left(1\right) & =\Phi\left(1\cdot1\right)=\Phi\left(1\right)\cdot\Phi\left(1\right)
\end{align*}
Therefore we get:
\begin{align*}
\Phi\left(1\right) & =\mathbbm{1}
\end{align*}
Now follows:
\begin{align*}
\Phi\left(t^{2}\right) & =\Phi\left(t\cdot t\right)=\Phi\left(t\right)\cdot\Phi\left(t\right)=A\cdot A=A^{2}\\
\Phi\left(t^{l}\right) & =A^{l}\\
\Phi\left(p\right) & =p\left(A\right)=a_{n}A^{n}+a_{n-1}A^{n-1}+\ldots+a_{0}\mathbbm{1}
\end{align*}



\subsection{Lemma \textmd{(spectral mapping theorem for polynomials)}\label{sub:Lem-spectral-mapping-thm_polynomials}}

For a complex polynomial $p\in\mathbb{P}_{\mathbb{C}}$ holds:
\begin{align*}
\sigma\left(p\left(A\right)\right) & =p\left(\sigma\left(A\right)\right)
\end{align*}



\subsubsection*{Proof}
\begin{itemize}
\item If $p=c\in\mathbb{C}$ is constant, then the lemma is trivial:
\begin{align*}
p\left(\sigma\left(A\right)\right) & =c=\sigma\left(c\mathbbm{1}\right)=\sigma\left(p\left(A\right)\right)
\end{align*}
So further on let $p$ be not constant.
\item $p\left(\sigma\left(A\right)\right)\subseteq\sigma\left(p\left(A\right)\right)$:
For $\lambda\in\sigma\left(A\right)$ and $z\in\mathbb{C}$ yields
the fundamental theorem of algebra:
\begin{align*}
p\left(z\right)-p\left(\lambda\right) & =\left(z-\lambda\right)q\left(z\right)
\end{align*}
Here $q\left(z\right)$ is a new polynomial with $\deg\left(q\right)=\deg\left(p\right)-1$.
This also holds if we set $z=A$:
\begin{align*}
p\left(A\right)-p\left(\lambda\right) & =\left(A-\lambda\right)q\left(A\right)
\end{align*}
Assume $p\left(\lambda\right)\in\varrho\left(p\left(A\right)\right)$,
i.e. $p\left(A\right)-p\left(\lambda\right)$ has a bounded inverse.
Then holds:
\begin{align*}
\mathbbm{1} & =\left(p\left(A\right)-p\left(\lambda\right)\right)\cdot\left(p\left(A\right)-p\left(\lambda\right)\right)^{-1}=\left(A-\lambda\right)\cdot q\left(A\right)\cdot\left(p\left(A\right)-p\left(\lambda\right)\right)^{-1}\\
\Rightarrow\quad\left(A-\lambda\right)^{-1} & =\underbrace{q\left(A\right)}_{\in L\left(H\right)}\cdot\underbrace{\left(p\left(A\right)-p\left(\lambda\right)\right)^{-1}}_{\in L\left(H\right)}\in L\left(H\right)
\end{align*}
This gives $\lambda\in\varrho\left(A\right)$ in contradiction to
$\lambda\in\sigma\left(A\right)$ and so $p\left(\lambda\right)\in\sigma\left(p\left(A\right)\right)$.
\item $\sigma\left(p\left(A\right)\right)\subseteq p\left(\sigma\left(A\right)\right)$:
Consider $\mu\in\sigma\left(p\left(A\right)\right)$ and set $n:=\text{deg}\left(p\right)$.
Using the fundamental theorem of algebra we get:
\begin{align*}
q\left(z\right):=p\left(z\right)-\mu & =a\left(z-\lambda_{1}\right)\cdot\ldots\cdot\left(z-\lambda_{n}\right)\\
q\left(A\right):=p\left(A\right)-\mu & =a\left(A-\lambda_{1}\right)\cdot\ldots\cdot\left(A-\lambda_{n}\right)
\end{align*}
If all the operators $A-\lambda_{i}$ had a continuous inverse, then
this would hold also for their product in contradiction to the assumption
$\mu\in\sigma\left(p\left(A\right)\right)$. Thus one of the $\lambda_{i}$
is in the spectrum of $A$. Because one of the linear factors vanishes,
follows:
\begin{align*}
0 & =q\left(\lambda_{i}\right)=p\left(\lambda_{i}\right)-\mu\\
\Rightarrow\quad\mu & =p\left(\lambda_{i}\right)\in p\left(\sigma\left(A\right)\right)
\end{align*}

\end{itemize}
\qqed

Let $p\in\mathbb{P}_{\mathbb{C}}$ be a complex polynomial.
\begin{align*}
\left(p\left(A\right)\right)^{*} & =\overline{p}\left(A\right)
\end{align*}
Thus $p\left(A\right)$ is not symmetric.


\subsection{Definition \textmd{(normal operator)}}

$A\in L\left(H\right)$ is called \emph{normal}, if $\left[A,A^{*}\right]=0$.


\subsection{Theorem\label{sub:Thm-normal-operator}}

For a normal $A\in L\left(H\right)$ holds $r\left(A\right)=\opnorm A$.

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
  \draw (0,0) circle (2);
  \draw[->] (0,0) -- node[above]{$r(A)$} (-2,0);
  \draw plot[smooth cycle,tension=.7] coordinates{(1.2,-1.2) (1,-1.6) (0,-1.1) (0.2,0) (0.2,0.5) (-0.2,0.7) (-0.5,1.4) (1,1)};
  \node at (0.7,-0.2) {$\sigma(A)$};
\end{tikzpicture}\caption{$r\left(A\right)=\opnorm A$}
\end{figure}



\subsubsection*{Proof}

We already proved for a general $A\in L\left(H\right)$:
\begin{align}
r\left(A\right) & =\sup_{\lambda\in\sigma\left(A\right)}\abs{\lambda}=\lim_{n\to\infty}\opnorm{A^{n}}^{\frac{1}{n}}\label{eq:rA_lim}
\end{align}
For symmetric operators, we know furthermore:
\begin{align}
r\left(A\right) & =\opnorm A=\sup_{\norm u=1}\abs{\left\langle u,Au\right\rangle }\label{eq:rA_normA}
\end{align}
For \emph{normal} operators, we conclude the following: $A^{*}A$
is symmetric and thus:
\begin{align*}
\opnorm A^{2} & =\sup_{\norm u=1}\norm{Au}^{2}=\sup_{\norm u=1}\left\langle Au,Au\right\rangle =\sup_{\norm u=1}\left\langle u,A^{*}Au\right\rangle \stackrel{\eqref{eq:rA_normA}}{=}\opnorm{A^{*}A}=\\
 & \stackrel{\eqref{eq:rA_normA}}{=}r\left(A^{*}A\right)\stackrel{\eqref{eq:rA_lim}}{=}\lim_{n\to\infty}\opnorm{\left(A^{*}A\right)^{n}}^{\frac{1}{n}}
\end{align*}
\begin{align*}
\left(A^{*}A\right)^{n} & =\underbrace{A^{*}A\cdot A^{*}A\cdot\ldots\cdot A^{*}A}_{n\text{-times}}\stackrel{A\text{ normal}}{=}\left(A^{*}\right)^{n}\cdot A^{n}
\end{align*}
With 
\begin{align*}
\opnorm A^{2} & =\sup_{\norm u=1}\left\langle Au,Au\right\rangle =\sup_{\norm u=1}\left\langle u,A^{*}Au\right\rangle \stackrel{A\text{ normal}}{=}\sup_{\norm u=1}\left\langle u,AA^{*}u\right\rangle =\sup_{\norm u=1}\left\langle A^{*}u,A^{*}u\right\rangle =\opnorm{A^{*}}^{2}
\end{align*}
we get:
\begin{align*}
\opnorm{\left(A^{*}A\right)^{n}} & \le\opnorm{\left(A^{*}\right)^{n}}\cdot\opnorm{A^{n}}=\opnorm{A^{n}}^{2}
\end{align*}
It follows:
\begin{align*}
\opnorm A^{2} & =\lim_{n\to\infty}\opnorm{\left(A^{*}A\right)^{n}}^{\frac{1}{n}}\le\lim_{n\to\infty}\left(\opnorm{A^{n}}^{2}\right)^{\frac{1}{n}}\le\opnorm A^{2}
\end{align*}
This gives:
\begin{align*}
\opnorm A^{2} & =\lim_{n\to\infty}\left(\opnorm{A^{n}}^{\frac{1}{n}}\right)^{2}=\left(\lim_{n\to\infty}\opnorm{A^{n}}^{\frac{1}{n}}\right)^{2}=\left(r\left(A\right)\right)^{2}
\end{align*}
\begin{align*}
\Rightarrow\quad r\left(A\right) & =\opnorm A
\end{align*}
\qqed


\subsection{Lemma}

Let $A\in L\left(H\right)$ be symmetric and $p\in\mathbb{P}_{\mathbb{C}}$
a complex polynomial. Then holds:
\begin{align*}
\opnorm{p\left(A\right)} & =\sup_{\lambda\in\sigma\left(A\right)}\abs{p\left(\lambda\right)}
\end{align*}



\subsubsection*{Proof}

$p\left(A\right)$ is normal and thus, according to Theorem \ref{sub:Thm-normal-operator}
holds:
\begin{align*}
\opnorm{p\left(A\right)} & =\sup_{\mu\in\sigma\left(p\left(A\right)\right)}\abs{\mu}\stackrel{\ref{sub:Lem-spectral-mapping-thm_polynomials}}{=}\sup_{\lambda\in\sigma\left(A\right)}\abs{p\left(\lambda\right)}
\end{align*}
\qqed


\subsubsection*{Proof of theorem \ref{sub:Thm-spectral-mapping-theorem}}
\begin{itemize}
\item For complex polynomials, we set $\Phi\left(p\right)=p\left(A\right)$.
Then holds:
\begin{align*}
\opnorm{\Phi\left(p\right)}=\opnorm{p\left(A\right)} & =r\left(p\left(A\right)\right)=\sup_{\lambda\in\sigma\left(A\right)}\abs{p\left(\lambda\right)}=\norm p_{C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)}
\end{align*}
Thus $\Phi:\mathbb{P}_{\mathbb{C}}\to L\left(H\right)$ is an isometry.
($\mathbb{P}_{\mathbb{C}}\subseteq C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)$)\\
\emph{Remark:} If we had considered $C^{0}\left(\left[a,b\right],\mathbb{C}\right)$
with
\begin{align*}
a & =\inf_{\norm u=1}\left\langle u,Au\right\rangle \\
b & =\sup_{\norm u=1}\left\langle u,Au\right\rangle 
\end{align*}
then we would only have an inequality:
\begin{align*}
\opnorm{\Phi\left(p\right)} & \le\norm p_{C^{0}\left(\left[a,b\right]\right)}
\end{align*}

\item Moreover holds:
\begin{align*}
\Phi\left(p\cdot q\right) & =\left(p\cdot q\right)\left(A\right)=p\left(A\right)\cdot q\left(A\right)=\Phi\left(p\right)\cdot\Phi\left(q\right)\\
\left(\Phi\left(p\right)\right)^{*} & =\Phi\left(\overline{p}\right)
\end{align*}

\item Using the Stone-Weierstraß approximation theorem, $\Phi$ uniquely
extends to an isometry:
\begin{align*}
\Phi:C^{0}\left(\sigma\left(A\right),\mathbb{C}\right) & \to L\left(H\right)
\end{align*}
This yields i), ii), iii), vii).
\item More specifically, consider $f\in C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)$.
Then there exist $p_{n}\in\mathbb{P}_{\mathbb{C}}$ such that $p_{n}\rightrightarrows f$
on $\sigma\left(A\right)$. ($K=\sigma\left(A\right)$ is a compact
metric space.) This means:
\begin{align*}
\norm{p_{n}-f}_{C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)} & =\sup_{z\in\sigma\left(A\right)}\abs{p_{n}\left(z\right)-f\left(z\right)}\xrightarrow{n\to\infty}0
\end{align*}
\begin{align*}
\opnorm{\Phi\left(p_{n}\right)-\Phi\left(p_{m}\right)} & \stackrel{\text{isometry}}{=}\norm{p_{n}-p_{m}}\xrightarrow{n,m\to\infty}0
\end{align*}
Thus the operators $\Phi\left(p_{n}\right)$ form a Cauchy sequence
in $L\left(H\right)$ and since $L\left(H\right)$ is a Banach space,
this sequence converges to:
\begin{align*}
\Phi\left(f\right) & :=\lim_{n\to\infty}\Phi\left(p_{n}\right)
\end{align*}
\end{itemize}
\begin{enumerate}
\item [iv)]For $Au=\lambda u$ holds:
\begin{align*}
\Phi\left(f\right)u & =\lim_{n\to\infty}\Phi\left(p_{n}\right)u=\lim_{n\to\infty}p_{n}\left(A\right)u=\lim_{n\to\infty}p_{n}\left(\lambda\right)u=f\left(\lambda\right)u
\end{align*}
%DATE: Fr 21.12.12
\item [vi)]Now we prove the spectral mapping theorem:\\
„$\subseteq$“: Assume $\mu\in\sigma\left(f\left(A\right)\right)$,
but $\mu\not\in f\left(\sigma\left(A\right)\right).$ Then holds $f-\mu\not=0$
on $\sigma\left(A\right)$ and we can invert:
\begin{align*}
\frac{1}{f-\mu} & \in C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)
\end{align*}
Now follows:
\begin{align*}
\mathbbm{1} & =\Phi\left(1\right)=\Phi\left(\frac{1}{f-\mu}\left(f-\mu\right)\right)=\underbrace{\Phi\left(\frac{1}{f-\mu}\right)}_{\in L\left(H\right)}\cdot\underbrace{\Phi\left(f-\mu\right)}_{=f\left(A\right)-\mu\mathbbm{1}}
\end{align*}
So $f\left(A\right)-\mu\mathbbm{1}$ has a bounded inverse in contradiction
to the assumption $\mu\in\sigma\left(f\left(A\right)\right)$.\\
„$\supseteq$“: Consider $\lambda\in\sigma\left(A\right)$. Choose
polynomials $p_{n}\in\mathbb{P}_{\mathbb{C}}$ with $p_{n}\rightrightarrows f$.
Then converges in $L\left(H\right)$:
\begin{align*}
p_{n}\left(A\right)-p_{n}\left(\lambda\right)\mathbbm{1} & \xrightarrow{n\to\infty}f\left(A\right)-f\left(\lambda\right)\mathbbm{1}
\end{align*}
Assume that $f\left(\lambda\right)\not\in\sigma\left(f\left(A\right)\right)$.
Then $f\left(A\right)-f\left(\lambda\right)\mathbbm{1}$ has a bounded
inverse.\\
According to Theorem \ref{sub:Thm-set-cont-invertible-->open}, the
invertible operators are open in $L\left(H\right)$. Therefore there
exists a $\delta\in\mathbb{R}_{>0}$ such that $B$ has a bounded
inverse for all $B\in B_{\delta}\left(f\left(A\right)-f\left(\lambda\right)\mathbbm{1}\right)$.
In particular, the operators $p_{n}\left(A\right)-p_{n}\left(\lambda\right)\mathbbm{1}$
have a bounded inverse for sufficiently large $n$.\\
This is a contradiction to the spectral mapping theorem for polynomials
\ref{sub:Lem-spectral-mapping-thm_polynomials}.
\item [v)]Claim: $f\ge0\quad\Rightarrow\quad\Phi\left(f\right)\ge0$\\
Let $f\in C^{0}\left(\sigma\left(A\right),\mathbb{R}\right)$ be real-valued
and $f\ge0$. Then $g:=\sqrt{f}\in C^{0}\left(\sigma\left(A\right),\mathbb{R}\right)$
and $f=g^{2}$.
\begin{align*}
\left\langle u,\Phi\left(f\right)u\right\rangle  & =\left\langle u,\Phi\left(g^{2}\right)u\right\rangle =\left\langle u,\Phi\left(g\right)\Phi\left(g\right)u\right\rangle =\left\langle \Phi\left(\overline{g}\right)u,\Phi\left(g\right)u\right\rangle =\left\langle \Phi\left(g\right)u,\Phi\left(g\right)u\right\rangle \ge0
\end{align*}

\end{enumerate}
\qqed[\ref{sub:Thm-spectral-mapping-theorem}]

$\chi_{\Omega}\left(A\right)$ would be the projector onto the invariant
subspace corresponding to the spectrum in~$\Omega$. Formally we
can compute:
\begin{align*}
\left(\chi_{\Omega}\left(A\right)\right)^{*} & =\overline{\chi_{\Omega}}\left(A\right)=\chi_{\Omega}\left(A\right)\\
\chi_{\Omega}\left(A\right)\chi_{\Omega}\left(A\right) & =\chi_{\Omega}^{2}\left(A\right)=\chi_{\Omega}\left(A\right)
\end{align*}
This motivates, why we would like to form $f\left(A\right)$ for a
bounded Borel function $f$ on $\sigma\left(A\right)$.


\section{Spectral Measures}

Let $A\in L\left(H\right)$ be symmetric. Choose a $u\in H$ (fixed).
\begin{align*}
\Phi_{u}:C^{0}\left(\sigma\left(A\right),\mathbb{R}\right) & \to\mathbb{R}\subseteq\mathbb{C}\\
f & \mapsto\left\langle u,\Phi\left(f\right)u\right\rangle 
\end{align*}
\begin{align*}
\abs{\Phi_{u}\left(f\right)} & =\abs{\left\langle u,\Phi\left(f\right)u\right\rangle }\le\opnorm{\Phi\left(f\right)}\cdot\norm u^{2}=\norm f_{C^{0}\left(\sigma\left(A\right),\mathbb{R}\right)}\cdot\norm u^{2}
\end{align*}
Thus $\phi_{u}$ is a bounded linear functional on $C^{0}\left(\sigma\left(A\right),\mathbb{R}\right)$.
According to the Riesz representation theorem there exists a unique
regular bounded Borel measure $\mu_{u}$ such that:
\begin{align*}
\left\langle u,f\left(A\right)u\right\rangle  & =\int_{\sigma\left(A\right)}f\left(\lambda\right)\dd\mu_{u}\left(\lambda\right)
\end{align*}
The measure $\mu_{u}$ is even positive, because if $f\ge0$, set
$g=\sqrt{f}$ to get:
\begin{align*}
\int_{\sigma\left(A\right)}f\left(\lambda\right)\dd\mu_{u}\left(\lambda\right)=\left\langle u,f\left(A\right)u\right\rangle  & =\left\langle g\left(A\right)u,g\left(A\right)u\right\rangle \ge0\qquad\fall_{f\in C^{0}\left(\sigma\left(A\right),\mathbb{R}\right),\ f\ge0}
\end{align*}
Hence by approximation follows $\mu_{u}\left(\Omega\right)\ge0$ for
all Borel sets $\Omega\subseteq\sigma\left(A\right)$. So $\mu_{u}$
is a positive measure.\\
The resulting integral can be defined for a more general class of
functions.\\
A \emph{Borel function} $f$ is a function, which is measurable for
the Borel algebra, i.e. $f^{-1}\left(\Omega\right)$ is a Borel function
for all open $\Omega\subseteq\mathbb{C}$.\\
We use the following notation: $\mathfrak{M}$ is the set of all Borel
sets in $\sigma\left(A\right)$.\\
$\mathcal{B}\left(\sigma\left(A\right),\mathbb{R}\right)=L^{\infty}\left(\dd\mu_{u}\right)$
are the bounded Borel functions on $\sigma\left(A\right)$. We always
assume:
\begin{align*}
\sup_{\sigma\left(A\right)}\abs f & <\infty
\end{align*}
We define:
\begin{align*}
\phi_{u}:\mathcal{B}\left(\sigma\left(A\right),\mathbb{R}\right) & \to\mathbb{R}\\
\phi_{u}\left(f\right) & :=\int_{\sigma\left(A\right)}f\left(\lambda\right)\dd\mu_{u}\left(\lambda\right)
\end{align*}



\subsection{Lemma\label{sub:Lem-phiu}}

\begin{align*}
\abs{\phi_{u}\left(f\right)} & \le\norm f_{L^{\infty}}\cdot\norm u^{2}
\end{align*}



\subsubsection*{Proof}

For $f\in\mathcal{B}\left(\sigma\left(A\right),\mathbb{R}\right)$
choose $\varphi_{n}\in C^{0}\left(\sigma\left(A\right),\mathbb{R}\right)$
such that $\varphi_{n}\to f$ converges point-wise and $\norm{\varphi_{n}}_{\infty}\le\norm f_{\infty}$.
(Approximate $f$ by step-functions and then approximate the step
functions by continuous functions.)\\
Due to $\abs{\varphi_{n}}\le C$ and 
\begin{align*}
\int_{\sigma\left(A\right)}C\dd\mu_{u} & =C\mu_{u}\left(\sigma\left(A\right)\right)=C\left\langle u,\Phi\left(1\right)u\right\rangle =C\left\langle u,\mathbbm{1}u\right\rangle =C\norm u^{2}<\infty
\end{align*}
we can use the dominated convergence theorem: 
\begin{align*}
\abs{\int_{\sigma\left(A\right)}f\dd\mu_{u}} & \sr ={\text{dominated}}{\text{convergence}}\lim_{n\to\infty}\abs{\int_{\sigma\left(A\right)}^{\infty}\varphi_{n}\dd\mu_{n}}=\lim_{n\to\infty}\abs{\left\langle u,\Phi\left(\varphi_{n}\right)u\right\rangle }\le\\
 & \le\lim_{n\to\infty}\norm u^{2}\cdot\norm{\Phi\left(\varphi_{n}\right)}=\lim_{n\to\infty}\norm u^{2}\cdot\norm{\varphi_{n}}\le\norm f\cdot\norm u^{2}
\end{align*}
\qqed

Define using the Fréchet-Riesz theorem the unique Operator $\Phi\left(f\right)$
by:

\begin{align*}
\Phi_{u}\left(f\right) & :=\left\langle u,\Phi\left(f\right)u\right\rangle 
\end{align*}
By polarization we get: 
\begin{align*}
B_{f}\left(u,v\right) & =\Phi_{\frac{u+v}{2}}\left(f\right)-\Phi_{\frac{u-v}{2}}\left(f\right)-\ii\Phi_{\frac{u+\ii v}{2}}\left(f\right)+\ii\Phi_{\frac{u-\ii v}{2}}\left(f\right)
\end{align*}
Alternatively define for $f\in C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)$:
\begin{align*}
\Phi_{u,v}\left(f\right) & :=\left\langle u,\Phi\left(f\right)v\right\rangle =\int_{\sigma\left(A\right)}f\left(\lambda\right)\dd\mu_{u,v}\left(\lambda\right)
\end{align*}
\begin{align*}
B_{f}\left(u,v\right) & :=\int_{\sigma\left(A\right)}f\left(\lambda\right)\dd\mu_{u,v}\left(\lambda\right)
\end{align*}
$\dd\mu_{u,v}$ is a only a \emph{complex-valued,} bounded, regular
Borel measure.


\subsection{Lemma}

$B_{f}\left(u,v\right)$ is a \emph{sesquilinear form}, i.e. linear
in the second and anti-linear in the first argument, and it holds:
\begin{align*}
\abs{B_{f}\left(u,v\right)} & \le\norm f\cdot\norm u\cdot\norm v
\end{align*}



\subsubsection*{Proof}

This follows from the polarization formula and Lemma \ref{sub:Lem-phiu}.\qqed


\subsection{Theorem}

Let $B$ be a bounded sesquilinear form, i.e.:
\begin{align*}
\abs{B\left(u,v\right)} & \le C\cdot\norm u\cdot\norm v\qquad\fall_{u,v\in H}
\end{align*}
Then there is a unique operator $D\in L\left(H\right)$ with $\opnorm D\le C$
such that:
\begin{align*}
B\left(u,v\right) & =\left\langle u,Dv\right\rangle 
\end{align*}



\subsubsection*{Proof}

For $v\in H$ the map
\begin{align*}
\psi & :=\overline{B\left(.,v\right)}
\end{align*}
is a bounded linear form. According to the Fréchet-Riesz theorem \ref{sub:Thm-Frechet-Riesz}
there exists a $w\in H$ such that for all $u\in H$ holds:
\begin{align*}
\psi\left(u\right) & =\left\langle w,u\right\rangle 
\end{align*}
Then follows:
\begin{align*}
B\left(u,v\right) & =\overline{\left\langle w,u\right\rangle }=\left\langle u,w\right\rangle 
\end{align*}
Thus $D$ is uniquely determined by $Dv=w$. So $D:H\to H$ is linear
and bounded by the open mapping principle \ref{sub:Thm-Open-mapping},
i.e. $D\in L\left(H\right)$ and for all $v\in H$ holds:
\begin{align*}
B\left(u,v\right) & =\left\langle u,Dv\right\rangle 
\end{align*}
Choose $u=Dv$ to get:
\begin{align*}
B\left(Dv,v\right) & =\left\langle Dv,Dv\right\rangle =\norm{Dv}^{2}\\
 & \le C\cdot\norm{Dv}\cdot\norm v
\end{align*}
Therefore we have for all $v\in H$:
\begin{align*}
\norm{Dv} & \le C\cdot\norm v\\
\opnorm D & \le C
\end{align*}
\qqed

We conclude: For $f\in\mathcal{B}\left(\sigma\left(A\right),\mathbb{C}\right)$
we construct $B_{f}\left(u,v\right)$. Then there exists a $\Phi\left(f\right)\in L\left(H\right)$
such that for all $u,v\in H$ holds:
\begin{align*}
\left\langle u,\Phi\left(f\right)v\right\rangle  & =B_{f}\left(u,v\right)
\end{align*}
So $\Phi:\mathcal{B}\left(\sigma\left(A\right),\mathbb{C}\right)\to L\left(H\right)$
gives a functional calculus on $\mathcal{B}\left(\sigma\left(A\right),\mathbb{C}\right)$,
i.e. we can calculate $f\left(A\right)$ for an arbitrary Borel function.

%DATE: Do 10.1.13


\subsection{Theorem \textmd{(Spectral theorem in functional calculus form)\label{sub:Thm-Spectral-theorem-functional-calculus}}}

Let $A\in L\left(H\right)$ be symmetric. Then there is a unique mapping
$\Phi:\mathcal{B}\left(\sigma\left(A\right)\right)\to L\left(H\right)$
with the following properties:
\begin{enumerate}[label=\roman*)]
\item $\Phi$ is an involutive algebra homomorphism, i.e.:
\begin{align*}
\Phi\left(f\right)\cdot\Phi\left(g\right) & =\Phi\left(f\cdot g\right)\\
\Phi\left(f\right)^{*} & =\Phi\left(\,\overline{f}\,\right)
\end{align*}
If $f\in C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)$, then
$\Phi\left(f\right)$ agrees with the corresponding operator of the
continuous functional calculus.
\item $\opnorm{\Phi\left(f\right)}\le\norm f_{\infty}$
\item If $f_{n}\to f$ converges point-wise and it holds $\norm{f_{n}}_{\infty}<C$,
then $\Phi\left(f_{n}\right)\to\Phi\left(f\right)$ converges strongly,
i.e. for all $u\in H$ converges in $H$:
\begin{align*}
\Phi\left(f_{n}\right)u & \to\Phi\left(f\right)u
\end{align*}

\item From $Au=\lambda u$ follows:
\begin{align*}
\Phi\left(f\right)u & =f\left(\lambda\right)u
\end{align*}

\item If $f\ge0$ holds, then $\Phi\left(f\right)\ge0$ is positive semidefinite.
\item If $B\in L\left(H\right)$ commutes with $A$, i.e. $\left[A,B\right]=AB-BA=0$,
then $\left[B,\Phi\left(f\right)\right]=0$. We write also $f\left(A\right)=\Phi\left(f\right)$.
\end{enumerate}
\emph{Note:} There is no spectral mapping theorem.


\subsubsection*{Proof}
\begin{enumerate}[label=\roman*)]
\item Prove the homomorphism property by approximation:\\
\emph{First step:} Assume $f\in C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)$
and $g\in\mathcal{B}\left(\sigma\left(A\right),\mathbb{C}\right)$.
Then there exists a series $g_{n}\in C^{0}$ such that $g_{n}\to g$
converges point-wise and $\norm{g_{n}}_{\infty}<C$. Then follows
the point-wise convergence:
\begin{align*}
fg_{n} & \to fg
\end{align*}
We use the notation:
\begin{align*}
\phi_{u,v}\left(h\right) & :=\left\langle u,\Phi\left(h\right)v\right\rangle \\
\Rightarrow\qquad\phi_{u,u}\left(h\right) & =\phi_{u}\left(h\right)
\end{align*}
Since $\mu_{u}$ is a regular bounded Borel measure, we can apply
the dominated convergence theorem:
\begin{align*}
\phi_{u,u}\left(f\cdot g\right) & \stackrel{\text{Definition}}{=}\int_{\sigma\left(A\right)}f\cdot g\dd\mu_{u}\sr ={\text{dominated}}{\text{convergence}}\lim_{n\to\infty}\int_{\sigma\left(A\right)}f\cdot g_{n}\dd\mu_{u}=\lim_{n\to\infty}\phi_{u,u}\left(f,g_{n}\right)=\\
 & =\lim_{n\to\infty}\left\langle u,\Phi\left(f\cdot g_{n}\right)u\right\rangle =\lim_{n\to\infty}\left\langle u,f\left(A\right)\cdot g_{n}\left(A\right)u\right\rangle =\\
 & =\lim_{n\to\infty}\left\langle \left(f\left(A\right)\right)^{*}u,g_{n}\left(A\right)u\right\rangle =\lim_{n\to\infty}\phi_{\left(f\left(A\right)\right)^{*}u,u}\left(g_{n}\right)
\end{align*}
We know for all $u\in H$ using dominated convergence (see above):
\begin{align*}
\phi_{u,u}\left(g_{n}\right) & \to\phi_{u,u}\left(g\right)
\end{align*}
By polarization follows for all $u,v\in H$:
\begin{align*}
\phi_{v,u}\left(g_{n}\right) & \to\phi_{v,u}\left(g\right)
\end{align*}
This gives:
\begin{align*}
\phi_{u,u}\left(f\cdot g\right) & =\lim_{n\to\infty}\phi_{\left(f\left(A\right)\right)^{*}u,u}\left(g_{n}\right)=\phi_{\left(f\left(A\right)\right)^{*}u,u}\left(g\right)=\left\langle \left(f\left(A\right)\right)^{*}u,\Phi\left(g\right)u\right\rangle 
\end{align*}
\begin{align*}
\Rightarrow\quad\left\langle u,\Phi\left(f\cdot g\right)u\right\rangle  & =\left\langle u,f\left(A\right)\cdot g\left(A\right)u\right\rangle 
\end{align*}
Polarization yields:
\begin{align*}
\Phi\left(fg\right) & =\Phi\left(f\right)\cdot\Phi\left(g\right)
\end{align*}
\emph{Second Step:} Consider $f,g\in\mathcal{B}$. We choose $f_{n}\in C^{0}$
with $f_{n}\to f$ and $\norm{f_{n}}<C$. Then $f_{n}\cdot g\to f\cdot g$
converges point-wise.
\begin{align*}
\left\langle u,\Phi\left(f\cdot g\right)u\right\rangle  & \sr ={\text{dominated}}{\text{convergence}}\lim_{n\to\infty}\left\langle u,\Phi\left(f_{n}\cdot g\right)u\right\rangle \sr ={\text{First step}}{}\lim_{n\to\infty}\left\langle u,\Phi\left(f_{n}\right)\cdot\Phi\left(g\right)u\right\rangle =\\
 & =\lim_{n\to\infty}\phi_{u,g\left(A\right)u}\left(f_{n}\right)=\phi_{u,g\left(A\right)u}\left(f\right)=\left\langle u,f\left(A\right)g\left(A\right)u\right\rangle 
\end{align*}
\begin{align*}
\Rightarrow\qquad\left\langle u,\left(\Phi\left(fg\right)-\Phi\left(f\right)\Phi\left(g\right)\right)u\right\rangle  & =0\qquad\fall_{u\in H}
\end{align*}
By polarization follows:
\begin{align*}
\Phi\left(fg\right) & =\Phi\left(f\right)\Phi\left(g\right)
\end{align*}
The involution property follows similarly.\qqed[\roman{enumi})]
\item [iii)]Claim: From point-wise convergence $f_{n}\to f$ and $\norm{f_{n}}<C$
follows strong convergence $f_{n}\left(A\right)\to f\left(A\right)$.

\begin{enumerate}[label=\alph*)]
\item From the dominated convergence theorem it is clear that holds:
\begin{align*}
\phi_{u}\left(f_{n}\right) & \to\phi_{u}\left(f\right)\\
\left\langle u,f_{n}\left(A\right)u\right\rangle  & \to\left\langle u,f\left(A\right)u\right\rangle 
\end{align*}
Polarization gives for all $u,v\in H$:
\begin{align*}
\left\langle u,f_{n}\left(A\right)v\right\rangle  & \to\left\langle u,f\left(A\right)v\right\rangle 
\end{align*}
In other words for all $v\in H$ holds:
\begin{align*}
f_{n}\left(A\right)v & \rightharpoondown f\left(A\right)v
\end{align*}

\item It holds:
\begin{align*}
\norm{f_{n}\left(A\right)v}^{2} & =\left\langle f_{n}\left(A\right)v,f_{n}\left(A\right)v\right\rangle =\left\langle v,\left(f_{n}\left(A\right)\right)^{*}f_{n}\left(A\right)v\right\rangle =\\
 & =\left\langle v,\overline{f_{n}}\left(A\right)f_{n}\left(A\right)v\right\rangle =\left\langle v,\abs{f_{n}\left(A\right)}^{2}v\right\rangle \sr{\to}{\text{dominated}}{\text{convergence}}\left\langle v,\abs f^{2}\left(A\right)v\right\rangle =\\
 & =\left\langle v,\overline{f}\left(A\right)f\left(A\right)v\right\rangle =\left\langle f\left(A\right)v,f\left(A\right)v\right\rangle =\norm{f\left(A\right)v}^{2}
\end{align*}

\item Now apply the following general Lemma:

\begin{description}
\item [{Lemma:}] $u_{n}\rightharpoondown u$ and $\norm{u_{n}}\to\norm u$
imply $u_{n}\to u$.
\item [{Proof:}] 
\begin{align*}
\norm{u-u_{n}} & =\left\langle u-u_{n},u-u_{n}\right\rangle =\\
 & =\norm u^{2}-2\text{Re}\underbrace{\left\langle u,u_{n}\right\rangle }_{\sr{}{\to\left\langle u,u\right\rangle }{\text{because }u\rightharpoondown u_{n}}}+\underbrace{\norm{u_{n}}^{2}}_{\sr{}{\to\norm u^{2}}{\text{because }\norm{u_{n}}\to\norm u}}\to\norm u^{2}-2\norm u^{2}+\norm u^{2}=0
\end{align*}
\qqed[Lemma]
\end{description}
\end{enumerate}
\begin{enumerate}[resume]
\item This gives:
\begin{align*}
f_{n}\left(A\right)v & \to f\left(A\right)v
\end{align*}
\qqed[iii)]
\end{enumerate}
\end{enumerate}
\begin{enumerate}[resume]
\item [ii)]Claim: $\norm{f\left(A\right)}\le\norm f_{\infty}$ for $f\in\mathcal{B}$.\\
Choose $f_{n}\in C^{0}$ which converge point-wise to $f$ and $\norm{f_{n}}_{\infty}<\norm f$.
\begin{align*}
\norm{f\left(A\right)u} & \stackrel{\text{iii)}}{=}\lim_{n\to\infty}\norm{f_{n}\left(A\right)u}\le\lim_{n\to\infty}\underbrace{\opnorm{f_{n}\left(A\right)}}_{=\norm{f_{n}}_{\infty}}\cdot\norm u=\lim_{n\to\infty}\norm{f_{n}}_{\infty}\cdot\norm u=\norm f_{\infty}\cdot\norm u
\end{align*}
\begin{align*}
\Rightarrow\qquad\opnorm{f\left(A\right)} & \le\norm f_{\infty}
\end{align*}
\qqed[ii)]
\item [iv) - vi)]follow immediately by approximation.
\end{enumerate}
\qqed


\subsection{Remark}

So far we considered Borel measures on $\sigma\left(A\right)\subseteq\mathbb{R}$.
These measures can be extended to Borel measures on $\mathbb{R}$
by defining for a Borel set $\Omega\in\mathfrak{M}\left(\mathbb{R}\right)$:
\begin{align*}
\mu\left(\Omega\right) & :=\mu\left(\Omega\cap\sigma\left(A\right)\right)
\end{align*}
$\Omega\cap\sigma\left(A\right)$ is a Borel set of $\sigma\left(A\right)$,
since $\sigma\left(A\right)$ is closed.

Now let $M\subseteq\mathfrak{M}\left(\mathbb{R}\right)$ be a Borel
set. $f\left(A\right)$ is well defined for any $f\in\mathcal{B}\left(\mathbb{R}\right)$.
With the characteristic function $\chi_{M}$ of $M$ define:
\begin{align*}
E_{M} & :=\chi_{M}\left(A\right)
\end{align*}
Then we get:
\begin{align*}
E_{M}^{*} & =\overline{\chi_{M}}\left(A\right)=\chi_{M}\left(A\right)=E_{M}\\
E_{M}^{2} & =\chi_{M}\left(A\right)\cdot\chi_{M}\left(A\right)=\left(\chi_{M}\cdot\chi_{M}\right)\left(A\right)=\chi_{M}\left(A\right)=E_{M}
\end{align*}
Thus $E_{M}$ is symmetric and idempotent, in other words $E_{M}$
is a projection operator.

The mapping $M\mapsto E_{M}$ is the spectral measure.


\subsection{Definition \textmd{(projection operator, spectral measure)\label{sub:Def-Spectral-measure}}}

$P\in L\left(H\right)$ is a \emph{projection operator} if $P^{2}=P=P^{*}$.\\
An operator-valued \emph{spectral measure} $E$ is a mapping
\begin{align*}
E:\mathfrak{M}\left(\mathbb{R}^{n}\right) & \to L\left(H\right)\\
M & \mapsto E_{M}:=E\left(M\right)
\end{align*}
with the following properties:
\begin{enumerate}[label=\roman*)]
\item $E_{M}$ is a projection operator for all $M\in\mathfrak{M}$.
\item $E_{\emptyset}=0$, $E_{\mathbb{R}^{n}}=\mathbbm{1}$
\item For $M=\bcupd_{n=1}^{\infty}M_{n}$ the operator $E_{M}$ is the strong
limit of the partial sums ${\displaystyle \sum_{n=1}^{k}E_{M_{n}}}$:
\begin{align*}
E_{M} & =\underset{k\to\infty}{\text{s-lim}}\sum_{n=1}^{k}E_{M_{n}}
\end{align*}
This means that for all $u\in H$ holds:
\begin{align*}
E_{M}u & =\sum_{n=1}^{\infty}\left(E_{M_{n}}u\right)
\end{align*}
The series does not necessarily converge in the operator norm!
\item $E_{M}\cdot E_{N}=E_{M\cap N}$
\item For all $u\in H$, the mapping $M\mapsto\left\langle u,E_{M}u\right\rangle \in\mathbb{R}$
is a (real) bounded regular Borel measure.
\end{enumerate}
$\text{supp}\left(E\right)$ is the complement of the largest open
set $\Omega$ with $E_{\Omega}=0$, which exists due to the $\sigma$-additivity.\\
$E$ is called a \emph{compact} spectral measure if $\text{supp}\left(E\right)$
is compact.


\subsection{Theorem}

Let $A\in L\left(H\right)$ be symmetric. Then the mapping
\begin{align*}
E:M & \mapsto\chi_{M}\left(A\right)
\end{align*}
is a spectral measure on $\mathbb{R}$ with $\text{supp}\left(E\right)\subseteq\sigma\left(A\right)$.


\subsubsection*{Proof}

We have to show the properties from the definition \ref{sub:Def-Spectral-measure}.

i) is clear.
\begin{align*}
\chi_{\emptyset}\left(A\right) & =0\left(A\right)=0\\
\chi_{\mathbb{R}}\left(A\right) & =\Phi\left(1\right)=\mathbbm{1}
\end{align*}
So ii) is shown.

iv) follows from:
\begin{align*}
\chi_{M}\left(A\right)\cdot\chi_{N}\left(A\right) & =\left(\chi_{M}\cdot\chi_{N}\right)\left(A\right)=\chi_{M\cap N}\left(A\right)
\end{align*}
For v) consider:
\begin{align*}
\left\langle u,E_{M}u\right\rangle  & =\left\langle u,\chi_{M}\left(A\right)u\right\rangle =\phi_{u}\left(\chi_{M}\right)=\int\chi_{M}\dd\mu_{u}=\mu_{u}\left(M\right)
\end{align*}
It remains to show iii) and $\text{supp}\left(E\right)\subseteq\sigma\left(A\right)$.

%DATE: Fr 11.1.13

For the later consider $\Omega\subseteq\varrho\left(A\right)$:
\begin{align*}
E_{\Omega} & =\chi_{\Omega}\left(A\right)=\Phi\left(\chi_{\Omega}\right)\sr ={\text{extension to }\mathcal{B}\left(\mathbb{R}\right)}{}\Phi\left(\chi_{\Omega}\chi_{\sigma\left(A\right)}\right)=\Phi\left(\chi_{\Omega\cap\sigma\left(A\right)}\right)=\Phi\left(0\right)=0
\end{align*}
Now show iii): From
\begin{align*}
M & =\bcupd_{j=1}^{\infty}M_{j}
\end{align*}
follows with ponit-wise convergence:
\begin{align*}
\chi_{M} & =\sum_{j=1}^{\infty}\chi_{M_{j}}
\end{align*}
Theorem \ref{sub:Thm-Spectral-theorem-functional-calculus} iii) yields:
\begin{align*}
\underset{n\to\infty}{\text{s-lim}}\sum_{j=1}^{n}\underbrace{\chi_{M_{j}}\left(A\right)}_{=E_{M_{j}}} & =\underbrace{\chi_{M}\left(A\right)}_{=E_{M}}
\end{align*}
\qqed


\subsubsection*{Notation}

$M\mapsto E_{M}$ is the spectral measure, which is projection operator
valued.\\
$M\mapsto\left\langle u,E_{M}u\right\rangle =\mu_{u}\left(M\right)=\mu_{u,u}\left(M\right)$
is the real, bounded, regular Borel measure.\\
$M\mapsto\left\langle u,E_{M}v\right\rangle =\mu_{u,v}\left(M\right)$
is the complex, bounded, regular Borel measure.\\
Consider the integral:
\begin{align*}
\int_{\mathbb{R}}f\left(\lambda\right)\dd\mu_{u}\left(\lambda\right)
\end{align*}
\begin{align*}
\dd\mu_{u}\left(\lambda\right) & =\dd\left\langle u,E_{\lambda}u\right\rangle \\
\dd\mu_{u,v}\left(\lambda\right) & =\dd\left\langle u,E_{\lambda}v\right\rangle 
\end{align*}



\subsection{Lemma\label{sub:Lem-E_lambdaE_M}}

Let $E$ be a spectral measure on $\mathbb{R}^{n}$ and $M\in\mathfrak{M}\left(\mathbb{R}^{n}\right)$.
Then holds for all $u,v\in H$:
\begin{align*}
\dd\left\langle u,E_{\lambda}E_{M}v\right\rangle  & =\chi_{M}\left(\lambda\right)\dd\left\langle u,E_{\lambda}v\right\rangle =\dd\left\langle E_{M}u,E_{\lambda}v\right\rangle 
\end{align*}



\subsubsection*{Proof}

For all $f\in\mathcal{B}\left(\mathbb{R}^{n}\right)$ we have to show:
\begin{align*}
\int_{\mathbb{R}^{n}}f\left(\lambda\right)\dd\left\langle u,E_{\lambda}E_{M}v\right\rangle  & =\int_{\mathbb{R}^{n}}f\left(\lambda\right)\cdot\chi_{M}\left(\lambda\right)\dd\left\langle u,E_{\lambda}v\right\rangle 
\end{align*}
By approximation, it suffices to show for all $\Omega\in\mathfrak{M}\left(\mathbb{R}^{n}\right)$:
\begin{align*}
\int_{\mathbb{R}^{n}}\chi_{\Omega}\left(\lambda\right)\dd\left\langle u,E_{\lambda}E_{M}v\right\rangle  & =\int_{\mathbb{R}^{n}}\chi_{\Omega}\left(\lambda\right)\chi_{M}\left(\lambda\right)\dd\left\langle u,E_{\lambda}v\right\rangle 
\end{align*}
Since $\int\chi_{M}\left(x\right)\dd\mu\left(x\right)=\mu\left(M\right)$,
we get:
\begin{align*}
\int_{\mathbb{R}^{n}}\chi_{\Omega}\left(\lambda\right)\dd\left\langle u,E_{\lambda}E_{M}v\right\rangle  & =\left\langle u,E_{\Omega}E_{M}v\right\rangle \stackrel{\text{property iv)}}{=}\left\langle u,E_{\Omega\cap M}v\right\rangle =\\
 & =\int_{\mathbb{R}^{n}}\chi_{\Omega\cap M}\left\langle u,\dd E_{\lambda}v\right\rangle =\int_{\mathbb{R}^{n}}\chi_{\Omega}\chi_{M}\left\langle u,\dd E_{\lambda}v\right\rangle 
\end{align*}
\qqed

We write:
\begin{align*}
\int_{\mathbb{R}^{n}}f\left(\lambda\right)\dd\left\langle u,E_{\lambda}v\right\rangle  & =:\left\langle u,\left(\int_{\mathbb{R}^{n}}f\left(\lambda\right)\dd E_{\lambda}\right)v\right\rangle 
\end{align*}
We will use this to define integration in $L\left(H\right)$.


\subsection{Theorem}

Let $E$ be a spectral measure on $\mathbb{R}^{n}$ and $f\in\mathcal{B}\left(\mathbb{R}^{n}\right)$.
Then the relations
\begin{align*}
\int f\left(\lambda\right)\dd\left\langle u,E_{\lambda}v\right\rangle  & =\left\langle u,Av\right\rangle \qquad\fall_{u,v\in H}
\end{align*}
define a unique normal operator $A\in L\left(H\right)$, which we
also denote by:
\begin{align*}
A & =\int f\left(\lambda\right)\dd E_{\lambda}
\end{align*}
Moreover:
\begin{align*}
A^{*} & =\int\overline{f\left(\lambda\right)}\dd E_{\lambda}
\end{align*}



\subsubsection*{Proof}

We define a bilinear form $B:H\times H\to\mathbb{C}$ by:
\begin{align*}
B\left(u,v\right) & =\int_{\mathbb{R}^{n}}f\left(\lambda\right)\dd\left\langle u,E_{\lambda}v\right\rangle 
\end{align*}
Then we have:
\begin{align*}
\abs{B\left(u,u\right)} & \le\int_{\mathbb{R}^{n}}\abs{f\left(\lambda\right)}\underbrace{\dd\left\langle u,E_{\lambda}u\right\rangle }_{\text{positive measure}}\le\norm f_{\infty}\cdot\left\langle u,\underbrace{E_{\mathbb{R}^{n}}}_{=\mathbbm{1}}u\right\rangle =\norm f_{\infty}\cdot\norm u^{2}
\end{align*}
Polarization and estimation yields:
\begin{align*}
\abs{B\left(u,v\right)} & \le\norm f_{\infty}\norm u\cdot\norm v
\end{align*}
Thus by the Fréchet-Riesz theorem, there is a unique $A\in L\left(H\right)$
with:
\begin{align*}
B\left(u,v\right) & =\left\langle u,Av\right\rangle 
\end{align*}
\begin{align*}
\left\langle u,Av\right\rangle  & =\int f\left(\lambda\right)\dd\left\langle u,E_{\lambda}v\right\rangle \\
\left\langle u,A^{*}v\right\rangle =\left\langle v,Au\right\rangle  & =\int\overline{f\left(\lambda\right)}\dd\left\langle u,E_{\lambda}v\right\rangle \\
\Rightarrow\qquad A^{*} & =\int\overline{f\left(\lambda\right)}\dd E_{\lambda}
\end{align*}
\qqed


\subsection{Theorem\label{sub:Thm-Product-of-Integrals}}

Let $E$ be a spectral measure on $\mathbb{R}^{n}$ and $f,g\in\mathcal{B}\left(\mathbb{R}^{n}\right)$.
Then holds:
\begin{align*}
\left(\int_{\mathbb{R}^{n}}f\left(\lambda\right)\dd E_{\lambda}\right)\left(\int_{\mathbb{R}^{n}}g\left(\lambda'\right)\dd E_{\lambda'}\right) & =\int_{\mathbb{R}^{n}}f\left(\lambda\right)g\left(\lambda\right)\dd E_{\lambda}
\end{align*}



\subsubsection*{Proof}

By approximation it suffices to consider the case $g=\chi_{M}$ for
$M\in\mathfrak{M}\left(\mathbb{R}^{n}\right)$.
\begin{align*}
A & :=\int_{\mathbb{R}^{n}}f\left(\lambda\right)\dd E_{\lambda} & E_{M} & =\int_{\mathbb{R}^{n}}\chi_{M}\dd E_{\lambda}
\end{align*}
For all $u,v\in H$ holds:
\begin{align*}
\left\langle u,A\cdot E_{M}v\right\rangle  & =\int_{\mathbb{R}^{n}}f\left(\lambda\right)\dd\left\langle u,E_{\lambda}E_{M}v\right\rangle \stackrel{\eqref{sub:Lem-E_lambdaE_M}}{=}\int_{\mathbb{R}^{n}}f\left(\lambda\right)\chi_{M}\left(\lambda\right)\dd\left\langle u,E_{\lambda}v\right\rangle =\\
 & =\left\langle u,\int_{\mathbb{R}^{n}}\left(f\cdot\chi_{M}\right)\left(\lambda\right)\dd E_{\lambda}v\right\rangle 
\end{align*}
\begin{align*}
\Rightarrow\qquad A\cdot E_{M} & =\int_{\mathbb{R}^{n}}f\cdot\chi_{M}\dd E_{\lambda}
\end{align*}
\qqed

Physicists write:
\begin{align*}
E_{\lambda}\cdot E_{\mu} & =\delta_{\lambda-\mu}E_{\lambda}
\end{align*}
This follows, because $E_{\lambda}$ is idempotent and for $\lambda\not=\mu$
holds:
\begin{align*}
E_{\lambda}E_{\mu}=E_{\left\{ \lambda\right\} }\cdot E_{\left\{ \mu\right\} } & =E_{\left\{ \lambda\right\} \cap\left\{ \mu\right\} }=E_{\emptyset}=0
\end{align*}



\subsection{Theorem \textmd{(spectral decomposition of a bounded symmetric operator)\label{sub:Thm-spectral-decomposition}}}

There is a one-to-one correspondence between bounded symmetric operators
$A\in L\left(H\right)$ and compact spectral measures $E$ on $\mathbb{R}$
by:
\begin{align*}
A & =\int_{\mathbb{R}}\lambda\dd E_{\lambda}
\end{align*}
This means for a given $A$ with corresponding spectral measure $E_{M}=\chi_{M}\left(A\right)$
holds this equation. Conversely, if $E$ is a compact spectral measure,
then this equation defines a bounded symmetric Operator and $E_{M}=\chi_{M}\left(A\right)$.

Moreover holds:
\begin{enumerate}[label=\roman*)]
\item $f\left(A\right)=\int_{\mathbb{R}}f\left(\lambda\right)\dd E_{\lambda}$
\item $\sigma\left(A\right)=\text{supp}\left(E\right)$
\end{enumerate}

\subsubsection*{Proof}

For a given $A$, let $E_{M}=\chi_{M}\left(A\right)$ be the corresponding
spectral measure. Then holds for all $u,v\in H$ by construction:
\begin{align*}
\left\langle u,f\left(A\right)v\right\rangle  & =\int_{\mathbb{R}}f\left(\lambda\right)\dd\left\langle u,E_{\lambda}v\right\rangle 
\end{align*}
By the definition of $\int f\left(\lambda\right)\dd E_{\lambda}$
follows:
\begin{align*}
f\left(A\right) & =\int_{\mathbb{R}}f\left(\lambda\right)\dd E_{\lambda}
\end{align*}
For the polynomial $f\left(\lambda\right)=\lambda$, i.e. $f\left(A\right)=A$,
this gives:
\begin{align*}
A & =\int_{\mathbb{R}}\lambda\dd E_{\lambda}
\end{align*}
If $E$ is a compact spectral measure, $\int_{\mathbb{R}}f\left(\lambda\right)\dd E_{\lambda}$
defines a normal operator with:
\begin{align*}
\left(\int_{\mathbb{R}}f\left(\lambda\right)\dd E_{\lambda}\right)^{*} & =\int_{\mathbb{R}}\overline{f\left(\lambda\right)}\dd E_{\lambda}
\end{align*}
The compatibility with the spectral calculus follows from theorem
\ref{sub:Thm-Product-of-Integrals}.

Thus it remains to show $\sigma\left(A\right)\subseteq\text{supp}\left(E\right)$.
Consider $\mu\not\in\text{supp}\left(E\right)$. We want to show $\mu\in\varrho\left(A\right)$.
Define the following bounded real function:
\begin{align*}
g\left(\lambda\right) & :=\frac{1}{\lambda-\mu}\chi_{\text{supp}\left(E\right)}\\
f\left(\lambda\right) & :=\lambda-\mu
\end{align*}
\begin{align*}
B & :=\int_{\mathbb{R}}g\dd E_{\lambda}\in L\left(H\right)
\end{align*}
is a well-defined integral.
\begin{align*}
\int_{\mathbb{R}}f\left(\lambda\right)\dd E_{\lambda} & =A-\mu\mathbbm{1}\\
\left(A-\mu\mathbbm{1}\right)B & =\left(\int_{\mathbb{R}}f\left(\lambda'\right)\dd E_{\lambda'}\right)\left(\int_{\mathbb{R}}g\left(\lambda\right)\dd E_{\lambda}\right)=\int_{\mathbb{R}}f\cdot g\dd E_{\lambda}=\\
 & =\int_{\mathbb{R}}\chi_{\text{supp}\left(E\right)}\underbrace{\dd E_{\lambda}}_{=0\text{ outside of }\text{supp}\left(E\right)}=\int_{\mathbb{R}}\dd E_{\lambda}=\mathbbm{1}
\end{align*}
Thus $B=\left(A-\mu\mathbbm{1}\right)^{-1}$ and therefore $\mu\in\varrho\left(A\right)$.\qqed


\subsection{Corollary}

For $f\in\mathcal{B}\left(\mathbb{R}\right)$ holds:
\begin{align*}
\opnorm{f\left(A\right)} & =\underset{\sigma\left(A\right)}{\text{sup\,\ ess}}\abs f
\end{align*}



\subsubsection*{Proof}

„$\le$“ was already proved in theorem \ref{sub:Thm-Spectral-theorem-functional-calculus}
ii).

To prove equality, we first note that $f\left(A\right)$ is a normal
operator, because it holds:
\begin{align*}
f\left(A\right) & =\int_{\mathbb{R}}f\left(\lambda\right)\dd E_{\lambda} & \left(f\left(A\right)\right)^{*} & =\int_{\mathbb{R}}\overline{f\left(\lambda\right)}\dd E_{\lambda}
\end{align*}
\begin{align*}
f\left(A\right)\cdot\left(f\left(A\right)\right)^{*} & =\left(\int_{\mathbb{R}}f\left(\lambda\right)\dd E_{\lambda}\right)\left(\int_{\mathbb{R}}\overline{f\left(\lambda\right)}\dd E_{\lambda}\right)=\\
 & =\int_{\mathbb{R}}f\left(\lambda\right)\overline{f\left(\lambda\right)}\dd E_{\lambda}=\int_{\mathbb{R}}\overline{f\left(\lambda\right)}f\left(\lambda\right)\dd E_{\lambda}=\left(f\left(A\right)\right)^{*}f\left(A\right)
\end{align*}
For a normal operator $B$ holds:
\begin{align*}
\opnorm B & =r\left(B\right)=\sup_{x\in\sigma\left(B\right)}\abs x
\end{align*}
Now follows by theorem \ref{sub:Thm-spectral-decomposition} ii):
\begin{align*}
\opnorm{f\left(A\right)} & =\sup_{x\in\sigma\left(f\left(A\right)\right)}\abs x=\sup\left(\text{supp}\left(f\left(E\right)\right)\right)=\underset{\lambda\in\text{supp}\left(E\right)}{\text{sup\,\ ess}}\abs{f\left(\lambda\right)}
\end{align*}


\qqed

%DATE: Do 17.01.13


\section{Simple Examples}


\subsection{Example: finite dimensions}

Consider $H=\mathbb{C}^{n}$ and a symmetric operator $A\in L\left(\mathbb{C}^{n}\right)$.
Choose an orthonormal eigenvector basis such that $A$ has the matrix
representation:
\begin{align*}
A & =\left(\begin{array}{ccc}
\lambda_{1} &  & 0\\
 & \ddots\\
0 &  & \lambda_{n}
\end{array}\right)
\end{align*}
The eigenvalues $\lambda_{i}\in\mathbb{R}$ are real, but there can
be degeneracies, i.e. $\lambda_{i}=\lambda_{j}$ for some $i\not=j$.
\begin{align*}
A^{2} & =\left(\begin{array}{ccc}
\lambda_{1}^{2} &  & 0\\
 & \ddots\\
0 &  & \lambda_{n}^{2}
\end{array}\right)
\end{align*}
Similarly we can compute polynomials of $A$.\\
The Stone-Weierstraß approximation yields for $f\in C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)$:
\begin{align*}
f\left(A\right) & =\left(\begin{array}{ccc}
f\left(\lambda_{1}\right) &  & 0\\
 & \ddots\\
0 &  & f\left(\lambda_{n}\right)
\end{array}\right)
\end{align*}
Since the spectrum
\begin{align*}
\sigma\left(A\right) & =\left\{ \lambda_{1},\ldots,\lambda_{n}\right\} 
\end{align*}
is a finite set, we have $C^{0}\left(\sigma\left(A\right)\right)=\mathcal{B}\left(\sigma\left(A\right)\right)$.
The spectral measure for $\Omega\subseteq\mathbb{C}$ is:
\begin{align*}
E_{\Omega} & :=\chi_{\Omega}\left(A\right)=\left(\begin{array}{ccc}
\chi_{\Omega}\left(\lambda_{1}\right) &  & 0\\
 & \ddots\\
0 &  & \chi_{\Omega}\left(\lambda_{n}\right)
\end{array}\right)
\end{align*}
Thus $E_{\Omega}$ is the projection operator on the eigenspaces,
for which the eigenvalues $\lambda$ lie in $\Omega$.
\begin{align*}
\int f\left(\lambda\right)\dd E_{\lambda} & =\sum_{j=1}^{n}f\left(\lambda_{j}\right)E_{\left\{ \lambda_{j}\right\} }
\end{align*}
More specifically, let $u_{j}$ be an orthonormal eigenvector basis,
$Au_{j}=\lambda_{j}u_{j}$ and $\left\langle u_{i},u_{j}\right\rangle =\delta_{ij}$.
Then for any $v\in\mathbb{C}^{n}$ let $u_{1}^{\left(\lambda\right)},\ldots,u_{\mu}^{\left(\lambda\right)}$
be all eigenvectors with the eigenvalue $\lambda$, i.e. $Au_{k}^{\left(\lambda\right)}=\lambda u_{k}^{\left(\lambda\right)}$,
so
\begin{align*}
E_{\left\{ \lambda\right\} }v & =\sum_{k=1}^{\mu}u_{k}^{\left(\lambda\right)}\left\langle u_{k}^{\left(\lambda\right)},v\right\rangle 
\end{align*}
 is the projection on the eigenspace $\left\langle u^{\left(k\right)}\right\rangle $.


\subsection{Example: compact operator}

Let $H$ be an infinite-dimensional Hilbert space and $A\in L\left(H\right)$
be symmetric and compact. According to the Hilbert-Schmidt theorem,
there is an orthonormal eigenvector basis $\left(u_{n}\right)$, i.e.:
\begin{align*}
Au_{n} & =\lambda_{n}u_{n}
\end{align*}
Then $\lambda_{n}\to0$, because $A$ is compact. The $\lambda_{n}$
have finite-dimensional eigenspaces.

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[scale=2]
  \draw[->] (-2,0) -- (2,0) node[right] {$\lambda$};
  \draw (0,0.05) -- (0,-0.05) node [below] {$0$};
  \foreach \t in {-1.5,-1,-0.7,-0.5,-0.4,0.3,0.5,0.6,0.8,1.2,1.7}     \draw[blue] (\t,0)  +(0.05,0.05) -- +(-0.05,-0.05) +(-0.05,0.05) -- +(0.05,-0.05);
  \foreach \t in {-0.21,-0.14,-0.07,0.21,0.14,0.07}     \draw[blue,fill=blue] (\t,0) circle (0.02);
  \node[blue] at (1,0.3) {$\sigma(A)$};
\end{tikzpicture}\caption{$\sigma\left(A\right)$ has only zero as limit point}
\end{figure}


\begin{align*}
A^{2}u_{n} & =\lambda_{n}^{2}u_{n}\\
p\left(A\right)u_{n} & =p\left(\lambda_{n}\right)u_{n}
\end{align*}
This holds for any polynomial $p$. The Stone-Weierstraß approximation
yields for $f\in C^{0}\left(\sigma\left(A\right)\right)$:
\begin{align*}
f\left(A\right)u_{n} & =f\left(\lambda_{n}\right)
\end{align*}
The Riesz representation theorem gives
\begin{align*}
f\left(A\right)u_{n} & =f\left(\lambda_{n}\right)
\end{align*}
for all $f\in\mathcal{B}\left(\sigma\left(A\right)\right)$ or even
$f\in\mathcal{B}\left(\mathbb{R}\right)$. Then follows:
\begin{align*}
E_{\Omega}u_{n} & :=\chi_{\Omega}\left(A\right)u_{n}=\chi_{\Omega}\left(\lambda_{n}\right)u_{n}
\end{align*}
Thus $E_{\Omega}$ is the projection operator to all eigenspaces whose
eigenvalues $\lambda$ lie in $\Omega$. But $E_{\left(-\varepsilon,\varepsilon\right)}$
has infinite rank for all $\varepsilon>0$.
\begin{align*}
A & =\sum_{\lambda\in\sigma\left(A\right)}\lambda E_{\left\{ \lambda\right\} }
\end{align*}
\begin{align*}
A_{N} & :=\sum_{\sr{}{\lambda\in\sigma\left(A\right)}{\abs{\lambda}>\frac{1}{N}}}\lambda E_{\left\{ \lambda\right\} }
\end{align*}
is a finite-dimensional approximation of $A$ (cf. \ref{sec:Thm-compact-operator-approximation})
in the sense:
\begin{align*}
\norm{A-A_{N}} & \xrightarrow{N\to\infty}0
\end{align*}
More precisely we have:
\begin{align*}
\norm{A-A_{N}} & \le\frac{1}{N}
\end{align*}
Now consider:
\begin{align*}
\mathbbm{1} & =\sum_{\lambda\in\sigma\left(A\right)}E_{\left\{ \lambda\right\} }\\
E_{N} & :=\sum_{\sr{}{\lambda\in\sigma\left(A\right)}{\abs{\lambda}>\frac{1}{N}}}E_{\left\{ \lambda\right\} }
\end{align*}
This converges strongly, but it does not converge in the operator
norm: 
\begin{align*}
\norm{E-E_{N}} & =\norm{E_{\left[-\frac{1}{N},\frac{1}{N}\right]}}=1
\end{align*}



\subsection{Example: continuous spectrum}

Consider the Hilbert space $H=L^{2}\left(\mathbb{R}\right)$ and the
function:
\begin{align*}
g\left(t\right) & :=\begin{cases}
t & \text{for }0<t<1\\
0 & \text{otherwise}
\end{cases}
\end{align*}


\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
 \begin{axis}[width=10cm, axis equal image,
			axis x line=middle, axis y line=middle,
			ymin=0, ymax=1.25,
			xmin =-1.15 , xmax=1.65,
			xlabel=$t$, ylabel=$g(t)$]
  \addplot[domain=0:1] {x};
  \draw[dashed] (axis cs:1,1) -- (axis cs:1,0);
 \end{axis}
\end{tikzpicture}\caption{Plot of $g\left(t\right)$}
\end{figure}


$A\in L\left(H\right)$ defined by
\begin{align*}
\left(Au\right)\left(t\right) & :=g\left(t\right)\cdot u\left(t\right)=\left(T_{g}\cdot u\right)\left(t\right)
\end{align*}
for $u\in H$ is a multiplication operator. From $\abs{g\left(t\right)}\le1$
follows $\norm A\le1$. As before we get:
\begin{align*}
A^{2} & =T_{g^{2}}\\
p\left(A\right) & =T_{p\left(g\right)}\qquad\fall_{\text{polynomial }p}\\
f\left(A\right) & =T_{f\left(g\right)}\qquad\fall_{f\,\in\,\mathcal{B}\left(\mathbb{R}\right)}
\end{align*}
Therefore we get:
\begin{align*}
E_{\Omega} & =T_{\chi_{\Omega}\left(g\right)}
\end{align*}
\begin{align*}
\left(\chi_{\Omega}\left(g\right)\right)\left(t\right) & =\begin{cases}
1 & \text{if }g\left(t\right)\in\Omega\\
0 & \text{otherwise}
\end{cases}\\
 & =\chi_{g^{-1}\left(\Omega\right)}
\end{align*}
In general for multiplication operators holds:
\begin{align*}
E_{\Omega}=T_{\chi_{\Omega}\left(g\right)} & =T_{\chi_{g^{-1}\left(\Omega\right)}}
\end{align*}
For $\Omega=\left(a,b\right)\subseteq\left(0,1\right)$ we get $g^{-1}\left(\Omega\right)=\Omega$
and thus $E_{\Omega}u=\chi_{\Omega}\cdot u$. If on the other hand
$\Omega=\left\{ 0\right\} $, then holds:
\begin{align*}
g^{-1}\left(\Omega\right) & =\mathbb{R}\setminus\left(0,1\right)=(-\infty,0]\cup[1,\infty)
\end{align*}
Thus we get:
\begin{align*}
E_{\left\{ 0\right\} }u & =\chi_{\mathbb{R}\setminus\left(0,1\right)}u
\end{align*}
The spectrum of $A$ is $\sigma\left(A\right)=\left[0,1\right]$.
(Remember that the spectrum is always closed!)

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[scale=2]
  \draw[->] (-1,0) -- (2,0) node[right] {$\lambda$};
  \draw (0.05,0.1) -- (0,0.1) -- (0,-0.1) node[below] {$0$} -- (0.05,-0.1);
  \draw (0.95,0.1) -- (1,0.1) -- (1,-0.1) node[below] {$1$} -- (0.95,-0.1);
    \draw[blue, very thick] (0,0) -- (1,0);
  \node[blue] at (0.5,0.25) {$\sigma(A)$};
  \draw[blue,fill=blue] (0,0) circle (0.03);
  \draw[blue,fill=blue] (1,0) circle (0.03);
\end{tikzpicture}\caption{Continuous spectrum $\sigma\left(A\right)$ of $A$}
\end{figure}


Zero is an eigenvalue corresponding to an infinite-dimensional eigenspace,
$Au=0$ for $u\big|_{\left[0,1\right]}=0$. Any $\lambda\in(0,1]$
is \emph{not} an eigenvalue:

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
 \begin{axis}[width=10cm, axis equal image,
			axis x line=middle, axis y line=middle,
			ymin=-0.4, ymax=1.25,
			xmin =-1.15 , xmax=1.65,
			xlabel=$t$, ylabel=$h(t)$]
  \addplot[domain=0:1] {x-0.3};
  \addplot[domain=-1.15:0] {-0.3};
  \addplot[domain=1:1.65] {-0.3};
  \draw[dashed] (axis cs:1,0.7) -- (axis cs:1,-0.3);
  \draw (axis cs:0.3,0.1) -- (axis cs:0.3,-0.1) node[below]{$\lambda$};
 \end{axis}
\end{tikzpicture}\caption{Plot of $g\left(t\right)-\lambda$}
\end{figure}


\begin{align*}
\left(A-\lambda\right)u & =T_{g-\lambda}u
\end{align*}
\begin{align*}
h & :=g-\lambda
\end{align*}
\begin{align*}
h\left(x\right)\cdot u\left(x\right) & =0\\
\Leftrightarrow\qquad u & =0\quad\fall_{x\in\mathbb{R},\ h\left(x\right)\not=0}\\
\Leftrightarrow\qquad u & =0\quad\text{almost everywhere}\\
\Leftrightarrow\qquad u & =0\in L^{2}\left(\mathbb{R}\right)
\end{align*}
Thus the eigenvalue equation only has the trivial solution.


\subsection{Example}

Consider $H=L^{2}\left(\mathbb{R}\right)$ and the multiplication
operator $A=T_{g}$ for $g\in C_{0}^{0}\left(\mathbb{R}\right)$.
Then follows $E_{\Omega}=T_{g^{-1}\left(\Omega\right)}$ as before
and $\sigma\left(A\right)=g\left(\mathbb{R}\right)$.

That $\lambda\in\sigma\left(A\right)$ is an eigenvalue is equivalent
to $g^{-1}\left(\left\{ \lambda\right\} \right)$ is a set of strictly
positive Borel measure.


\section{Essential and discrete spectrum}

Let $A\in L\left(H\right)$ be symmetric. (The definitions are similar
for normal operators or for unbounded self-adjoint operators). Let
$E$ be the corresponding spectral measure.


\subsection{Definition \textmd{(essential and discrete spectrum)}}

The essential spectrum $\sigma_{\text{ess}}\left(A\right)$ contains
all $\lambda\in\mathbb{C}$ for which $\text{rg}\left(E_{B_{\varepsilon}\left(\lambda\right)}\right)=\infty$
for all $\varepsilon\in\mathbb{R}_{>0}$.

The discrete spectrum $\sigma_{\text{disc}}\left(A\right)$ contains
all $\lambda\in\sigma\left(A\right)$ for which exists a $\varepsilon\in\mathbb{R}_{>0}$
such that the rank of $E_{B_{\varepsilon}\left(\lambda\right)}$ is
finite.

\emph{Note:} $\lambda\in\sigma_{\text{ess}}\left(A\right)$ implies
$\lambda\in\text{supp}\left(E\right)=\sigma\left(A\right)$. Thus
$\sigma\left(A\right)=\sigma_{\text{ess}}\left(A\right)\dot{\cup}\,\sigma_{\text{disc}}\left(A\right)$.


\subsection{Example}

Let $A$ be a compact symmetric operator of infinite rank.

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[scale=2]
  \draw[->] (-2,0) -- (2,0) node[right] {$\lambda$};
  \draw (0,0.05) -- (0,-0.05) node [below] {$0$};
  \foreach \t in {-1.5,-1,-0.7,-0.5,-0.4,0.3,0.5,0.6,0.8,1.2,1.7}     \draw[blue] (\t,0)  +(0.05,0.05) -- +(-0.05,-0.05) +(-0.05,0.05) -- +(0.05,-0.05);
  \foreach \t in {-0.21,-0.14,-0.07,0.21,0.14,0.07}     \draw[blue,fill=blue] (\t,0) circle (0.02);
  \node[blue] at (1,0.3) {$\sigma(A)$};
\end{tikzpicture}\caption{$\sigma\left(A\right)$ has only zero as limit point}
\end{figure}


Here we have:
\begin{align*}
\sigma_{\text{disc}} & =\sigma\left(A\right)\setminus\left\{ 0\right\}  & \sigma_{\text{ess}} & =\left\{ 0\right\} 
\end{align*}



\subsection{Theorem \textmd{(condition for discrete spectrum)}\label{sub:Thm-condition-discrete-spectrum}}

$\lambda\in\sigma_{\text{disc}}\left(A\right)$ holds if and only
if both of the following conditions are satisfied:
\begin{enumerate}[label=\roman*)]
\item $\lambda$ is an isolated point of $\sigma\left(A\right)$, i.e.
there exists a $\varepsilon\in\mathbb{R}_{>0}$ such that $B_{\varepsilon}\left(\lambda\right)\cap\sigma\left(A\right)=\left\{ \lambda\right\} $.
\item $ $$\lambda$ is an eigenvalue of finite multiplicity, i.e. $\ker\left(A-\lambda\right)$
is finite-dimensional.
\end{enumerate}

\subsubsection*{Proof}

„$\Leftarrow$“: If i) and ii) hold, then for an appropriately chosen
$\varepsilon\in\mathbb{R}_{>0}$
\begin{align*}
E_{B_{\varepsilon}\left(\lambda\right)} & =E_{\left\{ \lambda\right\} }
\end{align*}
is the projection operator on the finite-dimensional eigenspace.

„$\Rightarrow$“: Consider $\lambda\in\sigma_{\text{disc}}\left(A\right)$.
\begin{enumerate}[label=\roman*)]
\item Choose $\varepsilon\in\mathbb{R}_{>0}$ such that $E_{B_{\varepsilon}\left(\lambda\right)}$
has finite rank.
\begin{align*}
J & :=E_{B_{\varepsilon}\left(\lambda\right)}\left(H\right)
\end{align*}
is a finite-dimensional subspace of $H$. For $u\in J$ holds:
\begin{align*}
Au & =AE_{B_{\varepsilon}\left(\lambda\right)}u=E_{B_{\varepsilon}\left(\lambda\right)}Au
\end{align*}
Therefore follows $Au\in J$ and thus $A\big|_{J}:J\to J$ is a symmetric
operator on a finite-dimensional Hilbert space. Diagonalize as in
linear algebra:
\begin{align*}
\sigma\left(A\big|_{J}\right) & =\left\{ \lambda_{1},\ldots,\lambda_{n}\right\} =\sigma\left(A\right)\cap B_{\varepsilon}\left(\lambda\right)
\end{align*}
The $\lambda_{i}$ lie discrete and thus are isolated.
\item follows, because the eigenspace of $A$ is the same as that of $A\big|_{J}$,
which is finite-dimensional.
\end{enumerate}
\qqed


\subsection{Theorem \textmd{(Weyl criterion)}}
\begin{enumerate}[label=\roman*)]
\item $\lambda\in\sigma\left(A\right)$ holds if and only if there exists
a sequence $\left(u_{n}\right)_{n\in\mathbb{N}}$ in $H$ such that
for all $n\in\mathbb{N}$ holds $\norm{u_{n}}=1$ and:
\begin{align*}
\left(A-\lambda\right)u_{n} & \xrightarrow{n\to\infty}0
\end{align*}
One also says, that $\lambda$ is an \emph{approximate eigenvalue},
because this can also be expressed as follows: For any $\varepsilon\in\mathbb{R}_{>0}$
there exists a $u\in H$ with $\norm u=1$ and $\norm{\left(A-\lambda\right)u}\le\varepsilon$.
\item $\lambda\in\sigma_{\text{ess}}\left(A\right)$ holds if and only if
the $\left(u_{n}\right)$ from above can be chosen as an orthonormal
basis.
\end{enumerate}

\subsubsection*{Proof}
\begin{enumerate}[label=\roman*)]
\item For $\lambda\in\varrho\left(A\right)$ the operator $A-\lambda$
is continuously invertible, i.e. $\left(A-\lambda\right)^{-1}\in L\left(H\right)$.
So for all $u\in H$ holds:
\begin{align*}
\norm{\left(A-\lambda\right)^{-1}u} & \le C\norm u
\end{align*}
Since $A-\lambda$ is bijective, this is equivalent to:
\begin{align*}
\norm v & \le C\norm{\left(A-\lambda\right)v}\qquad\fall_{v\in H}
\end{align*}
This gives:
\begin{align*}
\norm{\left(A-\lambda\right)v} & \ge\frac{1}{C}\norm v\\
\norm{\left(A-\lambda\right)u_{n}} & \ge\frac{1}{C}\norm{u_{n}}=\frac{1}{C}
\end{align*}
Thus $\left(A-\lambda\right)u_{n}$ cannot converge to zero and thus
$\lambda$ is no approximate eigenvalue.\\
For $\lambda\in\sigma\left(A\right)$ the operator $\left(A-\lambda\right)$
has no bounded inverse. Then either $\left(A-\lambda\right)$ has
a non-trivial kernel, i.e. there exists a $u\in H$ with $\norm u=1$
and:
\begin{align*}
\left(A-\lambda\right)u & =0
\end{align*}
In this case one can choose $u_{n}:=u$.\\
If on the other hand $\left(A-\lambda\right)$ is injective, but has
no bounded inverse, then exists a sequence $\left(u_{n}\right)$ with
$\norm{\left(A-\lambda\right)u_{n}}\le\frac{1}{n}\norm{u_{n}}$. This
means that $\lambda$ is an approximate eigenvalue.
\item This follows directly from theorem \ref{sub:Thm-condition-discrete-spectrum}.
\end{enumerate}
\qqed


\section{The Stone Formula}

Let $A\in L\left(H\right)$ be symmetric, so we have $\sigma\left(A\right)\subseteq\mathbb{R}$.
Thus for any $\lambda\in\mathbb{C}\setminus\mathbb{R}$ the resolvent
\begin{align*}
R_{\lambda} & :=\left(A-\lambda\right)^{-1}\in L\left(H\right)
\end{align*}
exists.

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[scale=2]
  \draw[->] (-2,0) -- (2,0) node[right]{$\mathbb{R}$};
%  \foreach \t in {-0.3,0.3} {
%    \draw (0,\t) +(0.05,0.05) -- +(-0.05,-0.05) +(-0.05,0.05) -- +(0.05,-0.05);}
  \draw (1,0.5) node[right]{$\lambda$}  +(0.05,0.05) -- +(-0.05,-0.05) +(-0.05,0.05) -- +(0.05,-0.05);
%    \draw[<->] (0,0) -- node[right]{$\varepsilon$} (0,0.3);
\end{tikzpicture}\caption{$\lambda\not\in\mathbb{R}$}
\end{figure}


\begin{align*}
A & =\int_{\mathbb{R}}\mu\cdot\dd E_{\mu} & R_{\lambda} & =\int_{\mathbb{R}}\frac{1}{\mu-\lambda}\dd E_{\mu}
\end{align*}
$\frac{1}{\mu-\lambda}\in\mathcal{B}\left(\mathbb{R}\right)$ holds,
because the pole is away from the real axis.
\begin{align*}
\left(A-\lambda\right)R_{\lambda} & =\left(\int_{\mathbb{R}}\left(\mu-\lambda\right)\dd E_{\mu}\right)\left(\int_{\mathbb{R}}\frac{1}{\mu-\lambda}\dd E_{\mu}\right)=\int_{\mathbb{R}}\frac{\mu-\lambda}{\mu-\lambda}\dd E_{\mu}=\int_{\mathbb{R}}\dd E_{\mu}=E_{\mathbb{R}}=\mathbbm{1}
\end{align*}



\subsection{Theorem}

For $\lambda\in\mathbb{R}$ and $\varepsilon\in\mathbb{R}_{>0}$ holds:
\begin{align*}
\frac{1}{2\pi\ii}\int_{a}^{b}\left(R_{\lambda+\ii\varepsilon}-R_{\lambda-\ii\varepsilon}\right)\dd\lambda & =\frac{1}{2}\left(E_{\left(a,b\right)}+E_{\left[a,b\right]}\right)=\int_{a}^{b}\frac{1}{\mu-\lambda}\dd E_{\mu}
\end{align*}
This is a convenient method for computing the spectral measure or
the projection operator on eigenspaces.

\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[scale=2]
  \draw[->] (-2,0) -- (2,0);
  \foreach \x/\y in {-0.3/-0.3, 0.3/-0.3, -0.3/0.3, 0.3/0.3} {
    \draw (\x,\y) +(0.05,0.05) -- +(-0.05,-0.05) +(-0.05,0.05) -- +(0.05,-0.05);}
  \draw (-0.3,-0.3) -- (0.3,-0.3) (-0.3,0.3) -- (0.3,0.3);
  \draw[<->] (0.3,0) -- node[right]{$\varepsilon$} (0.3,0.3);
  \draw (0,0.1) -- node[below]{$\lambda\in\sigma_{\text{disc}}$} (0,-0.1);
  \node at (0.3,0.3) [above right] {$\lambda+\delta+\ii \cdot \varepsilon$};
\end{tikzpicture}\caption{Calculating the spectral measure for a $\lambda\in\sigma_{\text{disc}}$}
\end{figure}


\begin{align*}
\underset{\delta\searrow0}{\text{s-lim}}\:\underset{\varepsilon\searrow0}{\text{s-lim}}\,\frac{1}{2\pi\ii}\int_{\lambda-\delta}^{\lambda+\delta}\left(R_{\mu+\ii\varepsilon}-R_{\mu-\ii\varepsilon}\right)\dd\mu & =E_{\left\{ \lambda\right\} }
\end{align*}



\subsubsection*{Proof}

Let $a<b\in\mathbb{R}$ be given.
\begin{align*}
\phi_{\varepsilon}\left(\mu\right) & :=\frac{1}{2\pi\ii}\int_{a}^{b}\left(\frac{1}{\mu-\lambda-\ii\varepsilon}-\frac{1}{\mu-\lambda+\ii\varepsilon}\right)\dd\lambda
\end{align*}
Then holds $\phi_{\varepsilon}:\mathbb{R}\to\mathbb{C}$ and:
\begin{align*}
\phi_{\varepsilon}\left(A\right) & =\int_{\mathbb{R}}\phi_{\varepsilon}\left(\mu\right)\dd E_{\mu}=\frac{1}{2\pi\ii}\int_{a}^{b}\int_{\mathbb{R}}\bigg(\underbrace{\frac{\dd E_{\mu}}{\mu-\lambda-\ii\varepsilon}}_{=R_{\lambda+\ii\varepsilon}}-\underbrace{\frac{\dd E_{\mu}}{\mu-\lambda+\ii\varepsilon}}_{=R_{\lambda-\ii\varepsilon}}\bigg)\dd\lambda=\\
 & =\frac{1}{2\pi\ii}\int_{a}^{b}\left(R_{\lambda+\ii\varepsilon}-R_{\lambda-\ii\varepsilon}\right)\dd\lambda
\end{align*}
Now analyze the limit $\varepsilon\to0$.
\begin{align*}
\phi_{\varepsilon}\left(\mu\right) & =\frac{-1}{2\pi\ii}\left(\ln\left(\lambda-\mu+\ii\varepsilon\right)-\ln\left(\lambda-\mu-\ii\varepsilon\right)\right)\bigg|_{\lambda=a}^{\lambda=b}
\end{align*}
The logarithm is cut at the negative real axis.
\begin{align*}
\ln\left(z\right) & =\ln\left(\abs z\right)+\ii\arg\left(z\right) & z & =\abs ze^{\ii\arg\left(z\right)}
\end{align*}
The argument of $z$ lies in the range $\left(-\pi,\pi\right)$.

\begin{figure}[H]
\noindent \begin{centering}
\begin{tikzpicture}
  \draw[->] (-2,0) -- (2,0) node[right]{Re$(z)$};
  \draw[->] (0,-2) -- (0,2) node[above]{Im$(z)$};
  \draw[fill=black] (-1,0.5) circle (2pt) node[above] {$\lambda - \mu + \ii \varepsilon$};
  \draw[fill=black] (-1,-0.5) circle (2pt) node[below] {$\lambda - \mu - \ii \varepsilon$};
  \draw (0,0) -- (-1,0.5) (0.5,0) arc (0:154:0.5);
  \node (arg) at (0.3,0.3) [above right]{arg$(\lambda - \mu + \ii \varepsilon)$};
  \draw ($(arg.190) + (0.1,0.1)$) -- (0.15,0.15);
\end{tikzpicture}
\par\end{centering}

\caption{$-\pi<\arg\left(z\right)<\pi$}
\end{figure}


Thus we get:
\begin{align*}
\lim_{\varepsilon\searrow0}\left(\ln\left(\lambda-\mu+\ii\varepsilon\right)-\ln\left(\lambda-\mu-\ii\varepsilon\right)\right) & =\begin{cases}
\;\;0 & \text{if }\lambda-\mu>0\\
\:\pi\ii & \text{if }\lambda-\mu=0\\
2\pi\ii & \text{if }\lambda-\mu<0
\end{cases}
\end{align*}
Then follows:
\begin{align*}
\phi\left(\mu\right) & :=\lim_{\varepsilon\searrow0}\phi_{\varepsilon}\left(\mu\right)=\frac{-1}{2\pi\ii}\begin{cases}
\quad0 & \text{if }\mu\not\in\left[a,b\right]\\
\ -\pi\ii & \text{if }\mu\in\left\{ a,b\right\} \\
-2\pi\ii & \text{if }\mu\in\left(a,b\right)
\end{cases}=\begin{cases}
0 & \text{if }\mu\not\in\left[a,b\right]\\
\frac{1}{2} & \text{if }\mu\in\left\{ a,b\right\} \\
1 & \text{if }\mu\in\left(a,b\right)
\end{cases}
\end{align*}
Thus $\phi_{\varepsilon}\left(\mu\right)\to\phi\left(\mu\right)$
converges point-wise.

\emph{Idea:}
\begin{align*}
\phi_{\varepsilon}\left(A\right) & \to\phi\left(A\right)=\frac{1}{2}\left(E_{\left[a,b\right]}+E_{\left(a,b\right)}\right)
\end{align*}
But how does this converge?\\
Consider weak convergence:
\begin{align*}
\left\langle u,\phi_{\varepsilon}\left(A\right)u\right\rangle  & =\int_{\mathbb{R}}\phi_{\varepsilon}\left(\mu\right)\underbrace{\dd\left\langle u,E_{\mu}u\right\rangle }_{=\dd\mu_{u}=\dd\mu_{u,u}}
\end{align*}
$\dd\mu_{u}$ is a bounded regular real Borel measure. From $\abs{\phi\left(\mu\right)}\le1$
follows for small enough $\varepsilon\in\mathbb{R}_{>0}$ now $\abs{\phi_{\varepsilon}\left(\mu\right)}\le2$.
Because our Borel measure is bounded, 2 is an integrable function,
i.e. $2\in L^{1}\left(\mathbb{R},\dd\mu_{u}\right)$. Therefore we
can use the bounded convergence theorem to get:
\begin{align*}
\lim_{\varepsilon\searrow0}\int_{\mathbb{R}}\phi_{\varepsilon}\left(\mu\right)\dd\left\langle u,E_{\mu}u\right\rangle  & =\int_{\mathbb{R}}\phi\left(\mu\right)\dd\left\langle u,E_{\mu}u\right\rangle =\left\langle u,\phi_{u}\left(A\right)u\right\rangle 
\end{align*}
What about strong convergence?\\
We want to show for all $u\in H$ the convergence $\phi_{\varepsilon}\left(A\right)u\to\phi\left(A\right)u$
in $H$, or equivalently:
\begin{align*}
\left(\phi_{\varepsilon}-\phi\right)\left(A\right)u & \to0\\
\Leftrightarrow\qquad\norm{\left(\phi_{\varepsilon}-\phi\right)\left(A\right)u} & \to0
\end{align*}
\begin{align*}
\norm{\left(\phi_{\varepsilon}-\phi\right)\left(A\right)u}^{2} & =\left\langle \left(\phi_{\varepsilon}-\phi\right)\left(A\right)u,\left(\phi_{\varepsilon}-\phi\right)\left(A\right)u\right\rangle =\left\langle u,\left(\left(\phi_{\varepsilon}-\phi\right)\left(A\right)\right)^{*}\left(\phi_{\varepsilon}-\phi\right)\left(A\right)u\right\rangle =\\
 & =\left\langle u,\left(\overline{\phi}_{\varepsilon}-\overline{\phi}\right)\left(A\right)\left(\phi_{\varepsilon}-\phi\right)\left(A\right)u\right\rangle =\left\langle u,\abs{\phi_{\varepsilon}-\phi}^{2}\left(A\right)u\right\rangle =\\
 & =\int_{\mathbb{R}}\underbrace{\abs{\phi_{\varepsilon}-\phi}^{2}\left(\mu\right)}_{\to0\ \text{point-wise}}\underbrace{\dd\left\langle u,E_{\mu}u\right\rangle }_{\sr{}{\text{point-wise regular}}{\text{Borel measure}}}\xrightarrow[\sr{}{\text{dominated}}{\text{convergence}}]{\varepsilon\searrow0}0
\end{align*}
Therefore it converges strongly.\qqed


\chapter{Spectral Theorem for bounded normal operators}

$A\in L\left(H\right)$ is normal if it commutes with its adjoint,
i.e. $\left[A,A^{*}\right]=0$. Before we considered symmetric $A\in L\left(H\right)$.
Then for a complex valued function $f$ the operator $f\left(A\right)$
is normal, but in general not symmetric, because:
\begin{align*}
\left(f\left(A\right)\right)^{*} & =\overline{f}\left(A\right)\stackrel{\text{in general}}{\not=}f\left(A\right)
\end{align*}
\begin{align*}
f\left(A\right)\cdot\left(f\left(A\right)\right)^{*} & =\left(f\cdot\overline{f}\right)\left(A\right)=\left(\overline{f}\cdot f\right)\left(A\right)=\left(f\left(A\right)\right)^{*}\cdot f\left(A\right)
\end{align*}
The basic idea is:
\begin{align*}
\frac{1}{2}\left(A+A^{*}\right) & =:B & \frac{1}{2\ii}\left(A-A^{*}\right) & =:C
\end{align*}
$A=B+\ii C$, $B$ and $C$ are symmetric and $\left[B,C\right]=0$.


\section{Theorem\label{sec:Thm-Spectral-theorem-commuting-operators}}

Let $H$ be a complex separable Hilbert space, $A_{i}\in L\left(H\right)$
for $i\in\left\{ 1,\ldots,n\right\} $ be symmetric operators, which
commute pair wise, i.e. $\left[A_{i},A_{j}\right]=0$ for all $i,j\in\left\{ 1,\ldots,n\right\} $
and
\begin{align*}
K & :=\prod_{i=1}^{n}\underbrace{\left[-\opnorm{A_{i}},\opnorm{A_{i}}\right]}_{\supseteq\sigma\left(A_{i}\right)}\subseteq\mathbb{R}^{n}
\end{align*}
be compact. Then there is a mapping
\begin{align*}
\Phi:C^{0}\left(K,\mathbb{C}\right) & \to L\left(H\right)
\end{align*}
(notation: $\Phi\left(f\right)=f\left(A_{1},\ldots,A_{n}\right)$)
with the following properties:
\begin{enumerate}[label=\roman*)]
\item $\Phi$ is an involutive algebra homomorphism.
\item $\opnorm{\Phi\left(f\right)}\le\norm f_{\infty}=\sup_{K}\abs f$
\item $\Phi\left(\text{pr}_{i}\right)=A_{i}$ for the projection maps:
\begin{align*}
\text{pr}_{i}:\mathbb{R}^{n} & \to\mathbb{R}\\
\left(x_{1},\ldots,x_{n}\right) & \mapsto x_{i}
\end{align*}

\end{enumerate}

\subsubsection*{Proof}

Let $E_{i}$ be the spectral measure of the operator $A_{i}$.
\begin{align*}
E_{i}\left(M\right) & =\chi_{M}\left(A_{i}\right)
\end{align*}
Let $M\subseteq K$ be a cube, i.e. $M=M_{1}\times\ldots\times M_{n}$.
Define:
\begin{align*}
\chi_{M}\left(A_{1},\ldots,A_{n}\right) & :=\chi_{M_{1}}\left(A_{1}\right)\cdot\ldots\cdot\chi_{M_{n}}\left(A_{M_{n}}\right)
\end{align*}

\begin{itemize}
\item Now holds $\left[\chi_{M_{i}}\left(A_{i}\right),\chi_{M_{j}}\left(A_{j}\right)\right]=0$,
because from
\begin{align*}
\left[A_{i},A_{j}\right] & =0
\end{align*}
follows via induction for any polynomials $p,q$:
\begin{align*}
\left[p\left(A_{i}\right),q\left(A_{j}\right)\right] & =0
\end{align*}
With the Stone-Weierstraß and the Riesz representation theorem follows
for all Borel functions $f,g\in\mathcal{B}\left(\mathbb{R}\right)$:
\begin{align*}
\left[f\left(A_{i}\right),g\left(A_{j}\right)\right] & =0
\end{align*}

\item $\chi_{M}\left(A_{1},\ldots,A_{n}\right)$ is a projection operator.
\begin{align*}
\left(\chi_{M}\left(A_{1},\ldots,A_{n}\right)\right)^{*} & =\overline{\chi_{M_{n}}}\left(A_{n}\right)\cdot\ldots\cdot\overline{\chi_{M_{1}}}\left(A_{1}\right)=\\
 & =\chi_{M_{1}}\left(A_{1}\right)\cdot\ldots\cdot\chi_{M_{n}}\left(A_{n}\right)=\chi_{M}\left(A_{1},\ldots,A_{n}\right)
\end{align*}
\begin{align*}
 & \chi_{M}\left(A_{1},\ldots,A_{n}\right)\cdot\chi_{M'}\left(A_{1},\ldots,A_{n}\right)\\
 & \qquad\qquad=\chi_{M_{1}}\left(A_{1}\right)\cdot\ldots\cdot\chi_{M_{n}}\left(A_{n}\right)\cdot\chi_{M_{1}'}\left(A_{1}\right)\cdot\ldots\cdot\chi_{M_{n}'}\left(A_{n}\right)=\\
 & \qquad\qquad=\chi_{M_{1}\cap M_{1}'}\left(A_{1}\right)\cdot\ldots\cdot\chi_{M_{n}\cap M_{n}'}\left(A_{n}\right)=\chi_{M\cap M'}\left(A_{1},\ldots,A_{n}\right)
\end{align*}

\item Let $f=\sum_{\alpha}a_{\alpha}\chi_{M_{\alpha}}$ be a step function,
meaning that the $M_{\alpha}$ are disjoint cubes and $a_{\alpha}\in\mathbb{C}$.
Define:
\begin{align*}
\Phi\left(f\right) & =\sum_{\alpha}a_{\alpha}\chi_{M_{\alpha}}\left(A_{1},\ldots,A_{n}\right)
\end{align*}


\begin{description}
\item [{Claim:}] This definition is well-defined, i.e. it does not depend
on the decomposition of $f$ into cells.
\item [{Proof:}] Suppose we have:
\begin{align*}
f & =\sum_{\alpha=1}^{N}a_{\alpha}\chi_{M_{\alpha}}=\sum_{\beta=1}^{\tilde{N}}\tilde{a}_{\beta}\chi_{\tilde{M}_{\beta}}
\end{align*}
Choose a joint refinement. In fact, it suffices to consider the case
that $\tilde{M}_{\beta}$ is already a refinement of $M_{\alpha}$.
Thus $M_{\alpha}=\bcupd_{\beta\in I_{\alpha}}M_{\beta}$ and the $I_{\alpha}$
form a partition of $\left\{ 1,\ldots,\tilde{N}\right\} $. Using
the properties of the $E_{i}$, a direct computation gives:
\begin{align*}
\chi_{M_{\alpha}} & =\sum_{\beta\in I_{\alpha}}\chi_{\tilde{M}_{\alpha}}
\end{align*}
Substitute this in the formula for $f$ and reoreder the sums, to
the that the definition is well-defined.\qqed[Claim]
\end{description}
\item Verify the properties i) and ii) for step functions: By direct computation
follows:
\begin{align*}
\left(\Phi\left(f\right)\right)^{*} & =\Phi\left(\overline{f}\right)
\end{align*}
\begin{align*}
\Phi\left(f\right)\cdot\Phi\left(g\right) & =\left(\sum_{\alpha}a_{\alpha}\chi_{M_{\alpha}}\right)\left(\sum_{\beta}a_{\beta}\chi_{M_{\beta}}\right)\stackrel{\text{as above}}{=}\sum_{\alpha,\beta}a_{\alpha}b_{\beta}\chi_{M_{\alpha}\cap M_{\beta}}=\Phi\left(f\cdot g\right)
\end{align*}
\begin{align*}
\norm{\Phi\left(f\right)} & =\norm{\sum_{\alpha}a_{\alpha}\chi_{M_{\alpha}}}\le\left(\max_{\alpha}\abs{a_{\alpha}}\right)\cdot\underbrace{\norm{\sum_{\alpha}\chi_{M_{\alpha}}}}_{\le1}\le\norm f_{\infty}
\end{align*}

\item Now consider $f\in C^{0}\left(K,\mathbb{C}\right)$. There is a sequence
of step functions $f_{k}$ such that $f_{k}\rightrightarrows f$ converges
uniformly.
\begin{align*}
\norm{\Phi\left(f_{k}\right)-\Phi\left(f_{l}\right)} & =\Phi\left(f_{k}-f_{l}\right)\stackrel{\text{ii)}}{\le}\sup\abs{f_{k}-f_{l}}\xrightarrow{k,l\to\infty}0
\end{align*}
Since $H$ is complete, $\Phi\left(f_{k}\right)$ converges in $L\left(H\right)$
and we define $\Phi\left(f\right):=\lim_{k\to\infty}\phi\left(f_{k}\right)$.
Then the properties i) and ii) remain true by continuity.
\item Compute $\Phi\left(\text{pr}_{i}\right)$. For this let $f_{k}=\sum_{\alpha}a_{\alpha}\chi_{M_{\alpha}}$
be a step function with $f_{k}\left(x\right)\rightrightarrows x$
and set $\text{pr}_{i}^{k}\left(x\right)=f_{k}\left(x_{i}\right)$,
which implies $\text{pr}_{i}^{k}\rightrightarrows\text{pr}_{i}$.
\begin{align*}
\Phi\left(\text{pr}_{i}^{k}\right) & =\sum_{\alpha}a_{\alpha}\chi_{\mathbb{R}\times\ldots\times\underbrace{M_{\alpha}}_{i\text{-th position}}\times\ldots\times\mathbb{R}}\left(A_{1},\ldots,A_{n}\right)=\\
 & =\prod_{j\not=i}\underbrace{\chi_{\mathbb{R}}\left(A_{j}\right)}_{=\mathbbm{1}}\cdot\sum_{\alpha}a_{\alpha}\chi_{M_{\alpha}}\left(A_{i}\right)=\chi_{f_{k}}\left(A_{i}\right)\xrightarrow{\text{in }L\left(H\right)}A_{i}
\end{align*}

\end{itemize}
\qqed

We know $\text{supp}\left(\chi\left(A_{j}\right)\right)=\sigma\left(A_{j}\right)\subseteq\left[-\opnorm{A_{j}},\opnorm{A_{j}}\right]$.
\begin{align*}
K & :=\left[-\opnorm{A_{1}},\opnorm{A_{1}}\right]\times\left[-\opnorm{A_{2}},\opnorm{A_{2}}\right]\subseteq\mathbb{C}
\end{align*}
\emph{Goal}: Construct a spectral measure $\chi_{M}\left(A_{1},A_{2}\right)$
on $K$.
\begin{itemize}
\item For $M=M_{1}\times M_{2}$ (``cubes'') we set:
\begin{align*}
\chi_{M_{1}\times M_{2}}\left(A_{1},A_{2}\right) & =\chi_{M_{1}}\left(A\right)\cdot\chi_{M_{2}}\left(A_{2}\right)
\end{align*}

\item For step functions
\begin{align*}
f & =\sum_{\alpha=1}^{N}c_{\alpha}\chi_{M_{1}^{\alpha}\times M_{2}^{\alpha}}
\end{align*}
we set:
\begin{align*}
\Phi\left(f\right) & =\sum_{\alpha=1}^{N}c_{\alpha}\chi_{M_{1}^{\alpha}\times M_{2}^{\alpha}}\left(A_{1},A_{2}\right)
\end{align*}

\item For $f\in C^{0}\left(K\right)$ we choose step functions $f_{n}$
such that $f_{n}\rightrightarrows f$ converges on $K$.
\begin{align*}
\Phi\left(f\right) & :=\lim_{n\to\infty}\Phi\left(f_{n}\right)
\end{align*}
This convergence is in $L\left(H\right)$.
\end{itemize}

\section{Theorem}

Now let $A\in L\left(H\right)$ be normal, i.e. $\left[A,A^{*}\right]=0$,
and define the symmetric bounded operators:
\begin{align*}
A_{1} & :=\frac{1}{2}\left(A+A^{*}\right) & A_{2} & :=\frac{1}{2\ii}\left(A-A^{*}\right)
\end{align*}
Then follows $A=A_{1}+\ii A_{2}$ and $\left[A_{1},A_{2}\right]=0$,
which implies $\left[\chi_{M_{1}}\left(A_{1}\right),\chi_{M_{2}}\left(A_{2}\right)\right]=0$
for all sets $M_{1},M_{2}\subseteq\mathbb{R}$.
\begin{align*}
K & :=\left[-\opnorm{A_{1}},\opnorm{A_{1}}\right]\times\left[-\opnorm{A_{2}},\opnorm{A_{2}}\right]\subseteq\mathbb{C}
\end{align*}
Then there exists exactly one map
\begin{align*}
\Phi:C^{0}\left(K,\mathbb{C}\right) & \to L\left(H\right)
\end{align*}
with the following properties:
\begin{enumerate}[label=\roman*)]
\item $\Phi$ is an involutive algebra homomorphism.
\item $\opnorm{\Phi\left(f\right)}\le\norm f_{\infty}$
\item $f\left(z\right)=z$ for $z\in K$ already implies $\Phi\left(f\right)=A$.
\item $Au=\lambda u$ implies $\Phi\left(f\right)u=f\left(\lambda\right)u$
\item If $f$ is real-valued, then $\Phi\left(f\right)$ is symmetric.
\item $f\ge0$ implies $\Phi\left(f\right)\ge0$.
\item For a $T\in L\left(H\right)$ with $\left[T,A\right]=\left[T,A^{*}\right]=0$
follows for all $f\in C^{0}$:
\begin{align*}
\left[T,\Phi\left(f\right)\right] & =0
\end{align*}

\end{enumerate}

\subsubsection*{Proof}

\begin{align*}
\text{pr}_{1}\left(x_{1},x_{2}\right) & =x_{1}\\
\Phi\left(\text{pr}_{1}\right) & =A_{1}
\end{align*}


Choose step functions $f_{n}$ of one variable, such that $f_{n}\left(x\right)\rightrightarrows x$
on $\left[-\opnorm{A_{1}},\opnorm{A_{1}}\right]$. Then the functions
\begin{align*}
g_{n}\left(x_{1},x_{2}\right) & :=f_{n}\left(x_{1}\right)
\end{align*}
converge uniformly to $\text{pr}_{1}$ on $K$.
\begin{align*}
\Phi\left(g_{n}\right) & =\sum_{\alpha=1}^{N}c_{\alpha}\underbrace{\chi_{M_{1}^{\alpha}\times\left[-\opnorm{A_{2}},\opnorm{A_{2}}\right]}}_{=\chi_{M_{1}^{\alpha}}\left(A_{1}\right)\cdot\underbrace{\chi_{\left[-\opnorm{A_{2}},\opnorm{A_{2}}\right]}\left(A_{2}\right)}_{=\mathbbm{1}}}=\sum_{\alpha=1}^{N}c_{\alpha}\chi_{M_{1}^{\alpha}}\left(A_{1}\right)=f_{n}\left(A_{1}\right)\to A_{1}
\end{align*}
This converges follows from the functional calculus for \emph{a symmetric
operator}.

Choose $\Phi$ as in Theorem \ref{sec:Thm-Spectral-theorem-commuting-operators}
for the commuting operators $A_{1}$ and $A_{2}$. Then i), ii) and
v) follow immediately.
\begin{enumerate}
\item [vi)]For $f\ge0$ there exists a $g\in C^{0}\left(K,\mathbb{R}\right)$
with $f=g^{2}$.
\begin{align*}
\left\langle u,\phi\left(f\right)u\right\rangle  & =\left\langle u,\phi\left(g\right)\cdot\phi\left(g\right)u\right\rangle =\left\langle \phi\left(g\right)u,\phi\left(g\right)u\right\rangle \ge0
\end{align*}

\item [vii)]From $\left[T,A_{1}\right]=0=\left[T,A_{2}\right]$ follows:
\begin{align*}
\left[T,\chi_{M}\left(A_{1}\right)\right] & =0=\left[T,\chi_{M}\left(A_{2}\right)\right]
\end{align*}
This gives by approximation
\begin{align*}
\left[T,\chi_{M}\left(A_{1},A_{2}\right)\right] & =0
\end{align*}
for all $M\subseteq\mathbb{R}^{2}\stackrel{\sim}{=}\mathbb{C}$.%DATE: Do 24.1.13
\item [iii)]From $f\left(z\right)=z$ follows $\Phi\left(f\right)=A$.
\begin{align*}
z & =x_{1}+\ii x_{2}\\
f\left(x_{1},x_{2}\right) & =x_{1}+\ii x_{2}
\end{align*}
\begin{align*}
\Rightarrow\qquad\Phi\left(f\right) & =\Phi\left(\text{pr}_{1}\right)+\ii\Phi\left(\text{pr}_{2}\right)=A_{1}+\ii A_{2}=A
\end{align*}

\item [iv)]We want to show $Au=\lambda u$ implies $\Phi\left(f\right)u=f\left(\lambda\right)u$.
Consider $u\in H$ with $Au=\lambda u$.

\begin{description}
\item [{Claim:}] $A^{*}u=\overline{\lambda}u$
\item [{Proof:}] It holds:
\begin{align*}
A\left(A^{*}u\right) & =A^{*}Au=A^{*}\lambda u=\lambda\left(A^{*}u\right)
\end{align*}
Thus $A^{*}$ maps the eigenspace $\ker\left(A-\lambda\right)$ to
itself, which implies:
\begin{align*}
A^{*}u-\overline{\lambda}u & \in\ker\left(A-\lambda\right)
\end{align*}
For $v\in\ker\left(A-\lambda\right)$ holds:
\begin{align*}
\left\langle v,\left(A^{*}-\overline{\lambda}\right)u\right\rangle  & =\left\langle \left(A-\lambda\right)v,u\right\rangle =0
\end{align*}
Thus we get $\left(A^{*}-\overline{\lambda}\right)u\in\ker\left(A-\lambda\right)\cap\left(\ker\left(A-\lambda\right)\right)^{\perp}=\left\{ 0\right\} $.
Now we have:
\begin{align*}
\left(A^{*}-\overline{\lambda}\right)u & =0
\end{align*}
\qqed[Claim]
\end{description}

So we have:
\begin{align*}
A_{1}u & =\lambda_{1}u & A_{2}u & =\lambda_{2}u & \lambda & =\lambda_{1}+\ii\lambda_{2}
\end{align*}
So $\Phi\left(p\right)u=p\left(\lambda\right)u$ holds for all polynomials
$p$. The Stone-Weierstraß theorem in two dimensions gives the result.

\end{enumerate}
\qqed

Now apply the Riesz representation theorem to extend the functional
calculus to bounded Borel functions $\mathcal{B}\left(K\right)$.


\section{Theorem\label{sec:Thm-normal-functional-calculus}}

Let $A\in L\left(H\right)$ be normal. Then there exists a map
\begin{align*}
\Phi:\mathcal{B}\left(K,\mathbb{C}\right) & \to L\left(H\right)
\end{align*}
with the following properties:
\begin{enumerate}[label=\roman*)]
\item $\Phi$ is an involutive algebra homomorphism.
\item $\opnorm{\Phi\left(f\right)}\le\norm f_{L^{\infty}\left(K\right)}$
\item For $f\in C^{0}$, $\Phi\left(f\right)$ coincides with the continuous
functional calculus.
\item For point-wise converging $f_{n}\to f$ with $\norm f_{\infty}<C$
converges $\Phi\left(f_{n}\right)\to\Phi\left(f\right)$ strongly.
\item $Au=\lambda u$ implies $\Phi\left(f\right)u=f\left(\lambda\right)u$
\item If $f$ is real-valued, then $\Phi\left(f\right)$ is symmetric.\\
$f\ge0$ and implies $\Phi\left(f\right)\ge0$.
\item For a $T\in L\left(H\right)$ with $\left[T,A\right]=\left[T,A^{*}\right]=0$
follows for all $f\in C^{0}$:
\begin{align*}
\left[T,\Phi\left(f\right)\right] & =0
\end{align*}

\end{enumerate}

\subsubsection*{Proof}

The proof is the same as for the symmetric case.\qqed


\section{Theorem \textmd{(spectral theorem for bounded normal operators)}}

There is a one-to-one correspondence between bounded normal operators
on $H$ and compact spectral measures via:
\begin{align*}
A & =\int_{\mathbb{R}^{2}\stackrel{\sim}{=}\mathbb{C}}\lambda\dd E_{\lambda}
\end{align*}
Moreover holds:
\begin{enumerate}[label=\roman*)]
\item $f\left(A\right)=\Phi\left(f\right)=\int_{\mathbb{R}^{2}}f\left(\lambda\right)\dd E_{\lambda}$
\item $\sigma\left(A\right)=\text{supp}\left(E\right)\subseteq\mathbb{R}^{2}\stackrel{\sim}{=}\mathbb{C}$
\end{enumerate}

\subsubsection*{Proof}

The proof is just as in the symmetric case, except for the property
ii).

„$\text{supp}\left(E\right)\supseteq\sigma\left(A\right)$“: Consider
$\mu\not\in\text{supp}\left(E\right)$. Then
\begin{align*}
g\left(\lambda\right) & :=\frac{1}{\lambda-\mu}\cdot\chi_{\text{supp}\left(E\right)}
\end{align*}
is a bounded Borel function, since $\abs{g\left(\lambda\right)}\le\frac{1}{\varepsilon}$,
where $B_{\varepsilon}\left(\mu\right)\cap\text{supp}\left(E\right)=\emptyset$
and:
\begin{align*}
g\left(A\right)\cdot\left(A-\mu\right) & =\int_{\mathbb{R}^{2}}\frac{\lambda-\mu}{\lambda-\mu}\dd E_{\lambda}=\mathbbm{1}
\end{align*}


\begin{figure}[H]
\noindent \begin{centering}
\begin{tikzpicture}[scale=1.5]
  % Axen
  \draw[->] (-2,0) -- (2,0) node[right]{$\textnormal{Re}(z)$};
  \draw[->] (0,-1.3) -- (0,2) node[above]{$\textnormal{Im}(z)$};
  \draw plot[smooth cycle,tension=.7] coordinates{(0,-1) (0.75,-0.3) (1.7,0) (0.9,1.9) (-0.5,1.5) (-0.3,0.3) (-1,-0.5)};
  \node at (1.7,2) {$\textnormal{supp}(E)$};
  \draw (-0.8,0.5) node[left]{$\mu$} +(0.1,0.1) -- +(-0.1,-0.1) +(-0.1,0.1) -- +(0.1,-0.1);
  \draw[red] (-0.8,0.5) circle (0.45) ;
  \draw[red] (-0.8,0.5) -- node[right=-3pt]{$\varepsilon$} (-0.8,0.95);
\end{tikzpicture}
\par\end{centering}

\caption{$B_{\varepsilon}\left(\mu\right)\cap\text{supp}\left(E\right)=\emptyset$}
\end{figure}


Hence $\left(A-\lambda\right)$ has a bounded inverse and therefore
$\lambda\not\in\sigma\left(A\right)$.

„$\text{supp}\left(E\right)\subseteq\sigma\left(A\right)$“: For $\mu_{0}\in\varrho\left(A\right)$
we show $\mu_{0}\not\in\text{supp}\left(E\right)$.\\
Since $\varrho\left(A\right)$ is open, there exists a $\varepsilon\in\mathbb{R}_{>0}$
with $B_{\varepsilon}\left(\mu_{0}\right)\subseteq\varrho\left(A\right)$.

\begin{figure}[H]
\noindent \begin{centering}
\begin{tikzpicture}[scale=1.5]
  % Axen
  \draw[->] (-2,0) -- (2,0) node[right]{$\textnormal{Re}(z)$};
  \draw[->] (0,-1.3) -- (0,2) node[above]{$\textnormal{Im}(z)$};
  \draw plot[smooth cycle,tension=.7] coordinates{(0,-1) (0.75,-0.3) (1.7,0) (0.9,1.9) (-0.5,1.5) (-0.3,0.3) (-1,-0.5)};
  \node at (1.5,1.8) {$\sigma(A)$};
  \draw (-0.8,0.5) node[left]{$\mu_0$} +(0.1,0.1) -- +(-0.1,-0.1) +(-0.1,0.1) -- +(0.1,-0.1);
  \draw[red] (-0.8,0.5) circle (0.45) ;
  \draw[red] (-0.8,0.5) -- node[right=-3pt]{$\varepsilon$} (-0.8,0.95);
\end{tikzpicture}
\par\end{centering}

\caption{$B_{\varepsilon}\left(\mu_{0}\right)\subseteq\varrho\left(A\right)$}
\end{figure}


Lemma \ref{sec:Lemma-approximate-inverse} states: Let $B\in L\left(H\right)$
be an operator with bounded inverse and $B_{n}\in L\left(H\right)$
a sequence with $B_{n}\to B$ in $L\left(H\right)$. Then $B_{n}^{-1}$
exists for large enough $n$ and $B_{n}^{-1}\to B$ converges in $L\left(H\right)$.\\
In particular, for $\mu_{n}\xrightarrow{n\to\infty}\mu_{0}$ converges
also $\left(A-\mu_{n}\right)^{-1}\to\left(A-\mu_{0}\right)^{-1}$
in $L\left(H\right)$.\\
Consider now $\mu\in B_{r}\left(\mu_{0}\right)$ for any $r\in\mathbb{R}_{>0}$
and define:
\begin{align*}
B & :=\left(A-\mu\right)\cdot\left(A^{*}-\overline{\mu}\right)=\int\abs{\lambda-\mu}^{2}\dd E_{\lambda}
\end{align*}
Now choose a $\delta\in\mathbb{R}_{>0}$ to get:
\begin{align*}
B+\delta & =\int\left(\abs{\lambda-\mu}^{2}+\delta\right)\dd E_{\lambda}\\
\Rightarrow\qquad\left(B+\delta\right)^{-1} & =\int\frac{1}{\abs{\lambda-\mu}^{2}+\delta}\dd E_{\lambda}\in L\left(H\right)
\end{align*}
Similarly follows:
\begin{align*}
B^{p} & =\int\abs{\lambda-\mu}^{2p}\dd E_{\lambda}\\
\left(B+\delta\right)^{-p} & =\int\left(\abs{\lambda-\mu}^{2}+\delta\right)^{-p}\dd E_{\lambda}
\end{align*}
For $u\in H$ with $\norm u=1$ holds:
\begin{align*}
\left\langle u,\left(B+\delta\right)^{-p}u\right\rangle  & =\int_{\mathbb{R}^{2}}\frac{1}{\left(\abs{\lambda-\mu}^{2}+\delta\right)^{p}}\dd\left\langle u,E_{\lambda}u\right\rangle 
\end{align*}
$\dd\left\langle u,E_{\lambda}u\right\rangle $ is a point-wise bounded
Borel measure.
\begin{align*}
\abs{\left\langle u,\left(B+\delta\right)^{-p}u\right\rangle } & \le\underbrace{\norm u^{2}}_{=1}\cdot\norm{\left(B+\delta\right)^{-1}\left(B+\delta\right)^{-\left(p-1\right)}}\le\\
 & \le\ldots\le\opnorm{\left(B+\delta\right)^{-1}}^{p}\stackrel{\text{choose }r<\varepsilon}{\le}\opnorm{B^{-1}}^{p}
\end{align*}
\begin{align*}
\Rightarrow\qquad\liminf_{\delta}\abs{\left\langle u,\left(B+\delta\right)^{-p}u\right\rangle } & \le\norm{B^{-1}}^{p}
\end{align*}
Remember Fatou's lemma:
\begin{align*}
\int\liminf_{\delta}f_{\delta} & \le\liminf_{\delta}\int f_{\delta}
\end{align*}
holds if $\lim_{\delta\searrow0}f_{\delta}$ exists point-wise. (cf.
\noun{Rudin}: \emph{Real and complex analysis})

Applying Fatou's lemma gives:
\begin{align*}
\int_{\mathbb{R}^{2}}\liminf_{\delta}\frac{1}{\left(\abs{\lambda-\mu}^{2}+\delta\right)^{p}}\dd\left\langle u,E_{\lambda}u\right\rangle  & =\int_{\mathbb{R}^{2}}\frac{1}{\abs{\lambda-\mu}^{2p}}\dd\left\langle u,E_{\lambda}u\right\rangle \le\\
 & \le\liminf_{\delta}\int_{\mathbb{R}^{2}}\frac{1}{\left(\abs{\lambda-\mu}^{2}+\delta\right)^{p}}\dd\left\langle u,E_{\lambda}u\right\rangle \le\opnorm{B^{-1}}^{p}
\end{align*}
Thus we get:
\begin{align*}
\left(\int\frac{1}{\abs{\lambda-\mu}^{2p}}\dd\left\langle u,E_{\lambda}u\right\rangle \right)^{\frac{1}{p}} & \le\opnorm{B^{-1}}
\end{align*}
In other words, setting $g\left(\lambda\right)=\frac{1}{\abs{\lambda-\mu}^{2}}$,
we know for all $p\in\mathbb{N}_{\ge1}$ and all $\mu\in B_{\frac{\varepsilon}{2}}\left(\mu_{0}\right)$:
\begin{align*}
\norm g_{L^{p}\left(\dd\left\langle u,E_{\lambda}u\right\rangle \right)} & \le\opnorm{B^{-1}}
\end{align*}
This implies that there exists an $\varepsilon'\in\mathbb{R}_{>0}$
such that $B_{\varepsilon'}\left(\mu_{0}\right)$ is a set with measure
zero with respect to $\dd\left\langle u,E_{\lambda}u\right\rangle $,
since otherwise:
\begin{align*}
\left(\int\frac{1}{\abs{\lambda-\mu}^{2p}}\dd\left\langle u,E_{\lambda}u\right\rangle \right)^{\frac{1}{p}} & \ge\inf_{\lambda\in B_{\varepsilon'}\left(\mu_{0}\right)}\frac{1}{\abs{\lambda-\mu}^{2}}\cdot\underbrace{\left(\left\langle u,\dd E_{B_{\varepsilon'}\left(\mu_{0}\right)}u\right\rangle \right)^{\frac{1}{p}}}_{>0}\xrightarrow{p\to\infty}\inf_{\lambda\in B_{\varepsilon'}\left(\mu_{0}\right)}\frac{1}{\abs{\mu-\lambda}^{2}}
\end{align*}
Since $u$ is arbitrary (and $\varepsilon'$ can be chosen uniformly
in $u$) it follows that $E_{B_{\varepsilon'}\left(\mu_{0}\right)}=0$
and thus $\mu_{0}\not\in\text{supp}\left(E\right)$.\qqed


\section{Lemma\label{sec:Lemma-approximate-inverse}}

Let $B\in L\left(H\right)$ be an operator with bounded inverse and
$B_{n}\in L\left(H\right)$ a sequence with $B_{n}\to B$ in $L\left(H\right)$.
Then $B_{n}^{-1}$ exists for large enough $n$ and $B_{n}^{-1}\to B$
converges in $L\left(H\right)$.


\subsubsection*{Proof}

Use the Neumann series:
\begin{align*}
B_{n}^{-1} & =\left(B+\left(B_{n}-B\right)\right)^{-1}=\left(\mathbbm{1}+B^{-1}\left(B_{n}-B\right)\right)B^{-1}=\sum_{k=0}^{\infty}\left(-B^{-1}\left(B_{n}-B\right)\right)^{k}B^{-1}
\end{align*}
This converges absolutely, if $\opnorm{B_{n}-B}$ is sufficiently
small. Therefore holds:
\begin{align*}
\opnorm{B_{n}^{-1}-B^{-1}} & \le\sum_{k=1}^{\infty}\opnorm{B^{-1}}^{k+1}\cdot\opnorm{B_{n}-B}^{k}\xrightarrow{\opnorm{B_{n}\to B}}0
\end{align*}
\qqed[Lemma]


\section{Theorem}

Let $A\in L\left(H\right)$ be normal and $E$ the corresponding spectral
measure. Then holds for all $\varepsilon\in\mathbb{R}_{>0}$:
\begin{align*}
\lambda\in\sigma\left(A\right) & \quad\Leftrightarrow\quad E_{B_{\varepsilon}\left(\lambda\right)}\not=0
\end{align*}



\subsubsection*{Proof}

\begin{align*}
\lambda\in\sigma\left(A\right) & \quad\Leftrightarrow\quad\lambda\in\text{supp}\left(E\right)\quad\stackrel{\text{definition of }\text{supp}\left(E\right)}{\Leftrightarrow}\quad E_{B_{\varepsilon}\left(\lambda\right)}\not=0
\end{align*}
\qqed


\section{Theorem \textmd{(spectral mapping theorem for normal operators)}}

Let $A\in L\left(H\right)$ be normal and $f\in C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)$.
Then $\sigma\left(f\left(A\right)\right)=f\left(\sigma\left(A\right)\right)$.

\emph{Note}: This is not true in general for $f\in\mathcal{B}\left(\sigma\left(A\right),\mathbb{C}\right)$.


\subsubsection*{Proof}
\begin{enumerate}[label=\roman*)]
\item „$\sigma\left(f\left(A\right)\right)\subseteq f\left(\sigma\left(A\right)\right)$“:
Since $\sigma\left(A\right)$ is compact and $f$ continuous and therefore
maps compact sets to compact sets, follows:
\begin{align*}
f\left(\sigma\left(A\right)\right) & =\overline{f\left(\sigma\left(A\right)\right)}
\end{align*}
We show more generally:
\begin{align*}
\sigma\left(f\left(A\right)\right) & \subseteq\overline{f\left(\sigma\left(A\right)\right)}
\end{align*}
for any \emph{Borel} function $f\in\mathcal{B}\left(\sigma\left(A\right)\right)$.
Consider $\mu\not\in\overline{f\left(\sigma\left(A\right)\right)}$
and set:
\begin{align*}
g\left(\lambda\right) & =\frac{1}{f\left(\lambda\right)-\mu}\cdot\chi_{\sigma\left(A\right)}
\end{align*}
This is a bounded Borel function. Thus follows:
\begin{align*}
g\left(A\right)\cdot\left(f\left(A\right)-\mu\right) & =\int_{\mathbb{R}^{2}}\frac{f\left(\lambda\right)-\mu}{f\left(\lambda\right)-\mu}\chi_{\sigma\left(A\right)}\dd E_{\lambda}\stackrel{\sigma\left(A\right)=\text{supp}\left(E\right)}{=}\mathbbm{1}
\end{align*}
Hence $f\left(A\right)-\mu$ has a bounded inverse $g\left(A\right)$
and thus $\mu\in\varrho\left(f\left(A\right)\right)$, i.e. $\mu\not\in\sigma\left(f\left(A\right)\right)$.\qqed[\roman{enumi})]
\item „$f\left(\sigma\left(A\right)\right)\subseteq\sigma\left(f\left(A\right)\right)$“:
Consider $\mu\in\sigma\left(A\right)$ and show $f\left(\mu\right)\in\sigma\left(f\left(A\right)\right)$.\\
%DATE: Fr 25.1.13\\
From $\sigma\left(A\right)=\text{supp}\left(E\right)$ follows for
all $\varepsilon\in\mathbb{R}_{>0}$:
\begin{align*}
E_{B_{\varepsilon}\left(\mu\right)} & \not=0
\end{align*}
Thus we may choose $u\not=0$ with:
\begin{align*}
E_{B_{\varepsilon}\left(\mu\right)}u & =u
\end{align*}
Then holds:
\begin{align*}
\norm{\left(f\left(A\right)-f\left(\mu\right)\right)u}^{2} & =\left\langle \left(f\left(A\right)-f\left(\mu\right)\right)u,\left(f\left(A\right)-f\left(\mu\right)\right)u\right\rangle =\\
 & =\left\langle u,\left(\overline{f}\left(A\right)-\overline{f}\left(\mu\right)\right)\left(f\left(A\right)-f\left(\mu\right)\right)u\right\rangle =\\
 & =\int_{\mathbb{R}^{2}}\abs{f\left(\lambda\right)-f\left(\mu\right)}^{2}\dd\left\langle u,E_{\lambda}u\right\rangle =\\
 & =\int_{\mathbb{R}^{2}}\abs{f\left(\lambda\right)-f\left(\mu\right)}^{2}\dd\left\langle E_{B_{\varepsilon}\left(\mu\right)}u,E_{\lambda}E_{B_{\varepsilon}\left(\mu\right)}u\right\rangle =\\
 & =\int_{B_{\varepsilon}\left(\mu\right)}\abs{f\left(\lambda\right)-f\left(\mu\right)}^{2}\dd\left\langle u,E_{\lambda}u\right\rangle \le\\
 & \le\sup_{B_{\varepsilon}\left(\mu\right)}\abs{f\left(\lambda\right)-f\left(\mu\right)}^{2}\int_{\mathbb{R}^{2}}\dd\left\langle u,E_{\lambda}u\right\rangle \le\\
 & \le\sup_{B_{\varepsilon}\left(\mu\right)}\abs{f\left(\lambda\right)-f\left(\mu\right)}^{2}\norm u^{2}
\end{align*}
Since $f$ is continuous, there exists a sequence $u_{n}\in H$ with
$\norm{u_{n}}=1$ such that holds:
\begin{align*}
\norm{\left(f\left(A\right)-f\left(\mu\right)\right)u_{n}} & \to0
\end{align*}
Hence $f\left(A\right)-f\left(\mu\right)$ has no bounded inverse
and therefore follows $\mu\in\sigma\left(f\left(A\right)\right)$.
\end{enumerate}
\qqed


\section{Corollary}

For a normal $A\in L\left(H\right)$ and a $f\in C^{0}\left(\sigma\left(A\right)\right)$
holds:
\begin{align*}
\opnorm{f\left(A\right)} & =\norm f_{L^{\infty}\left(\sigma\left(A\right)\right)}
\end{align*}



\subsubsection*{Proof}

From $\left(f\left(A\right)\right)^{*}=\overline{f}\left(A\right)$
follows:
\begin{align*}
\left(f\left(A\right)\right)^{*}f\left(A\right) & =\abs f^{2}\left(A\right)=f\left(A\right)\left(f\left(A\right)\right)^{*}
\end{align*}
Hence the operator $f\left(A\right)$ is normal.
\begin{align*}
\opnorm{f\left(A\right)} & =r\left(f\left(A\right)\right)=\sup\left\{ \abs{\mu}\big|\mu\in\sigma\left(f\left(A\right)\right)\right\} =\\
 & =\sup\left\{ \abs{\mu}\big|\mu\in f\left(\sigma\left(A\right)\right)\right\} =\sup\left\{ \abs{f\left(\lambda\right)}\big|\lambda\in\sigma\left(A\right)\right\} =\norm f_{L^{\infty}\left(\sigma\left(A\right)\right)}
\end{align*}
\qqed

Thus the mapping
\begin{align*}
\Phi:C^{0}\left(\sigma\left(A\right),\mathbb{C}\right) & \to L\left(H\right)
\end{align*}
is preserving the norm. Be careful to remember that
\begin{align*}
\Phi:C^{0}\left(\mathbb{R}^{2},\mathbb{C}\right) & \to L\left(H\right)
\end{align*}
is \emph{not} preserving the norm. Instead holds:
\begin{align*}
\opnorm{f\left(A\right)} & \le\norm f_{L^{\infty}\left(\mathbb{R}\right)}
\end{align*}



\section{Theorem}

Let $A\in L\left(H\right)$ be normal and $E$ the corresponding spectral
measure. Then $\mu$ is an eigenvalue of $A$ if and only if $E_{\left\{ \mu\right\} }\not=0$.


\subsubsection*{Proof}

„$\Leftarrow$“: Assume that $E_{\left\{ \mu\right\} }\not=0$. Now
choose a vector $u\not=0$ with $E_{\left\{ \mu\right\} }u=u$. Then
holds:
\begin{align*}
\norm{\left(A-\mu\right)u}^{2} & =\int_{\mathbb{R}^{2}}\abs{\lambda-\mu}^{2}\dd\left\langle u,E_{\lambda}u\right\rangle =\int_{\mathbb{R}^{2}}\abs{\lambda-\mu}^{2}\dd\left\langle E_{\left\{ \mu\right\} }u,E_{\lambda}E_{\left\{ \mu\right\} }u\right\rangle =\\
 & =\int_{\mathbb{R}^{2}}\underbrace{\abs{\lambda-\mu}^{2}\chi_{\left\{ \mu\right\} }\left(\lambda\right)}_{=0}\dd\left\langle u,E_{\lambda}u\right\rangle =0
\end{align*}
„$\Rightarrow$“: Let $u$ be an eigenvector.
\begin{align*}
Au & =\mu u
\end{align*}
Then holds for all $f\in\mathcal{B}\left(\mathbb{R}^{2}\right)$ after
theorem \ref{sec:Thm-normal-functional-calculus} v):
\begin{align*}
f\left(A\right)u & =f\left(\mu\right)u
\end{align*}
Choose $f=\chi_{\left\{ \mu\right\} }$ to get:
\begin{align*}
f\left(A\right) & =\chi_{\left\{ \mu\right\} }\left(A\right)=E_{\left\{ \mu\right\} }
\end{align*}
\begin{align*}
\Rightarrow\qquad E_{\left\{ \mu\right\} }u & =u
\end{align*}
Hence follows $E_{\left\{ \mu\right\} }\not=0$.\qqed


\chapter{Cyclic vectors, the spectral theorem in its multiplicative form}

Let $A\in L\left(H\right)$ be normal.


\section{Definition \textmd{(cyclic vector)}}

A vector $u\in H$ is called \emph{cyclic} (with respect to $A$)
if holds:
\begin{align*}
\overline{\left\{ f\left(A\right)u\big|f\in C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)\right\} } & =H
\end{align*}



\section{Theorem\label{sec:Thm-cyclic-vector_unitary-operator}}

Let $u\in H$ be a cyclic vector. Then there exists a unitary operator
\begin{align*}
\mathcal{U}:H & \to L^{2}\big(\sigma\left(A\right),\underbrace{\dd\left\langle u,E_{\lambda}u\right\rangle }_{=\dd\mu_{u}}\big)
\end{align*}
such that for $f\in L^{2}\left(\sigma\left(A\right),\dd\left\langle u,E_{\lambda}u\right\rangle \right)$
and $g\left(\lambda\right)=\lambda$ holds:
\begin{align*}
\mathcal{U}A\mathcal{U}^{-1}f & =g\cdot f
\end{align*}



\subsubsection*{Proof}

\begin{align*}
\alpha\left(f\left(A\right)u\right)+\beta\left(g\left(A\right)u\right) & =\left(\alpha f+\beta g\right)\left(A\right)u
\end{align*}
\begin{align*}
\Rightarrow\qquad I_{u} & :=\left\{ f\left(A\right)u\big|f\in C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)\right\} =\left\langle f\left(A\right)u\big|f\in C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)\right\rangle 
\end{align*}
By assumption, $I_{u}$ is dense in $H$. Define
\begin{align*}
\mathcal{U}:I_{u} & \to L^{2}\left(\sigma\left(A\right),\dd\mu_{u}\right)
\end{align*}
by:
\begin{align*}
\mathcal{U}\left(f\left(A\right)u\right) & =f
\end{align*}
This is well-defined and an isometry, because:
\begin{align*}
\left\langle f\left(A\right)u,f\left(A\right)u\right\rangle  & =\int\abs{f\left(\lambda\right)}^{2}\underbrace{\dd\left\langle u,E_{\lambda}u\right\rangle }_{=\dd\mu_{u}}=\left\langle f,f\right\rangle _{L^{2}\left(\sigma\left(A\right),\dd\mu_{u}\right)}
\end{align*}
Moreover, the image of $\mathcal{U}$ is $C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)$
and this is dense in $L^{2}\left(\sigma\left(A\right),\dd\mu_{u}\right)$.
Therefore $\mathcal{U}$ can be uniquely extended by continuity to
an unitary operator:
\begin{align*}
\mathcal{U}:H=\overline{I_{u}} & \to\overline{C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)}=L^{2}\left(\sigma\left(A\right),\dd\mu_{u}\right)
\end{align*}
Compute now $\mathcal{U}A\mathcal{U}^{-1}$:
\begin{align*}
\mathcal{U}\left(f\left(A\right)u\right) & =f
\end{align*}
\begin{align*}
\mathcal{U}A\mathcal{U}^{-1}f & =\mathcal{U}\underbrace{A}_{=g\left(A\right)}\left(f\left(A\right)u\right)=\mathcal{U}\left(\left(g\cdot f\right)\left(A\right)u\right)=g\cdot f
\end{align*}
Using a density argument one shows that this holds for any $f\in L^{2}$.\qqed


\section{Examples}
\begin{enumerate}
\item Let $H$ be finite-dimensional and $A$ symmetric with simple eigenvalues
$\lambda_{1},\ldots,\lambda_{n}$. In an eigenvector basis holds:
\begin{align*}
A & =\left(\begin{array}{ccc}
\lambda_{1} &  & 0\\
 & \ddots\\
0 &  & \lambda_{n}
\end{array}\right)
\end{align*}
For $v=\left(1,0,\ldots,0\right)^{\TT}$ follows:
\begin{align*}
f\left(A\right)v & =\left(\begin{array}{ccc}
f\left(\lambda_{1}\right) &  & 0\\
 & \ddots\\
0 &  & f\left(\lambda_{n}\right)
\end{array}\right)v=f\left(\lambda_{1}\right)v
\end{align*}
Therefore this $v$ is not cyclic. Choose $u=\left(1,\ldots,1\right)^{\TT}$
to get:
\begin{align*}
f\left(A\right)u & =\left(\begin{array}{c}
f\left(\lambda_{1}\right)\\
\vdots\\
f\left(\lambda_{n}\right)
\end{array}\right)
\end{align*}
Since $\lambda_{i}\not=\lambda_{j}$ holds for $i\not=j$, there are
$f_{i}\in C^{0}\left(\sigma\left(A\right)\right)$ such that $f_{i}\left(\lambda_{i}\right)=1$
and $f_{i}\left(\lambda_{j}\right)=0$ for $i\not=j$$ $. With this
holds $f_{i}\left(A\right)u=e_{i}$. Therefore holds:
\begin{align*}
\left\{ f\left(A\right)u\big|f\in C^{0}\right\}  & =H
\end{align*}

\item Let $A$ be as in 1., but with the degeneracy $\lambda_{1}=\lambda_{2}$
and $u=\left(u_{1},\ldots,u_{n}\right)^{\TT}$. Then follows
\begin{align*}
f\left(A\right)u & =\left(\begin{array}{c}
f\left(\lambda_{1}\right)u_{1}\\
\vdots\\
f\left(\lambda_{n}\right)u_{n}
\end{array}\right)
\end{align*}
and the vector $v=\left(v_{1},v_{2},0,\ldots,0\right)^{\TT}$ with
\begin{align*}
\left(\begin{array}{c}
v_{1}\\
v_{2}
\end{array}\right) & \nparallel\left(\begin{array}{c}
u_{1}\\
u_{2}
\end{array}\right)
\end{align*}
is not in:
\begin{align*}
\left\{ f\left(A\right)u\big|f\in C^{0}\right\} 
\end{align*}
Hence there is no cyclic vector.
\end{enumerate}
\emph{Question}: What can we do if there is a cyclic vector?


\section{Lemma}

Let $A\in L\left(H\right)$ be normal and $A$ symmetric. Then there
exists an orthogonal decomposition
\begin{align*}
H & =\bigoplus_{j\in J}H_{j}
\end{align*}
with a finite or countable $J$ and to every $j\in J$ there is a
cyclic vector $u_{j}\in H_{j}$, i.e.:
\begin{align*}
H_{j} & =\overline{\left\{ f\left(A\right)u_{i}\big|f\in C^{0}\left(\sigma\left(A\right),\mathbb{C}\right)\right\} }
\end{align*}



\subsubsection*{Proof}

Let $\left(e_{i}\right)_{i\in\mathbb{N}}$ be an orthonormal Hilbert
basis. Choose $u_{1}=e_{1}$ and define:
\begin{align*}
H_{1} & :=\overline{\left\{ f\left(A\right)u_{1}\big|f\in C^{0}\right\} }\subseteq H
\end{align*}
If $H_{1}=H$, we are done. Otherwise, let $i_{0}\in\mathbb{N}$ be
the smallest number with $e_{i_{0}}\not\in H_{1}$ and set:
\begin{align*}
u_{2} & :=e_{i_{0}}-\text{pr}_{H_{1}}\left(e_{i_{0}}\right)=\text{pr}_{H_{1}^{\perp}}\left(e_{i_{0}}\right)\\
H_{2} & :=\overline{\left\{ f\left(A\right)u_{2}\big|f\in C^{0}\right\} }\subseteq H
\end{align*}
For $H=\left\langle H_{1},H_{2}\right\rangle $ we stop the procedure.
Otherwise choose $i_{1}$ as the smallest number such that $e_{i_{1}}\not\in\left\langle H_{1},H_{2}\right\rangle $,
and so on.\\
Proceeding inductively, we obtain that $J=\left\{ i_{k}\big|k\in\mathbb{N}\right\} $
is finite or countable and for $j\in J$ we have:
\begin{align*}
H_{j} & =\overline{\left\{ f\left(A\right)u_{j}\big|f\in C^{0}\right\} }
\end{align*}

\begin{itemize}
\item $H_{i}\perp H_{j}$ for $i\not=j$:
\begin{align*}
\left\langle f\left(A\right)u_{i},g\left(A\right)u_{j}\right\rangle  & =\big\langle\underbrace{\left(\overline{g}\cdot f\right)\left(A\right)u_{i}}_{\in H_{i}},u_{j}\big\rangle\stackrel{u_{j}\in H_{i}^{\perp}}{=}0
\end{align*}
The result follows by using that $\left\{ f\left(A\right)u_{i}\right\} $
and $\left\{ g\left(A\right)u_{j}\right\} $ are dense in $H_{i}$
respectively $H_{j}$.
\item The $H_{i}$ generate a dense subset of $H$: By construction we have:
\begin{align*}
e_{i_{k}} & \in\left\langle H_{1},H_{2},\ldots,H_{k+2}\right\rangle 
\end{align*}
Since $i_{k}\ge k$ holds, every basis vector $e_{i}$ is contained
in $\left\langle H_{1},H_{2},\ldots,H_{i+2}\right\rangle $. Hence
the algebraic span of the $\left(e_{i}\right)$ is contained in the
span of the $\left(H_{i}\right)_{i\in J}$.
\end{itemize}
\qqed


\section{Theorem \textmd{(spectral theorem in its multiplicative form)}}

Let $A\in L\left(H\right)$ be normal and $H$ separable. Then there
is a $\sigma$-compact measure space $\Omega$ with a finite measure
$\mu$ and a unitary operator
\begin{align*}
\mathcal{U}:H & \to L^{2}\left(\Omega,\dd\mu\right)
\end{align*}
such that for $g\in L^{\infty}\left(\Omega,\mu\right)$ holds:
\begin{align*}
\mathcal{U}A\mathcal{U}^{-1}f & =g\cdot f
\end{align*}



\subsubsection*{Proof}

Choose an orthogonal decomposition
\begin{align*}
H & =\bigoplus_{i\in J}H_{i}
\end{align*}
with cyclic $u_{i}\in H_{i}$. The subspaces
\begin{align*}
H_{i} & =\overline{\left\{ f\left(A\right)u_{i}\big|f\in C^{0}\right\} }
\end{align*}
are invariant under $A$, i.e. $A_{i}:=A\big|_{H_{i}}:H_{i}\to H_{i}$.
Now we rescale $u_{i}$ to get $\norm{u_{i}}=2^{-i}$. 
\begin{align*}
\mathcal{U}_{i}:H_{i} & \to L^{2}\big(\sigma\left(A\right),\underbrace{\dd\left\langle u_{i},E_{\lambda}u_{i}\right\rangle }_{=\dd\mu_{u_{i}}}\big)\\
f\left(A\right)u_{i} & \mapsto f
\end{align*}
This is just as before in theorem \ref{sec:Thm-cyclic-vector_unitary-operator}
unitary and for $g_{i}\left(\lambda\right)=\lambda$ holds:
\begin{align*}
\mathcal{U}_{i}A_{i}\mathcal{U}_{i}^{-1}f_{i} & =g_{i}f_{i}
\end{align*}
Now define:
\begin{align*}
\Omega & :=\sigma\left(A\right)\times J & \Omega_{i} & =\sigma\left(A\right)\times\left\{ i\right\} 
\end{align*}
%DATE: Do 31.1.13

Thus holds:
\begin{align*}
\Omega & =\bcupd_{i\in J}\Omega_{i}
\end{align*}
Define a measure:
\begin{align*}
\mu:\Omega_{i} & \to\mathbb{R}_{0}^{+}\\
\mu\left(U\times\left\{ i\right\} \right) & :=\mu_{u_{i}}\left(U\right)
\end{align*}
Extend $\mu$ by $\sigma$-additivity to a unique measure on $\Omega$.
For $U\subseteq\Omega$ we write with appropriate $U_{i}\subseteq\Omega_{i}$:
\begin{align*}
U & =\bcupd_{i\in I}U_{i}
\end{align*}


\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}[scale=1.5]
  \draw plot[smooth cycle,tension=.7] coordinates{(0,-1) (0.5,-0.3) (1,0) (0.5,0.8) (0,1) (-0.6,0.7) (-1,0)};
  \node at (0,1.5) {$\sigma(A) \times \{1\}$};
  \draw[red] plot[smooth cycle,tension=.7] coordinates{(0,-0.5) (0.3,-0.2) (0.7,0) (0.5,0.4) (0,0.5) (-0.3,0.2) (-0.5,0)} node[right=5pt]{$U_1$};
  \begin{scope}[xshift=80]
    \draw plot[smooth cycle,tension=.7] coordinates{(0,-1) (0.5,-0.3) (1,0) (0.5,0.8) (0,1) (-0.6,0.7) (-1,0)};
  \node at (0,1.5) {$\sigma(A) \times \{2\}$};
    \draw[red] plot[smooth cycle,tension=.7] coordinates{(0,-0.6) (0.2,-0.2) (0.4,0) (0.6,0.4) (0,0.8) (-0.6,0.2) (-0.5,-0.5)} node[above right]{$U_2$};
  \end{scope}
\end{tikzpicture}\caption{${\displaystyle U=\bcupd_{i\in I}U_{i}}$}
\end{figure}


Define ${\displaystyle \mu\left(U\right):=\sum_{i\in J}\mu\left(U_{i}\right)}$.
\begin{align*}
\mu\left(\Omega_{i}\right) & =\mu_{u_{i}}\left(\sigma\left(A\right)\right)=\big\langle u_{i},\underbrace{E_{\sigma\left(A\right)}}_{=\mathbbm{1}}u_{i}\big\rangle=\norm{u_{i}}^{2}=2^{-2i}
\end{align*}
\begin{align*}
\mu\left(\Omega\right) & =\sum_{i\in J}\mu\left(\Omega_{i}\right)=\sum_{i\in J}2^{-2i}\le1
\end{align*}
Thus $\mu$ is a bounded Borel measure.
\begin{align*}
\mathcal{U} & :=\bigoplus_{i\in J}\mathcal{U}_{i}:H\to L^{2}\left(\Omega,\dd\mu\right)
\end{align*}
is unitary.
\begin{align*}
L^{2}\left(\Omega,\dd\mu\right) & =\bigoplus_{i\in J}L^{2}\left(\Omega_{i},\dd\mu_{i}\right)\\
\mathcal{U}\uparrow\qquad & \qquad\qquad\quad\uparrow\mathcal{U}_{i}\\
H\qquad & =\qquad\bigoplus_{i\in J}H_{i}
\end{align*}
\begin{align*}
\left(\mathcal{U}A\mathcal{U}^{-1}\right)f & =\bigoplus_{i\in J}g_{i}\underbrace{f_{i}}_{\in L^{2}\left(\Omega_{i},\dd\mu_{i}\right)}
\end{align*}
Here $g_{i}\left(\left\{ \lambda\right\} \times\left\{ i\right\} \right)=\lambda$.
Now
\begin{align*}
g & :=\bigoplus_{i\in J}g_{i}
\end{align*}
is a bounded function:
\begin{align*}
\norm g_{L^{\infty}} & \le\sup_{\lambda\in\sigma\left(A\right)}\abs{\lambda}=r\left(A\right)
\end{align*}
\qqed


\section{The pure point spectrum and the absolutely continuous spectrum}

Let $A\in L\left(H\right)$ be symmetric and $H$ separable. Then
\begin{align*}
A & =\int_{\sigma\left(A\right)}\lambda\dd E_{\lambda}
\end{align*}
gave the decomposition:
\begin{align*}
\sigma\left(A\right) & =\sigma_{\text{disc}}\left(A\right)\dot{\cup}\sigma_{\text{ess}}\left(A\right)
\end{align*}
The spectral theorem in its multiplicative form gives another decomposition
of the spectrum.\\
There exists a operator
\begin{align*}
\mathcal{U}:H & \to L^{2}\left(\Omega,\dd\mu\right)
\end{align*}
with $\mathcal{U}A\mathcal{U}^{-1}$ is the operator of multiplication
by $g\in L^{\infty}\left(\Omega,\dd\mu\right)$ and $\dd\mu$ is a
positive finite Borel measure on $\Omega=\sigma\left(A\right)\times J$.
Since the spectrum is compact, it holds $\sigma\left(A\right)\subseteq\left[a,b\right]\subseteq\mathbb{R}$.

On $\Omega$ we also have the Lebesgue measure $\dd x$. According
to the Raden-Nikodym theorem (that we use without proof), $\dd\mu$
can be decomposed as:
\begin{align*}
\dd\mu & =\dd\mu_{\text{pp}}+\dd\mu_{\text{ac}}+\dd\mu_{\text{sing}}
\end{align*}
$\dd\mu_{\text{pp}}$ is the \emph{pure point}, $\dd\mu_{\text{ac}}$
the \emph{absolutely continuous} and $\dd\mu_{\text{sing}}$ the \emph{singular}
measure. It holds
\begin{align*}
\dd\mu_{\text{ac}} & =f\left(x\right)\dd x
\end{align*}
for a $f\in L^{2}\left(\Omega,\dd x\right)$. $\dd\mu_{\text{pp}}$
is a weighted counting measure, i.e. there is a countable set $K$
and $c_{j}\in\mathbb{R}_{>0}$ for $j\in K$ with:
\begin{align*}
\dd\mu_{\text{pp}}\left(\Omega\right) & =\sum_{j\in K}c_{j}\delta_{x_{j}}\\
\sum_{j\in K}c_{j} & <\infty
\end{align*}
This gives rise to a decomposition of the Hilbert spaces.
\begin{align*}
L^{2}\left(\Omega,\dd\mu\right) & =L^{2}\left(\Omega,\dd\mu_{\text{pp}}\right)\oplus L^{2}\left(\Omega,\dd\mu_{\text{ac}}\right)\oplus L^{2}\left(\Omega,\dd\mu_{\text{sing}}\right)
\end{align*}
Applying $\mathcal{U}^{-1}$ gives the corresponding decomposition:
\begin{align*}
H & =H_{\text{pp}}+H_{\text{ac}}+H_{\text{sing}}
\end{align*}
\begin{align*}
A\big|_{H_{\text{pp}}}:H_{\text{pp}} & \to H_{\text{pp}} & \sigma_{\text{pp}}\left(A\right) & :=\sigma\left(A|_{H_{\text{pp}}}\right)\\
A\big|_{H_{\text{ac}}}:H_{\text{ac}} & \to H_{\text{ac}} & \sigma_{\text{ac}}\left(A\right) & :=\sigma\left(A|_{H_{\text{ac}}}\right)\\
A\big|_{H_{\text{sing}}}:H_{\text{sing}} & \to H_{\text{sing}} & \sigma_{\text{sing}}\left(A\right) & :=\sigma\left(A|_{H_{\text{sing}}}\right)
\end{align*}



\chapter{The Spectral Theorem for Unbounded Self-Adjoint Operators}

Let $A:\mathcal{D}\left(A\right)\to H$ be a densely defined linear
operator with domain of definition $\mathcal{D}\left(A\right)\stackrel{\text{dense}}{\subseteq}H$.

\emph{Recall}:
\begin{itemize}
\item $A$ is \emph{symmetric} if $\left\langle u,Av\right\rangle =\left\langle Au,v\right\rangle $
for all $u,v\in\mathcal{D}\left(A\right)$. (also called \emph{formally
self-adjoint})
\item $A$ is \emph{self-adjoint} if $A^{*}=A$, or equivalently:
\begin{align*}
\left(\fall_{u\in\mathcal{D}\left(A\right)}:\left\langle Au,v\right\rangle =\left\langle u,w\right\rangle \right) &  & \Rightarrow\qquad & \left(\left(w\in\mathcal{D}\left(A\right)\right)\vphantom{\big|}\wedge\vphantom{\big|}\left(Av=w\right)\right)
\end{align*}

\end{itemize}

\section{Theorem \textmd{(The basic criterion for self-adjointness)\label{sec:Thm-The-basic-criterion-self-for-adjointness}}}

Let $A$ be a symmetric operator with dense domain of definition $\mathcal{D}\left(A\right)$.
Then the following statements are equivalent.
\begin{enumerate}[label=\roman*)]
\item $A$ is self-adjoint.
\item $A$ is closed and $\ker\left(A^{*}\pm\ii\right)=\left\{ 0\right\} $
(for $+$ and $-$).
\item $\text{im}\left(A\pm\ii\right)=H$ (for $+$ and $-$)
\end{enumerate}

\subsubsection*{Proof}

„i) $\Rightarrow$ ii)“: Let $A$ be self-adjoint, i.e. $A=A^{*}$.
Since $A^{*}$ is always closed, it follows that $A$ is closed. Let
$\varphi\in\mathcal{D}\left(A^{*}\right)=\mathcal{D}\left(A\right)$
be in the kernel of $A^{*}\pm\ii$, i.e. $\mp\ii\varphi=A^{*}\varphi=A\varphi$.
Then follows:
\begin{align*}
\mp\ii\left\langle \varphi,\varphi\right\rangle  & =\left\langle \varphi,A\varphi\right\rangle =\left\langle A\varphi,\varphi\right\rangle =\pm\ii\left\langle \varphi,\varphi\right\rangle 
\end{align*}
This shows $\norm{\varphi}=0$ and thus $\varphi=0$.

„ii) $\Rightarrow$ iii)“: Let $A$ be closed and $\ker\left(A\pm\ii\right)=\left\{ 0\right\} $
be trivial.
\begin{itemize}
\item $\text{im}\left(A\pm\ii\right)$ is dense in $H$. Assume conversely
that there exists a $u\not=0$ in $\left(\text{im}\left(A\pm\ii\right)\right)^{\perp}$.
Then follows for all $v\in\mathcal{D}\left(A\right)$:
\begin{align*}
0 & =\left\langle \left(A\pm\ii\right)v,u\right\rangle 
\end{align*}
So $u\in\mathcal{D}\left(\left(A\pm\ii\right)^{*}\right)=\mathcal{D}\left(A^{*}\right)$
and $\left(A^{*}\mp\ii\right)u=0$ in contradiction to $\ker\left(A^{*}\mp\ii\right)=\left\{ 0\right\} $.
\item $\text{im}\left(A\pm\ii\right)$ is closed in $H$. Let $\psi\in\overline{\text{im}\left(A\pm\ii\right)}$
lie in the closure of the image. Then there exist $\varphi_{n}\in\mathcal{D}\left(A\right)$
such that:
\begin{align*}
\left(A\pm\ii\right)\varphi_{n} & \to\psi
\end{align*}
For any $\varphi\in\mathcal{D}\left(A\right)$ holds:
\begin{align*}
\norm{\left(A\pm\ii\right)\varphi}^{2} & =\left\langle \left(A\pm\ii\right)\varphi,\left(A\pm\ii\right)\varphi\right\rangle =\norm{A\varphi}^{2}+\norm{\varphi}^{2}\pm\ii\underbrace{\left(\left\langle A\varphi,\varphi\right\rangle -\left\langle \varphi,A\varphi\right\rangle \right)}_{=0\text{, since \ensuremath{A}is symmetric}}
\end{align*}
Especially for $\varphi=\varphi_{n}-\varphi_{m}$ holds:
\begin{align*}
\underbrace{\norm{A\left(\varphi_{n}-\varphi_{m}\right)}^{2}}_{\ge0}+\underbrace{\norm{\varphi_{n}-\varphi_{m}}^{2}}_{\ge0} & =\norm{\left(A\pm\ii\right)\left(\varphi_{n}-\varphi_{m}\right)}^{2}\xrightarrow[\left(A\pm\ii\right)\varphi_{n}\to\psi]{n,m\to\infty}0
\end{align*}
It follows:
\begin{align*}
\norm{\varphi_{n}-\varphi_{m}} & \to0 & \varphi_{n} & \to\varphi\\
\norm{A\varphi_{n}-A\varphi_{m}} & \to0 & A\varphi_{n} & \to\psi\mp\ii\varphi
\end{align*}
Thus $\left(\varphi_{n},A\varphi_{n}\right)$ is a Cauchy sequence
in $\text{graph}\left(A\right)\subseteq H\times H$.\\
Since $A$ is closed, which means by definition that $\text{graph}\left(A\right)$
is closed in $H\times H$, the limit point $\left(\varphi,\psi\mp\ii\varphi\right)$
is in $\text{graph}\left(A\right)$. Then follows $\varphi\in\mathcal{D}\left(A\right)$
and $A\varphi=\psi\mp\ii\varphi$, i.e. $\psi\in\text{im}\left(A\pm\ii\right)$.
\end{itemize}
„iii) $\Rightarrow$ i)“: Assume that $\text{im}\left(A\pm\ii\right)=H$.
Consider $\varphi\in\mathcal{D}\left(A^{*}\right)$. Since $\text{im}\left(A\pm\ii\right)=H$,
there is a $u\in\mathcal{D}\left(A\right)$ such that $\left(A\pm\ii\right)u=\left(A^{*}\pm\ii\right)\varphi$.
From $\mathcal{D}\left(A\right)\subseteq\mathcal{D}\left(A^{*}\right)$
(always true for symmetric operators) follows $\varphi-u\in\mathcal{D}\left(A^{*}\right)$
and:
\begin{align*}
\left(A^{*}\pm\ii\right)\left(\varphi-u\right) & =0
\end{align*}
Consider $w\in\ker\left(A^{*}\pm\ii\right)\setminus\left\{ 0\right\} $.
Then holds for all $\xi\in\mathcal{D}\left(A\right)$:
\begin{align*}
\left\langle \left(A^{*}\pm\ii\right)w,\xi\right\rangle  & =0\\
\left\langle w,\left(A\mp\ii\right)\xi\right\rangle  & =0
\end{align*}
Using assumption $\text{im}\left(A\mp\ii\right)=H$ one can choose
$\xi$ such that $\left(A\mp\ii\right)\xi=w$, which means $\left\langle w,w\right\rangle =0$,
i.e. $w=0$. Thus holds:
\begin{align*}
\ker\left(A^{*}\pm\ii\right) & =\left\{ 0\right\} 
\end{align*}
This gives $\varphi=u\in\mathcal{D}\left(A\right)$, which implies
$\varphi\in\mathcal{D}\left(A^{*}\right)$ and thus $A$ is self-adjoint.\qqed


\section{Unbounded Multiplication Operators\label{sec:Unbounded-Multiplication-Operators}}

Let $\left(\Omega,\mu\right)$ be a measure space with a $\sigma$-finite
measure $\mu$. (For example, $\Omega$ is a $\sigma$-compact topological
space and $\mu$ a positive Borel measure on $\Omega$.)\\
$H=L^{2}\left(\Omega,\dd\mu\right)$ is our Hilbert space. Let $g:\Omega\to\mathbb{R}$
be measurable (and finite almost everywhere). We want to introduce
$T_{g}$:
\begin{align*}
T_{g}f & =g\cdot f
\end{align*}
For $g\in L^{\infty}\left(\Omega,\dd\mu\right)$, $T_{g}$ is a bounded
symmetric operator. Suppose $g$ is unbounded. What is $\mathcal{D}\left(T_{g}\right)$?
How to choose $\mathcal{D}\left(T_{g}\right)$ such that $T_{g}$
becomes self-adjoint?


\subsection*{Lemma\label{sub:Lem-Unbounded_Multiplication_Operators}}

Define:
\begin{align*}
\mathcal{D}\left(T_{g}\right) & =\left\{ f\in L^{2}\left(\Omega,\dd\mu\right)\big|g\cdot f\in L^{2}\left(\Omega,\dd\mu\right)\right\} \subseteq L^{2}\left(\Omega,\dd\mu\right)
\end{align*}
Then $T_{g}:\mathcal{D}\left(T_{g}\right)\to L^{2}\left(\Omega,\dd\mu\right)$
is self-adjoint and $\sigma_{\text{ess}}\left(T_{g}\right)=g\left(\Omega\right)$.

%DATE: Fr 1.2.13


\subsubsection*{Proof}

$T_{g}$ is symmetric:
\begin{align*}
\left\langle T_{g}f,h\right\rangle  & =\int_{\Omega}\overline{\left(T_{g}f\right)}h\dd\mu=\int_{\Omega}\overline{g\left(x\right)\cdot f\left(x\right)}h\left(x\right)\dd\mu\left(x\right)=\int_{\Omega}g\left(x\right)\cdot\overline{f}\left(x\right)h\left(x\right)\dd\mu\left(x\right)=\\
 & =\int_{\Omega}\overline{f\left(x\right)}g\left(x\right)h\left(x\right)\dd\mu\left(x\right)=\left\langle f,T_{g}h\right\rangle 
\end{align*}
$T_{g}$ is self-adjoint: For $\psi\in\mathcal{D}\left(T_{g}^{*}\right)$
we show $\psi\in\mathcal{D}\left(T_{g}\right)$. This is equivalent
to the existence of a $v\in H$ such that for all $u\in\mathcal{D}\left(T_{g}\right)$
holds
\begin{align*}
\left\langle T_{g}u,\psi\right\rangle  & =\left\langle u,v\right\rangle 
\end{align*}
and we have $v=T_{g}^{*}\psi$. Now we write
\begin{align*}
\Omega & =\bigcup_{N}K_{N}
\end{align*}
with $K_{N}\subseteq K_{N+1}$ having finite measure and set:
\begin{align*}
\chi_{N}\left(x\right) & =\begin{cases}
1 & \text{if }\abs{g\left(x\right)}\le N\text{ and }x\in K_{N}\\
0 & \text{otherwise}
\end{cases}
\end{align*}
So $\chi_{N}\left(x\right)\nearrow1$ converges monotonously and it
holds:
\begin{align*}
\norm{T_{g}^{*}\psi}_{L^{2}}^{2} & =\int_{\Omega}\abs{\left(T_{g}^{*}\psi\right)\left(x\right)}^{2}\dd\mu\left(x\right)\sr ={\text{monotone}}{\text{convergence}}\lim_{N\to\infty}\int_{\Omega}\chi_{N}\left(x\right)\abs{\left(T_{g}^{*}\psi\right)\left(x\right)}^{2}\dd\mu\left(x\right)=\\
 & =\lim_{N\to\infty}\norm{\chi_{N}T_{g}^{*}\psi}^{2}
\end{align*}
\begin{align*}
\Rightarrow\qquad\norm{T_{g}^{*}\psi}_{L^{2}} & =\lim_{N\to\infty}\norm{\chi_{N}T_{g}^{*}\psi}_{L^{2}}=\lim_{N\to\infty}\sup_{\norm{\varphi}=1}\abs{\left\langle \varphi,\chi_{N}T_{g}^{*}\psi\right\rangle }=\\
 & \stackrel{\star}{=}\lim_{N\to\infty}\sup_{\norm{\varphi}=1}\abs{\left\langle T_{g}\chi_{N}\varphi,\psi\right\rangle }
\end{align*}
In $\star$ we used that $\chi_{N}\varphi$ is in $\mathcal{D}\left(T_{g}\right)$.
This is really the case, since for $\chi_{N}\varphi\in L^{2}\left(\Omega,\dd\mu\right)$
holds:
\begin{align*}
T_{g}\chi_{N}\varphi=\underbrace{g\cdot\chi_{N}}_{\text{is bounded}}\varphi & =T_{g\cdot\chi_{N}}\varphi\in L^{2}\left(\Omega,\dd\mu\right)
\end{align*}
Since the function $g\cdot\chi_{N}$ is bounded, the multiplication
operator $T_{g\cdot\chi_{N}}$ is bounded and thus follows:
\begin{align*}
\infty>\norm{T_{g}^{*}\psi} & =\lim_{N\to\infty}\sup_{\norm{\varphi}=1}\abs{\left\langle \varphi,\chi_{N}\cdot g\cdot\psi\right\rangle }=\lim_{N\to\infty}\norm{\chi_{N}\cdot g\cdot\psi}=\\
 & =\lim_{N\to\infty}\int_{\Omega}\chi_{N}\left(x\right)\abs{g\psi}^{2}\left(x\right)\dd\mu\left(x\right)\sr ={\text{monotone}}{\text{convergence}}\int_{\Omega}\abs{\left(g\psi\right)\left(x\right)}^{2}\dd\mu\left(x\right)
\end{align*}
So we have $g\psi\in L^{2}\left(\Omega,\dd\mu\right)$ and thus $\psi\in\mathcal{D}\left(T_{g}\right)$
holds by definition of $\mathcal{D}\left(T_{g}\right)$.

We omit the proof that $\sigma_{\text{ess}}\left(T_{g}\right)=g\left(\Omega\right)$.\qqed


\section{Theorem \textmd{(The Spectral Theorem in its Multiplicative Form)}}

Let $A:\mathcal{D}\left(H\right)\stackrel{\text{dense}}{\subseteq}H\to H$
be a self-adjoint operator and $H$ separable. Then there is a finite
measure space $\left(M,\mu\right)$, a unitary operator $\mathcal{U}:H\to L^{2}\left(M,\dd\mu\right)$
and a measurable function $f:M\to\mathbb{R}$ such that holds:
\begin{enumerate}[label=\alph*)]
\item $\psi\in\mathcal{D}\left(A\right)\quad\Leftrightarrow\quad f\cdot\mathcal{U}\psi\in L^{2}\left(M,\dd\mu\right)$
\item $ $$\varphi\in\mathcal{U}\left(\mathcal{D}\left(A\right)\right)$
implies $\mathcal{U}A\mathcal{U}^{-1}\varphi=f\cdot\varphi=T_{f}\cdot\varphi$.
\end{enumerate}
Thus $A$ is unitarily equivalent to the multiplication $T_{f}$ on
$L^{2}\left(M,\dd\mu\right)$ and as chosen in \ref{sub:Lem-Unbounded_Multiplication_Operators}:
\begin{align*}
\mathcal{U}\left(\mathcal{D}\left(A\right)\right) & =\mathcal{D}\left(T_{f}\right)=\left\{ \phi\in L^{2}\big|f\cdot\phi\in L^{2}\left(M,\dd\mu\right)\right\} 
\end{align*}



\subsubsection*{Proof}

According to our basic criterion \ref{sec:Thm-The-basic-criterion-self-for-adjointness},
the mapping
\begin{align*}
A\pm\ii:\mathcal{D}\left(A\right) & \to H
\end{align*}
is surjective (by property iii)) and injective (by property ii)),
noting:
\begin{align*}
\left\{ 0\right\} =\ker\left(A^{*}\pm\ii\right) & =\ker\left(A\pm\ii\right)
\end{align*}
So $A\pm\ii$ is bijective and thus the inverse $\left(A\pm\ii\right)^{-1}:H\to\mathcal{D}\left(A\right)\subseteq H$
exists.\\
The operators $\left(A\pm\ii\right)^{-1}$ are bounded, because for
all $u\in\mathcal{D}\left(A\right)$ holds (cf. proof of \ref{sec:Thm-The-basic-criterion-self-for-adjointness}):
\begin{align*}
\norm{\left(A+\ii\right)u}^{2} & =\norm{Au}^{2}+\norm u^{2}
\end{align*}
Thus for $v:=\left(A+\ii\right)u$ follows:
\begin{align*}
\norm{\left(A+\ii\right)^{-1}v} & \le\norm v\\
\opnorm{\left(A+\ii\right)^{-1}} & \le1
\end{align*}
The operators $\left(A\pm\ii\right)^{-1}$ are \emph{normal}: The
resolvent identity gives:
\begin{align*}
\left(A+\ii\right)^{-1}-\left(A-\ii\right)^{-1} & =-2\ii\cdot\left(A+\ii\right)^{-1}\cdot\left(A-\ii\right)^{-1}\\
\left(A-\ii\right)^{-1}-\left(A+\ii\right)^{-1} & =+2\ii\cdot\left(A-\ii\right)^{-1}\cdot\left(A+\ii\right)^{-1}
\end{align*}
Together this yields:
\begin{align*}
\left[\left(A+\ii\right)^{-1},\left(A-\ii\right)^{-1}\right] & =0
\end{align*}
Let us compute $\left(\left(A+\ii\right)^{-1}\right)^{*}$. For $u,v\in\mathcal{D}\left(A\right)$
holds:
\begin{align*}
\left\langle \left(A-\ii\right)u,v\right\rangle  & \stackrel{A\text{ symmetric}}{=}\left\langle u,\left(A+\ii\right)v\right\rangle \\
\Rotate{=}\qquad & \qquad\qquad\qquad\qquad\Rotate{=}\\
\big\langle\underbrace{\left(A-\ii\right)u}_{=\psi},\left(A+\ii\right)^{-1}\underbrace{\left(A+\ii\right)v}_{=\varphi}\big\rangle & =\big\langle\left(A-\ii\right)^{-1}\underbrace{\left(A-\ii\right)u}_{=\psi},\underbrace{\left(A+\ii\right)v}_{=\varphi}\big\rangle
\end{align*}
\begin{align*}
\left\langle \psi,\left(A+\ii\right)^{-1}\phi\right\rangle  & =\left\langle \left(A-\ii\right)^{-1}\psi,\phi\right\rangle 
\end{align*}
Since $\left(A-\ii\right)$ and $\left(A+\ii\right)$ are surjective,
this holds for all $\psi,\phi\in H$ and thus follows:
\begin{align*}
\left(\left(A+\ii\right)^{-1}\right)^{*} & =\left(A-\ii\right)^{-1}
\end{align*}
\begin{align*}
\Rightarrow\qquad\left[\left(A+\ii\right)^{-1},\left(\left(A+\ii\right)^{-1}\right)^{*}\right] & =0
\end{align*}
So $\left(A+\ii\right)^{-1}$ is normal and we can apply the spectral
theorem in its multiplicative form to the operator $\left(A+\ii\right)^{-1}$.
This gives:
\begin{align*}
\mathcal{U}:H & \to L^{2}\left(M,\dd\mu\right)
\end{align*}
$\mu$ is a bounded positive Borel measure on the $\sigma$-compact
topological space $M$.
\begin{align*}
M & =\sigma\left(\left(A+\ii\right)^{-1}\right)\times J
\end{align*}
And for $\varphi\in L^{2}\left(M,\dd\mu\right)$ holds
\begin{align*}
\left(\mathcal{U}\left(A+\ii\right)^{-1}\mathcal{U}^{-1}\right)\varphi & =g\cdot\varphi
\end{align*}
with a $g\in L^{\infty}\left(M,\dd\mu\right)$.\\
Moreover, since $\left(A+\ii\right)^{-1}$ is injective, the function
$g$ is non-zero almost everywhere: Assume conversely that there exists
a $\Omega\subseteq M$ with $\mu\left(\Omega\right)\not=0$ and $g\big|_{\Omega}=0$.
Then $\varphi:=\chi_{\Omega}$ is a non-zero vector in $L^{2}\left(M,\dd\mu\right)$
with $g\cdot\varphi\not=0$.
\begin{align*}
\norm{\varphi}^{2} & =\int_{M}\chi_{\Omega}^{2}\dd\mu=\mu\left(\Omega\right)>0
\end{align*}
Thus $\mathcal{U}^{-1}\varphi$ is a non-trivial vector in the kernel
of $\left(A+\ii\right)^{-1}$, which is a contradiction to the injectivity
of $A$.
\begin{enumerate}[label=\alph*)]
\item Set $f=\frac{1}{g}-\ii$. This function is measurable and finite
almost everywhere.\\
„$\Rightarrow$“: Since $\left(A+\ii\right)^{-1}:H\to\mathcal{D}\left(A\right)$
is bijective, a $\psi\in\mathcal{D}\left(A\right)$ can be written
uniquely as:
\begin{align*}
\psi & =\left(A+\ii\right)^{-1}\phi
\end{align*}
\begin{align*}
\Rightarrow\qquad\mathcal{U}\psi & =\mathcal{U}\left(A+\ii\right)^{-1}\phi=\underbrace{\mathcal{U}\left(A+\ii\right)^{-1}\mathcal{U}^{-1}}_{=T_{g}}\mathcal{U}\phi=g\mathcal{U}\phi\\
f\mathcal{U}\psi & =fg\mathcal{U}\phi=\underbrace{\left(1-\ii g\right)}_{\in L^{\infty}\left(M,\dd\mu\right)}\cdot\underbrace{\mathcal{U}\phi}_{\in L^{2}\left(M,\dd\mu\right)}\in L^{2}\left(M,\dd\mu\right)
\end{align*}
„$\Leftarrow$“: Assume $f\mathcal{U}\psi\in L^{2}\left(M,\dd\mu\right)$,
which implies $\left(f+\ii\right)\mathcal{U}\psi\in L^{2}\left(M,\dd\mu\right)$.
Now there exists a $\phi\in H$ such that holds:
\begin{align*}
\mathcal{U}\phi & =\left(f+\ii\right)\mathcal{U}\psi\qquad/\cdot g\\
g\mathcal{U}\phi & =g\left(f+\ii\right)\mathcal{U}\psi=\mathcal{U}\psi\\
\Rightarrow\qquad\psi & =\underbrace{\mathcal{U}^{-1}g\mathcal{U}}_{=\left(A+\ii\right)^{-1}}\phi=\left(A+\ii\right)^{-1}\phi
\end{align*}
Since $\left(A+\ii\right)^{-1}:H\to\mathcal{D}\left(A\right)$ is
bijective, $\psi\in\mathcal{D}\left(A\right)$ follows.
\item We need to show for all $\varphi\in\mathcal{U}\left(\mathcal{D}\left(A\right)\right)$:
\begin{align*}
\mathcal{U}A\mathcal{U}^{-1}\varphi & =f\varphi
\end{align*}
Write $\psi\in\mathcal{D}\left(A\right)$ as $\psi=\left(A+\ii\right)^{-1}\varphi$
to get just as in a) „$\Rightarrow$“:
\begin{align*}
\mathcal{U}\psi & =g\mathcal{U}\varphi\\
\mathcal{U}\varphi & =\frac{1}{g}\mathcal{U}\psi\\
\mathcal{U}\left(A+\ii\right)\psi & =\frac{1}{g}\mathcal{U}\psi\\
\mathcal{U}A\psi & =\frac{1}{g}\mathcal{U}\psi-\ii\mathcal{U}\psi=\left(\frac{1}{g}-\ii\right)\mathcal{U}\psi=f\mathcal{U}\psi\\
\mathcal{U}A\mathcal{U}^{-1}\chi & \stackrel{\chi=\mathcal{U}\psi}{=}f\cdot\chi
\end{align*}

\end{enumerate}
Finally we show that $f$ is real-valued. For all $\psi\in\mathcal{D}\left(A\right)$
holds, because $A$ is symmetric:
\begin{align*}
0 & =\text{Im}\left(\left\langle \psi,A\psi\right\rangle \right)=\text{Im}\left(\left\langle \psi,\mathcal{U}^{-1}f\mathcal{U}\psi\right\rangle \right)\stackrel{\mathcal{U}\text{ unitary}}{=}\text{Im}\left(\left\langle \mathcal{U}\psi,f\mathcal{U}\psi\right\rangle \right)=\\
 & =\int_{M}\text{Im}\left(f\left(x\right)\right)\cdot\abs{\left(\mathcal{U}\psi\right)\left(x\right)}^{2}\dd\mu\left(x\right)
\end{align*}
Since $\mathcal{U}\psi$ can be any $L^{2}$-function $\chi$ (just
choose $\psi=\mathcal{U}^{-1}\chi$), it follows that $\text{Im}\left(f\right)=0$
almost everywhere.\qqed


\subsubsection*{Connection to the Cayley transformation}

The operators
\begin{align*}
V & :=\left(A+\ii\right)\left(A-\ii\right)^{-1}\\
V^{*} & =\left(A+\ii\right)^{-1}\left(A-\ii\right)
\end{align*}
are unitary, because it holds:
\begin{align*}
V\cdot V^{*} & =\left(A+\ii\right)\left(A-\ii\right)^{-1}\left(A+\ii\right)^{-1}\left(A-\ii\right)=\\
 & =\left(A+\ii\right)\left(A+\ii\right)^{-1}\left(A-\ii\right)^{-1}\left(A-\ii\right)=\mathbbm{1}
\end{align*}
We worked here with $\left(A-\ii\right)^{-1}$.


\section{The unbounded Functional Calculus, Projection-valued Spectral measures}

\emph{Goal}: Suppose $E_{\lambda}$ is a spectral measure on $\mathbb{K}\in\left\{ \mathbb{R},\mathbb{C}\right\} $.
\begin{align*}
f\left(A\right) & =\int f\left(\lambda\right)\dd E_{\lambda}
\end{align*}
So far we had $f\in\mathcal{B}\left(\mathbb{K}\right)$. This gave
us a bounded linear operator. We want to calculate
\begin{align*}
f\left(A\right) & =\int f\left(\lambda\right)\dd E_{\lambda}
\end{align*}
for any Borel function $f$, possibly unbounded. Then $f\left(A\right)$
is a possibly unbounded operator. What is $\mathcal{D}\left(A\right)$
and what is $\mathcal{D}\left(A^{*}\right)$?
\begin{align*}
\mathcal{D}\left(A\right) & =\left\{ u\in H\bigg|\int_{\mathbb{K}}\abs{f\left(\lambda\right)}^{2}\dd\left\langle u,E_{\lambda}u\right\rangle <\infty\right\} 
\end{align*}
%DATE Do 7.2.13


\subsubsection*{Example}

\begin{align*}
\left(UAU^{-1}\right)f & =gf
\end{align*}
and $g:\Omega\to\mathbb{R}$ is measurable.
\begin{align*}
\mathcal{D}\left(A\right) & =\left\{ U^{-1}\varphi\big|\varphi\in L^{2}\left(\Omega,\dd\mu\right)\wedge gf\in L^{2}\left(\Omega,\dd\mu\right)\right\} =\\
 & =U^{-1}\mathcal{D}\left(UAU^{-1}\right)U
\end{align*}
The spectral calculus yields:
\begin{align*}
UA^{2}U^{-1} & =\left(UAU^{-1}\right)^{2}=g^{2}
\end{align*}
\begin{align*}
\Rightarrow\qquad\mathcal{D}\left(A^{2}\right) & =\left\{ U^{-1}\varphi\big|\varphi\in L^{2}\left(\Omega,\dd\mu\right)\wedge g^{2}f\in L^{2}\left(\Omega,\dd\mu\right)\right\} 
\end{align*}
So the domain of definition changes.


\subsection{Theorem \textmd{(The spectral theorem in functional calculus form)}}

Let $A:\mathcal{D}\left(A\right)\subseteq H\to H$ be self-adjoint.
Then there is a unique mapping
\begin{align*}
\Phi:\mathcal{B}\left(\mathbb{R}\right) & \to L\left(H\right)
\end{align*}
such that the following holds:
\begin{enumerate}[label=\roman*)]
\item $\Phi$ is an involutive algebra homomorphism.
\item $\norm{\Phi\left(f\right)}_{L\left(H\right)}\le\norm f_{\infty}$
\item Let $g_{n}\in\mathcal{B}\left(\mathbb{R}\right)$ be the elements
of a sequence such that $g_{n}\to g$ converges point-wise and $\abs{g_{n}\left(x\right)}\le\abs x$
holds. Then for every $\psi\in\mathcal{D}\left(A\right)$ converges:
\begin{align*}
\Phi\left(g_{n}\right)\psi & \to\Phi\left(g\right)\psi
\end{align*}

\item If $g_{n}\to g$ converges point-wise with $\abs{g_{n}\left(x\right)}<C$,
then holds for all $\psi\in H$ converges:
\begin{align*}
\Phi\left(g_{n}\right)\psi & \to\Phi\left(g\right)\psi
\end{align*}

\item For $A\psi=\lambda\psi$ follows $\Phi\left(f\right)\psi=f\left(\lambda\right)\psi$
\item For $h\ge0$ holds $\Phi\left(h\right)\ge0$.
\end{enumerate}

\subsubsection*{Proof}

After a unitary transformation with the operator $U$ from the spectral
theorem in its multiplicative form, we can assume $H=L^{2}\left(M,\dd\mu\right)$
and:
\begin{align*}
\mathcal{D}\left(A\right) & =\left\{ \varphi\in L^{2}\left(M,\dd\mu\right)\big|g\varphi\in L^{2}\left(M,\dd\mu\right)\right\} \\
A\varphi & =g\varphi\\
\left(\Phi\left(f\right)\varphi\right)\left(x\right) & =f\left(g\left(x\right)\right)\cdot\varphi\left(x\right)
\end{align*}
Since $f\left(g\right)\in L^{\infty}$ holds, define for any $\varphi\in L^{2}$:
\begin{align*}
\Phi\left(f\right)\varphi & :=f\left(g\right)\varphi\in L^{2}
\end{align*}
This defines an operator in $L\left(H\right)$.\\
The properties i) and ii) are obvious. iii) and iv) follow from dominated
convergence:
\begin{enumerate}
\item [iii)]It holds:
\begin{align*}
\Phi\left(f_{n}\right)\varphi & =f_{n}\left(g\right)\cdot\varphi\\
\Phi\left(f\right)\varphi & =f\left(g\right)\varphi\\
f_{n}\left(g\right) & \xrightarrow{\text{point-wise}}f\left(g\right)
\end{align*}
By assumption holds $\abs{f_{n}\left(g\right)}\le\abs g$ and by our
formula for $\mathcal{D}\left(A\right)$ follows for all $\varphi\in\mathcal{D}\left(A\right)$:
\begin{align*}
\abs{f_{n}\left(g\right)\varphi},\abs{f\left(g\right)\varphi} & \le\abs g\cdot\abs{\varphi}\in L^{2}
\end{align*}

\end{enumerate}
iv) follows similarly and v) and vi) are obvious.

\emph{Uniqueness of $\Phi$}: Let $K\subseteq\mathbb{R}$ be compact
and $\varphi\in L^{2}\left(K,\dd\mu\right)$. Then holds:
\begin{align*}
\Phi\left(g\cdot\chi_{K}\right)\varphi & =\underbrace{\Phi\left(g\right)}_{=A}\cdot\Phi\left(\chi_{K}\right)\varphi=A\Phi\left(\chi_{K}\right)\varphi
\end{align*}
On $K$ we can approximate $g$ using Stone-Weierstraß. Then choose
a sequence $K_{1}\subseteq K_{2}\subseteq\ldots$ of compact $K_{n}$
with $\bigcup_{n\in\mathbb{N}}K_{n}=\mathbb{R}$. Now take the limit
$n\to\infty$ and use property iii) to get $\Phi\left(g\right)\varphi=A\varphi$,
which shows the uniqueness of $\Phi$.\qqed

Now we write $\Phi\left(f\right)=:f\left(A\right)$. We can again
introduce the spectral measure:
\begin{align*}
E_{\Omega} & :=\Phi\left(\chi_{\Omega}\right)=\chi_{\Omega}\left(A\right)
\end{align*}
After a unitary transformation holds:
\begin{align*}
E_{\Omega}\varphi & =\chi_{\Omega}\left(g\right)\cdot\varphi
\end{align*}
This shows:
\begin{align*}
E_{\Omega}^{*} & =E_{\Omega}=E_{\Omega}^{2}\\
E_{U}\cdot E_{V} & =E_{U\cap V}
\end{align*}
\begin{align*}
\left\langle \varphi,E_{\Omega}\varphi\right\rangle  & =\int_{\mathbb{R}}\abs{\varphi}^{2}\chi_{\Omega}\left(g\right)\dd\mu\\
\left\langle \varphi,f\left(A\right)\varphi\right\rangle  & =\int_{\mathbb{R}}\abs{\varphi}^{2}f\left(g\right)\dd\mu=\int_{\mathbb{R}}f\dd\left\langle \varphi,E_{\lambda}\varphi\right\rangle 
\end{align*}



\subsection{Theorem}

There is a one-to-one correspondence between self-adjoint operators
and projection-valued spectral measures (not necessarily with compact
support) given by:
\begin{align*}
A & =\int_{\mathbb{R}}\lambda\dd E_{\lambda}\\
\mathcal{D}\left(A\right) & =\left\{ u\in H\bigg|\int_{\mathbb{R}}\lambda^{2}\dd\left\langle u,E_{\lambda}u\right\rangle <\infty\right\} 
\end{align*}
Moreover holds:
\begin{enumerate}[label=\roman*)]
\item $f\left(A\right)=\int_{\mathbb{R}}f\left(\lambda\right)\dd E_{\lambda}$
holds for all bounded Borel functions $f$.
\item If $f$ is an unbounded Borel function, we set:
\begin{align*}
\mathcal{D}_{f} & =\left\{ u\in H\bigg|\int_{\mathbb{R}}\abs f^{2}\dd\left\langle u,E_{\lambda}u\right\rangle <\infty\right\} 
\end{align*}
The set $\mathcal{D}_{f}\subseteq H$ is dense and
\begin{align*}
B & :=\int_{\mathbb{R}}f\dd E_{\lambda}:\mathcal{D}_{f}\to H
\end{align*}
is a densely defined closed operator with:
\begin{align*}
B^{*}=\int_{\mathbb{R}}\overline{f}\dd E_{\lambda}:\mathcal{D}_{f} & \to H
\end{align*}
(In particular, if $f$ is real-valued, the operator $B$ is again
self-adjoint.)
\end{enumerate}

\subsubsection*{Proof}
\begin{itemize}
\item $\mathcal{D}_{f}$ is dense in $H$: After a unitary transformation
we identify $H$ with $L^{2}\left(M,\dd\mu\right)$ and define:
\begin{align*}
\mathcal{D}_{f} & =\left\{ \varphi\in L^{2}\left(M,\dd\mu\right)\bigg|\int\abs{f\left(g\right)}^{2}\cdot\abs{\varphi}^{2}\dd\mu<\infty\right\} 
\end{align*}
(Recall $f\left(A\right)=f\left(g\right)$.) For $\psi\in L^{2}\left(M,\dd\mu\right)$,
we want to show $\psi\in\overline{\mathcal{D}_{f}}$. To this end
we set:
\begin{align*}
\psi_{n}\left(x\right) & :=\begin{cases}
\psi\left(x\right) & \text{if }\abs{f\left(g\left(x\right)\right)}\le n\\
0 & \text{otherwise}
\end{cases}
\end{align*}
Then holds:
\begin{align*}
\int\abs{f\left(g\right)}^{2}\cdot\abs{\psi_{n}}^{2}\dd\mu & \le n^{2}\int\abs{\psi_{n}}^{2}\dd\mu\le n^{2}\int\abs{\psi}^{2}\dd\mu<\infty
\end{align*}
Hence follows $\psi_{n}\in\mathcal{D}_{f}$. Obviously $\psi_{n}\to\psi$
converges point-wise and it holds:
\begin{align*}
\abs{\psi_{n}} & \le\abs{\psi}\in L^{2}\left(M,\dd\mu\right)
\end{align*}
Thus dominated convergence yields $\psi_{n}\to\psi$ in $L^{2}\left(M,\dd\mu\right)$.
\item Next, $B\varphi=f\left(g\right)\varphi$ with
\begin{align*}
\mathcal{D}\left(B\right) & =\left\{ \varphi\in L^{2}\big|f\left(g\right)\varphi\in L^{2}\right\} 
\end{align*}
is an unbounded multiplication operator. Its adjoint can be computed
as in section \ref{sec:Unbounded-Multiplication-Operators}.
\end{itemize}
\qqed


\chapter{Examples, Construction of Self-Adjoint extensions}

The (interesting) operator $H=-\Delta_{\mathbb{R}^{3}}+V\left(x\right)$
requires Sobolev spaces and Fourier transform. This is discussed in
the lecture partial differential equations I.

Here we only consider more simple, one-dimensional examples.


\section{Example}

Consider $A=\ii\frac{\dd}{\dd x}$ on $H=L^{2}\left(\mathbb{R},\dd x\right)$
with domain of definition:
\begin{align*}
\mathcal{D}\left(A\right) & =C_{0}^{\infty}\left(\mathbb{R}\right)
\end{align*}

\begin{itemize}
\item $A$ is symmetric: For $\psi,\phi\in C_{0}^{\infty}\left(\mathbb{R}\right)$
holds:
\begin{align*}
\left\langle \psi,A\phi\right\rangle  & =\int_{\mathbb{R}}\overline{\psi\left(x\right)}\ii\left(\frac{\dd}{\dd x}\phi\left(x\right)\right)\dd x=\\
 & \sr ={\text{integration}}{\text{by parts}}\underbrace{\overline{\psi\left(x\right)}\cdot\ii\phi\left(x\right)\big|_{-\infty}^{\infty}}_{=0,\ \text{(compact support)}}\int_{\mathbb{R}}\left(-\ii\right)\left(\frac{\dd}{\dd x}\overline{\psi\left(x\right)}\right)\phi\left(x\right)\dd x=\\
 & =\int_{\mathbb{R}}\overline{\left(\ii\frac{\dd}{\dd x}\psi\left(x\right)\right)}\phi\left(x\right)\dd x=\left\langle A\psi,\phi\right\rangle 
\end{align*}

\item $A$ is \emph{not} self-adjoint: If $A$ were self-adjoint, the following
computation would hold:
\begin{align*}
\fall_{u\in\mathcal{D}\left(A\right)}:\left\langle Au,v\right\rangle  & =\left\langle u,w\right\rangle \quad\Rightarrow\quad\left(v\in\mathcal{D}\left(A\right)\right)\wedge\left(Av=w\right)
\end{align*}
Any $v\in C_{0}^{1}\left(\mathbb{R}\right)\setminus C_{0}^{\infty}\left(\mathbb{R}\right)$
is a counter example.\\
We could even satisfy the condition on the left by choosing $v\in C^{1}\left(\mathbb{R}\right)$.
(We need no decay assumption, since it suffices that one function
has compact support). Thus follows:
\begin{align*}
\mathcal{D}\left(A^{*}\right) & \subseteq C^{1}\left(\mathbb{R}\right)
\end{align*}



\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
  \draw plot[smooth cycle,tension=.7] coordinates{(0,-1) (1,-0.7) (2,0) (1,0.8) (0,1) (-0.5,1.3) (-1,0)};
  \node at (0,0) {$\mathcal{D}(A)$};
  \draw plot[smooth cycle,tension=.7] coordinates{(0,-1.5) (2,-1) (3,0) (2,2) (0,3) (-1,4) (-3,0)};
  \node at (-0.8,3) {$\mathcal{D}(A^*)$};
  \draw[red] plot[smooth cycle,tension=.7] coordinates{(0,-1.3) (1,-1.1) (2.7,0) (1.2,1.6) (0,1.8) (-2,0)};
  \node[red] at (1,1.2) {$\mathcal{D'}(A)$};
  \draw[blue] plot[smooth cycle,tension=.7] coordinates{(0,-1.4) (1.5,-1) (2.8,0) (1.5,1.7) (0,2.2) (-1,2.5) (-2.5,0)};
  \node[blue] at (-0.75,2) {$\mathcal{D'}(A^*)$};
\end{tikzpicture}\caption{The large $\mathcal{D}'\left(A\right)\supseteq\mathcal{D}\left(A\right)$,
the smaller is $\mathcal{D}'\left(A^{*}\right)\subseteq\mathcal{D}\left(A^{*}\right)$.}
\end{figure}


\item $A:\mathcal{D}\left(A\right)\to H$ is essentially self-adjoint: This
means that $\overline{A}$ with $\text{graph}\left(\overline{A}\right):=\overline{\text{graph}\left(A\right)}$
is self-adjoint.\\
According to the basic criterion for self-adjointness (Theorem \ref{sec:Thm-The-basic-criterion-self-for-adjointness}),
we know:
\begin{align*}
A\text{ self-adjoint} & \quad\Leftrightarrow\quad\text{im}\left(A\pm\ii\right)=H
\end{align*}
Therefore, for essential self-adjointness it suffices to show that
$\left(A\pm\ii\right)\left(C_{0}^{\infty}\left(\mathbb{R}\right)\right)\subseteq H=L^{2}$
is dense.

\begin{description}
\item [{Claim:}] For all $v\in H$ there exists a $u\in H$ such that $\left(u,v\right)\in\overline{\text{graph}\left(A\pm\ii\right)}$.\\
(In other words, $\overline{A}\pm\ii$ is surjective.)
\item [{Proof:}] Since $\left(A\pm\ii\right)\left(C_{0}^{\infty}\right)\subseteq H$
is dense, there exists a sequence of $u_{n}\in C_{0}^{\infty}$ such
that with $w_{n}:=Au_{n}$ converges:
\begin{align*}
\left(A\pm\ii\right)u_{n} & =w_{n}\pm\ii u_{n}\to v
\end{align*}
The estimates from the proof of the basic criterion imply:
\begin{align*}
w_{n}=Au_{n} & \to w & u_{n} & \to u
\end{align*}
This yields that $\left(u_{n},w_{n}\right)\to\left(u,w\right)$ converges.
From $\left(u_{n},w_{n}\right)\in\text{graph}\left(A\right)$ follows
$\left(u,w\right)\in\overline{\text{graph}\left(A\right)}$.\qqed[Claim]
\item [{Claim:}] $\left(A\pm\ii\right)\left(C_{0}^{\infty}\left(\mathbb{R}\right)\right)$
is dense in $L^{2}$.
\item [{Proof:}] The vectors in the image of $A\pm\ii$ are of the form:
\begin{align*}
\ii\frac{\dd}{\dd x}u\pm\ii u & =:v
\end{align*}
From $u\in C_{0}^{\infty}$ follows $v\in C_{0}^{\infty}$. Multiply
by $e^{\mp x}$ and integrate by parts to get:
\begin{align*}
\int_{-\infty}^{\infty}e^{\mp x}v\left(x\right)\dd x & =\ii\int_{-\infty}^{\infty}e^{\mp x}\left(\left(\frac{\dd}{\dd x}\pm1\right)u\left(x\right)\right)\dd x=\\
 & \sr ={\text{integrate}}{\text{by parts}}-\ii\int_{-\infty}^{\infty}u\left(x\right)\left(\left(\frac{\dd}{\dd x}\pm1\right)e^{\mp x}\right)\dd x=\\
 & =-\ii\int_{-\infty}^{\infty}u\left(x\right)\underbrace{\left(\mp e^{\mp x}\pm e^{\mp x}\right)}_{=0}\dd x=0
\end{align*}
Thus the functions in the image of $A\pm\ii$ satisfy the condition:
\begin{align*}
\int_{-\infty}^{\infty}e^{\mp x}v\left(x\right)\dd x & =0
\end{align*}
Conversely, if a function $v\left(x\right)$ satisfies this condition
for $+$ and $-$, then
\begin{align*}
u\left(x\right) & :=\int_{-\infty}^{x}e^{\mp t}v\left(t\right)\dd t
\end{align*}
is in $C_{0}^{\infty}\left(\mathbb{R}\right)$ and $\left(A\pm\ii\right)u=v$.\\
Now we need to show:
\begin{align*}
\overline{\left\{ v\in C_{0}^{\infty}\left(\mathbb{R}\right)\bigg|\int e^{\pm x}v\left(x\right)\dd x=0\right\} } & =H
\end{align*}
Since $C_{0}^{\infty}\left(\mathbb{R}\right)$ is dense in $H$, we
only need to prove that $\psi\in C_{0}^{\infty}\left(\mathbb{R}\right)$
is an element of the left set. We look for $v_{n}\in C_{0}^{\infty}\left(\mathbb{R}\right)$
with
\begin{align*}
\int e^{\pm x}v_{n}\left(x\right)\dd x & =0
\end{align*}
such that $v_{n}\to\psi$ converges in $L^{2}$.\\
Choose $\eta\in C_{0}^{\infty}\left(\left[0,1\right]\right)$ and
use the ansatz:
\begin{align*}
v_{n} & =\psi+c_{+}\eta\left(x-L\right)+c_{-}\eta\left(x+L\right)
\end{align*}
\begin{figure}[H]
\noindent \centering{}\begin{tikzpicture}
 \begin{axis}[width=17cm, height = 10cm, axis x line=middle, axis y line=middle,
		xtick={0}, ytick={0}, xlabel=$q$,
        extra x ticks={-2,-1.5,1.5,2}, extra x tick labels={$-L$, $-L+1$, $L$, $L+1$},
		xmin=-2.5, xmax=2.5, ymin=-0.2, ymax=1.3, samples=300]
  \addplot[red, mark=none, domain=-1.2:1.2] {0.6*(1 + 5*x^2 - x^4+ 2*x^3)*exp(-4*(x)^4)};
  \addlegendentry{$v_n $}
  \addplot[thick, dashed, mark=none, domain=-1.2:1.2] {0.6*(1 + 5*x^2 - x^4+ 2*x^3)*exp(-4*(x)^4)};
  \addlegendentry{$\psi $}
  \addplot[red, mark=none, domain=1.5:2] {((x-1.75)^2-0.0625) * exp(-1/(10*(2.01-x))^2-1/(10*(x-1.49))^2)};
  \node at (axis cs: 1.75,0.15) {$c_+ \eta (x-L)$};
  \addplot[red, mark=none, domain=-2:-1.5] {-1.7*((x+1.75)^2-0.0625) * exp(-1/(10*(2.01+x))^2-1/(10*(-x-1.49))^2)};
  \node at (axis cs: -1.75,0.15) {$c_- \eta (x+L)$};
 \end{axis}
\end{tikzpicture} \caption{Approximation of $\psi$ with the $v_{n}$}
\end{figure}
Then holds:
\begin{align*}
0 & \stackrel{!}{=}\int_{-\infty}^{\infty}e^{\pm x}v_{n}\left(x\right)\dd x=\\
 & =\int_{-\infty}^{\infty}\psi\left(x\right)\dd x+c_{+}\underbrace{\int_{-\infty}^{\infty}e^{\pm x}\eta\left(x-L\right)\dd x}_{\sim e^{\pm L}}+c_{-}\underbrace{\int_{-\infty}^{\infty}e^{\pm x}\eta\left(x+L\right)\dd x}_{\sim e^{\mp L}}
\end{align*}
We have two conditions and two free parameters. One sees that $c_{+},c_{-}$
are proportional to $e^{-L}$. Thus $v_{n}\to\psi$ converges in $L^{2}$.\qqed[Claim]
\end{description}
\end{itemize}
Thus $\overline{A}$ with $\mathcal{D}\left(\overline{A}\right)$
(which can be described in detail) is self-adjoint.
\begin{align*}
\overline{A} & =\int_{-\infty}^{\infty}\lambda\dd E_{\lambda} &  & \text{spectral theorem}
\end{align*}



\section{Example}

On the Hilbert space $H=L^{2}\left(\left[0,1\right],\dd x\right)$
consider the operator $A:=\frac{\dd}{\dd x}$ with $\mathcal{D}\left(A\right)=C_{0}^{\infty}\left(\left(0,1\right)\right)$.
\begin{enumerate}[label=\alph*)]
\item $A$ is \emph{not} essentially self-adjoint. Just as in the previous
example, $A$ being essentially self-adjoint is equivalent to
\begin{align*}
\left(A\pm\ii\right)\left(C_{0}^{\infty}\left(\left(0,1\right)\right)\right) & \subseteq H
\end{align*}
being dense, or equivalently
\begin{align*}
M & :=\left\{ v\in C_{0}^{\infty}\left(\left(0,1\right)\right)\bigg|0=\int_{0}^{1}e^{\pm x}v\left(x\right)\dd x\right\} \subseteq H
\end{align*}
being dense. For $\psi\left(x\right)=e\left(x\right)\in H$ holds
for all $v\in M$:
\begin{align*}
\left\langle \psi,v\right\rangle  & =\int_{0}^{1}\psi\left(x\right)v\left(x\right)\dd x=\int_{0}^{1}e^{x}v\left(x\right)\dd x=0
\end{align*}
Therefore holds $0\not=\psi\in M^{\perp}$ and $M$ is \emph{not}
dense in $H$.
\item For $f\in C_{0}^{\infty}\left(\left[0,1\right]\right)$ and $n\in\mathbb{Z}$
define:
\begin{align*}
c_{n} & :=\int_{0}^{1}f\left(x\right)e^{2\pi\ii nx}\dd x
\end{align*}
This gives rise to a unitary transformation (Plancherel theorem):
\begin{align*}
U:L^{2}\left(\left[0,1\right]\right) & \to\ell_{2}\\
f & \mapsto\left(c_{n}\right)_{n\in\mathbb{Z}}
\end{align*}
\begin{align*}
\int_{0}^{1}\abs f^{2}\dd x & =\sum_{n\in\mathbb{Z}}\abs{c_{n}}^{2}
\end{align*}
\begin{align*}
\hat{A}\left(c_{n}\right) & =\left(U\ii\frac{\dd}{\dd x}U^{-1}\right)\left(c_{n}\right)=\left(-2\pi nc_{n}\right)_{n}
\end{align*}
$\hat{A}$ is a multiplication operator with:
\begin{align*}
\mathcal{D}\left(\hat{A}\right) & =\left\{ \left(c_{n}\right)_{n}\in\ell^{2}\big|\left(nc_{n}\right)_{n}\in\ell^{2}\right\} \subseteq\ell^{2}
\end{align*}
Then
\begin{align*}
\hat{A}:\mathcal{D}\left(\hat{A}\right) & \to\ell^{2}
\end{align*}
is self-adjoint. Thus
\begin{align*}
A:\mathcal{D}\left(A\right):=U^{-1}\mathcal{D}\left(\hat{A}\right) & \to L^{2}
\end{align*}
is self-adjoint.
\end{enumerate}

\section{Example\label{sec:Example-Friedrich-Kato}}

Consider $H=L^{2}\left(\mathbb{R},\dd x\right)$, $A=\ii\frac{\dd}{\dd x}$
and $T=T_{g}$ with a real valued $g$.
\begin{align*}
\left(A+T\right)\psi\left(x\right) & =\ii\frac{\dd}{\dd x}\psi\left(x\right)+g\left(x\right)\psi\left(x\right)
\end{align*}
How to choose $\mathcal{D}\left(A+T\right)$ in order to make the
operator self-adjoint?

There are two solutions:
\begin{itemize}
\item Friedrichs extension (by K. O. Friedrichs) for semi-bounded operators.
\item Katos's method
\end{itemize}

\section{Theorem \textmd{(Kato-Rellich)}}

Let $A:\mathcal{D}\left(A\right)\to H$ be self-adjoint and $T$ symmetric
with $\mathcal{D}\left(T\right)\supseteq\mathcal{D}\left(A\right)$.
Moreover, assume that there are constants $a,b\in\mathbb{R}_{\ge0}$
with $b<1$ such that for all $u\in\mathcal{D}\left(A\right)$ holds:
\begin{align}
\norm{Tu}^{2} & \le a^{2}\norm u^{2}+b^{2}\norm{Au}^{2}\label{eq:Tu-inequality}
\end{align}
Then $A+T$ with
\begin{align*}
\mathcal{D}\left(A+T\right) & =\mathcal{D}\left(A\right)
\end{align*}
is self-adjoint.

$T$ is \emph{relatively bounded with respect to $A$}.


\subsubsection*{Proof}

The inequality \eqref{eq:Tu-inequality} implies:
\begin{align*}
\norm{Tu} & \le a\norm u+b\norm{Au}
\end{align*}
For $u\in\mathcal{D}\left(A\right)$ holds:
\begin{align*}
Au & =\left(A+T\right)u-Tu
\end{align*}
\begin{align*}
\norm{Au} & \le\norm{\left(A+T\right)u}+\norm{Tu}\le\\
 & \le\norm{\left(A+T\right)u}+a\norm u+b\norm{Au}
\end{align*}
This gives:
\begin{align}
\norm{Au} & \le\frac{1}{1-b}\left(\norm{\left(A+T\right)u}+a\norm u\right)\label{eq:normAu}
\end{align}

\begin{itemize}
\item $\left(A+T\right)$ with $\mathcal{D}\left(A+T\right):=\mathcal{D}\left(A\right)$
is closed: Choose $u_{n}\in\mathcal{D}\left(A\right)$ such that $u_{n}\to u$
and $\left(A+T\right)u_{n}\to w$ converge. We want to show $u\in\mathcal{D}\left(A\right)$
and $\left(A+T\right)u=w$. \eqref{eq:normAu} implies:
\begin{align*}
\norm{A\left(u_{n}-u_{m}\right)} & \le\frac{1}{1-b}\underbrace{\norm{\left(A+T\right)\left(u_{n}-u_{m}\right)}}_{\to0}+\frac{a}{1-b}\underbrace{\norm{u_{n}-u_{m}}}_{\to0}
\end{align*}
This gives $A\left(u_{n}-u_{m}\right)\to0$ and thus $Au_{n}\to v$.
Since $A$ is self-adjoint, it is closed, implying that $u\in\mathcal{D}\left(A\right)$
and $Au=v$.
\item It remains to be showed that $\frac{A+T}{c}\pm\ii$ is surjective
for any $c\in\mathbb{R}_{>0}$. This is equivalent to $A+T\pm\ii c$
being surjective. Since $A$ is self-adjoint, we know that
\begin{align*}
A\pm\ii c:\mathcal{D}\left(A\right) & \to H
\end{align*}
is bijective with:
\begin{align*}
\left(A\pm\ii c\right)^{-1}:H & \to\mathcal{D}\left(A\right)
\end{align*}
This gives:
\begin{align*}
\left(A+T+\ii c\right) & =\underbrace{\left(T\left(A+\ii c\right)^{-1}+\mathbbm{1}\right)}_{\text{to show that this is invertible}}\underbrace{\left(A+\ii c\right)}_{\text{invertible}}
\end{align*}
We show that $\norm{T\left(A+\ii c\right)^{-1}}<1$. Then $\mathbbm{1}+T\left(A+\ii c\right)^{-1}$
has a bounded inverse in terms of the Neumann series.\\
For $u\in H$ define $v:=\left(A+\ii c\right)^{-1}u\in\mathcal{D}\left(A\right)$,
so it holds:
\begin{align}
u & =\left(A+\ii c\right)v\nonumber \\
\norm u^{2} & =\norm{Av}^{2}+c^{2}\norm v^{2}\nonumber \\
\norm v^{2} & \le\frac{1}{c^{2}}\norm u^{2}\label{eq:v}\\
\norm{Av}^{2} & \le\norm u^{2}\label{eq:Av}
\end{align}
We get:
\begin{align*}
\norm{T\left(A+\ii c\right)^{-1}u}^{2} & =\norm{Tv}^{2}\le a^{2}\norm v^{2}+b^{2}\norm{Av}^{2}\le\\
 & \stackrel{\eqref{eq:Av}}{\le}a^{2}\norm v^{2}+b^{2}\norm u^{2}\le\\
 & \stackrel{\eqref{eq:v}}{\le}\frac{a^{2}}{c^{2}}\norm u^{2}+b^{2}\norm u^{2}=\left(\frac{a^{2}}{c^{2}}+b^{2}\right)\norm u^{2}
\end{align*}
By choosing $c$ sufficiently large, we can arrange that with $\tilde{c}<1$
holds for all $u\in H$:
\begin{align*}
\norm{T\left(A+\ii c\right)^{-1}u}^{2} & \le\tilde{c}\norm u^{2}
\end{align*}
This gives:
\begin{align*}
\norm{T\left(A+\ii c\right)^{-1}} & <1
\end{align*}

\end{itemize}
\qqed


\subsubsection*{Back to example \ref{sec:Example-Friedrich-Kato}}

$A=-\ii\frac{\dd}{\dd x}$ is self-adjoint with $\mathcal{D}\left(A\right)$
being the domain of definition of the closure of $A:C_{0}^{\infty}\left(\mathbb{R}\right)\to\mathbb{R}$
and $T=T_{g}$.

If \emph{Kato's condition} is fulfilled, i.e. for all $u\in\mathcal{D}\left(A\right)$
the inequality
\begin{align*}
\norm{T_{g}u}^{2} & \le a^{2}\norm u^{2}+b^{2}\norm{Au}^{2}
\end{align*}
with $a,b\in\mathbb{R}_{>0}$ and $b<1$ holds, then $A+T$ is also
self-adjoint.

For which $g$ is Kato's condition satisfied?
\begin{align*}
\norm{Au}^{2} & =\int_{-\infty}^{\infty}\abs{u'\left(x\right)}^{2}\dd x
\end{align*}
(Let us assume $u\in C_{0}^{\infty}$.)
\begin{align*}
\abs{u\left(x\right)-u\left(y\right)} & =\abs{\int_{x}^{y}1\cdot u'\left(t\right)\dd t}\stackrel{\text{Schwarz}}{\le}\left(\int_{x}^{y}1^{2}\dd t\right)^{\frac{1}{2}}\cdot\left(\int_{x}^{y}\abs{u'\left(t\right)}^{2}\dd t\right)^{\frac{1}{2}}\le\\
 & \le\abs{x-y}^{\frac{1}{2}}\cdot\norm{Au}
\end{align*}
Moreover, the mean value theorem (Mittelwertungleichung) gives for
all $a\in\mathbb{R}$ the existence of a $y\in\left[a-\frac{1}{2},a+\frac{1}{2}\right]$
such that holds:
\begin{align*}
\abs{u\left(y\right)} & \le\int_{a-\frac{1}{2}}^{a+\frac{1}{2}}\abs{u\left(\tau\right)}\dd\tau\stackrel{\text{Schwarz}}{\le}\underbrace{\left(\int_{a-\frac{1}{2}}^{a+\frac{1}{2}}1^{2}\dd t\right)^{\frac{1}{2}}}_{=1}\cdot\left(\int_{a-\frac{1}{2}}^{a+\frac{1}{2}}\abs{u\left(t\right)}^{2}\dd t\right)^{\frac{1}{2}}\le\norm u_{L^{2}}
\end{align*}
This gives:
\begin{align*}
\abs{u\left(x\right)} & \le\abs{u\left(y\right)}+\abs{u\left(x\right)-u\left(y\right)}\le\norm u+\norm{Au}
\end{align*}
Consider now different cases:
\begin{enumerate}
\item case: $g$ is bounded, i.e. $\norm g_{\infty}\le c\in\mathbb{R}_{\ge0}$.
Then holds:
\begin{align*}
\norm{T_{g}u}^{2} & =\int_{\mathbb{R}}\abs{g\left(x\right)}^{2}\abs{u\left(x\right)}^{2}\dd x\le c^{2}\norm u^{2}\\
\Rightarrow\qquad\norm{T_{g}u} & \le c\norm u
\end{align*}
Thus Kato's condition is satisfied with $b=0$.
\item case: $g$ is not bounded and $\norm g_{L^{2}}<1$. Then holds:
\begin{align*}
\norm{T_{g}u}^{2} & =\int_{\mathbb{R}}\abs{g\left(x\right)}^{2}\abs{u\left(x\right)}^{2}\dd x\le\sup_{x\in\mathbb{R}}\abs{u\left(x\right)}^{2}\cdot\norm g_{L^{2}}^{2}\\
\Rightarrow\qquad\norm{T_{g}u} & \le\left(\norm u+\norm{Au}\right)\norm g_{L^{2}}=\norm g_{L^{2}}\cdot\norm u+\norm g_{L^{2}}\cdot\norm{Au}
\end{align*}
Kato's condition is again satisfied.
\item case: $g\in L^{2}\left(\mathbb{R}\right)$, but no bound on $\norm g_{L^{2}}$.
Decompose $g=g_{1}+g_{2}$:
\begin{align*}
g_{1}^{\left(L\right)} & :=g\cdot\chi_{\left[-L,L\right]}\in L^{\infty}\\
g_{2}^{\left(L\right)} & :=g-g_{1}
\end{align*}
From the dominated convergence theorem follows:
\begin{align*}
\norm{g_{2}^{\left(L\right)}}_{L^{2}} & \xrightarrow{L\to\infty}0
\end{align*}
Thus there exists a $L\in\mathbb{R}_{>0}$ with $\norm{g_{2}^{\left(L\right)}}<1$.
Combining case 1 for $g_{1}^{\left(L\right)}$ and case 2 for $g_{2}^{\left(L\right)}$
shows that $A+T_{g}$ is again self-adjoint.
\end{enumerate}

\section{Example}

Consider the operator
\begin{align*}
H & =-\Delta_{\mathbb{R}^{3}}+V
\end{align*}
on $L^{2}\left(\mathbb{R}^{3}\right)$ with:
\begin{align*}
V\left(x\right) & =\begin{cases}
\frac{c}{\norm x} & \text{Coulomb potential}\\
c\cdot\frac{e^{-\norm x}}{\norm x} & \text{Yukawa potential}
\end{cases}
\end{align*}
The goal is to find $\mathcal{D}\left(H\right)$ such that $H$ is
self-adjoint.

Consider the ``unperturbed operator'' $-\Delta_{\mathbb{R}^{3}}$
on $L^{2}\left(\mathbb{R}^{3}\right)$ and use a Fourier transformation
\begin{align*}
\hat{A} & :=U\left(-\Delta_{\mathbb{R}^{3}}\right)U^{-1}f=T_{g}f
\end{align*}
with:
\begin{align*}
\left(T_{g}f\right)\left(k\right) & =\norm k^{2}f\left(k\right)
\end{align*}
Define:
\begin{align*}
\mathcal{D}\left(\hat{A}\right) & :=\left\{ f\in L^{2}\left(\mathbb{R}^{3}\right)\big|\norm k^{2}f\left(k\right)\in L^{2}\left(\mathbb{R}^{3}\right)\right\} \\
\mathcal{D}\left(-\Delta_{\mathbb{R}^{3}}\right) & :=U^{-1}\left(\mathcal{D}\left(\hat{A}\right)\right)=W^{2,2}\left(\mathbb{R}\right)
\end{align*}
Here $W^{k,p}\left(\mathbb{R}\right)$ is a Sobolov space and the
special case $W^{k,2}\left(\mathbb{R}\right)$ is also a Hilbert space.
The norm of $W^{2,2}\left(\mathbb{R}\right)$ is:
\begin{align*}
\norm f_{W^{2,2}}^{2} & =\int\left(\abs f^{2}+\norm{\nabla f}^{2}+\abs{\nabla^{2}f}^{2}\right)\left(x\right)\dd^{3}x
\end{align*}
Functions in $W^{2,2}$ are only weakly differentiable. With elliptic
estimates follows:
\begin{align*}
\norm u_{W^{2,2}} & \le\left(1+\varepsilon\right)\norm{\Delta u}^{2}+c\norm u^{2}
\end{align*}
Also the \emph{Sobolov inequality} and the \emph{Sobolov embedding
theorem} holds:
\begin{align*}
\norm u_{L^{2p}} & \le\varepsilon\norm{\Delta u}^{2}+c\left(\varepsilon\right)\norm u^{2}
\end{align*}
Kato's condition is:
\begin{align*}
\norm{Vu}_{L^{2}}^{2} & \le a^{2}\norm u^{2}+b^{2}\norm{\Delta u}^{2}
\end{align*}
With
\begin{align*}
\frac{1}{p}+\frac{1}{q} & =1
\end{align*}
holds:
\begin{align*}
\norm{Vu}_{L^{2}}^{2} & ?\int_{\mathbb{R}^{3}}\abs{V\left(x\right)}^{2}\abs{u\left(x\right)}^{2}\dd^{3}x\le\norm V_{2q}\cdot\underbrace{\norm u_{2p}}_{\text{Sobolev inequality}}\le\\
 & \le\norm V_{2q}\left(\varepsilon\norm{\Delta u}^{2}+c\left(\varepsilon\right)\norm u^{2}\right)
\end{align*}
Now holds $b:=\varepsilon\norm V_{2q}^{2}<1$ for sufficiently small
$\varepsilon$, provided that $\norm V_{L^{2q}}<\infty$. This is
satisfied for the Yukawa potential, but for the Coulomb potential
one must work a bit harder.


\part*{Appendix\thispagestyle{empty}}

\addcontentsline{toc}{part}{Appendix}

\fancyhead[R]{}
\fancyhead[C]{Appendix}


\chapter*{Acknowledgements}

\addcontentsline{toc}{section}{\hspace*{2.7em}Acknowledgements}

\fancyhead[R]{Acknowledgements}

My special thanks goes to Professor Finster, who gave this lecture
and allowed me to publish this script of the lecture.

I would also like to thank all those, who found errors by careful
reading and told me of them.

\vspace{1cm}


\hfill{}Andreas Völklein


\chapter*{GNU Free Documentation License}

\addcontentsline{toc}{section}{\hspace*{2.7em}GNU Free Documentation License}

\fancyhead[R]{GNU Free Documentation License}

\noindent \begin{center}
Version 1.3, 3 November 2008\\
Copyright © 2000, 2001, 2002, 2007, 2008 Free Software Foundation,
Inc. 
\par\end{center}

\noindent \begin{center}
\texttt{<}\url{https://fsf.org/}\texttt{>}
\par\end{center}

\noindent \begin{center}
Everyone is permitted to copy and distribute verbatim copies of this
license document,\\
but changing it is not allowed
\par\end{center}


\section*{\noun{0. Preamble}}

\noindent The purpose of this License is to make a manual, textbook,
or other functional and useful document “free” in the sense of freedom:
to assure everyone the effective freedom to copy and redistribute
it, with or without modifying it, either commercially or noncommercially.
Secondarily, this License preserves for the author and publisher a
way to get credit for their work, while not being considered responsible
for modifications made by others.

\noindent This License is a kind of “copyleft”, which means that derivative
works of the document must themselves be free in the same sense. It
complements the GNU General Public License, which is a copyleft license
designed for free software.

\noindent We have designed this License in order to use it for manuals
for free software, because free software needs free documentation:
a free program should come with manuals providing the same freedoms
that the software does. But this License is not limited to software
manuals; it can be used for any textual work, regardless of subject
matter or whether it is published as a printed book. We recommend
this License principally for works whose purpose is instruction or
reference.


\section*{\noun{1. Applicability and definitions}}

This License applies to any manual or other work, in any medium, that
contains a notice placed by the copyright holder saying it can be
distributed under the terms of this License. Such a notice grants
a world-wide, royalty-free license, unlimited in duration, to use
that work under the conditions stated herein. The “\textbf{Document}”,
below, refers to any such manual or work. Any member of the public
is a licensee, and is addressed as “\textbf{you}”. You accept the
license if you copy, modify or distribute the work in a way requiring
permission under copyright law.

A “\textbf{Modified Version}” of the Document means any work containing
the Document or a portion of it, either copied verbatim, or with modifications
and/or translated into another language.

A “\textbf{Secondary Section}” is a named appendix or a front-matter
section of the Document that deals exclusively with the relationship
of the publishers or authors of the Document to the Document's overall
subject (or to related matters) and contains nothing that could fall
directly within that overall subject. (Thus, if the Document is in
part a textbook of mathematics, a Secondary Section may not explain
any mathematics.) The relationship could be a matter of historical
connection with the subject or with related matters, or of legal,
commercial, philosophical, ethical or political position regarding
them.

The “\textbf{Invariant Sections}” are certain Secondary Sections whose
titles are designated, as being those of Invariant Sections, in the
notice that says that the Document is released under this License.
If a section does not fit the above definition of Secondary then it
is not allowed to be designated as Invariant. The Document may contain
zero Invariant Sections. If the Document does not identify any Invariant
Sections then there are none.

The “\textbf{Cover Texts}” are certain short passages of text that
are listed, as Front-Cover Texts or Back-Cover Texts, in the notice
that says that the Document is released under this License. A Front-Cover
Text may be at most 5 words, and a Back-Cover Text may be at most
25 words.

A “\textbf{Transparent}” copy of the Document means a machine-readable
copy, represented in a format whose specification is available to
the general public, that is suitable for revising the document straightforwardly
with generic text editors or (for images composed of pixels) generic
paint programs or (for drawings) some widely available drawing editor,
and that is suitable for input to text formatters or for automatic
translation to a variety of formats suitable for input to text formatters.
A copy made in an otherwise Transparent file format whose markup,
or absence of markup, has been arranged to thwart or discourage subsequent
modification by readers is not Transparent. An image format is not
Transparent if used for any substantial amount of text. A copy that
is not “Transparent” is called “\textbf{Opaque}”.

Examples of suitable formats for Transparent copies include plain
ASCII without markup, Texinfo input format, \LaTeX{} input format,
SGML or XML using a publicly available DTD, and standard-conforming
simple HTML, PostScript or PDF designed for human modification. Examples
of transparent image formats include PNG, XCF and JPG. Opaque formats
include proprietary formats that can be read and edited only by proprietary
word processors, SGML or XML for which the DTD and/or processing tools
are not generally available, and the machine-generated HTML, PostScript
or PDF produced by some word processors for output purposes only.

The “\textbf{Title Page}” means, for a printed book, the title page
itself, plus such following pages as are needed to hold, legibly,
the material this License requires to appear in the title page. For
works in formats which do not have any title page as such, “Title
Page” means the text near the most prominent appearance of the work's
title, preceding the beginning of the body of the text.

The “\textbf{publisher}” means any person or entity that distributes
copies of the Document to the public.

A section “\textbf{Entitled XYZ}” means a named subunit of the Document
whose title either is precisely XYZ or contains XYZ in parentheses
following text that translates XYZ in another language. (Here XYZ
stands for a specific section name mentioned below, such as “\textbf{Acknowledgements}”,
“\textbf{Dedications}”, “\textbf{Endorsements}”, or “\textbf{History}”.)
To “\textbf{Preserve the Title}” of such a section when you modify
the Document means that it remains a section “Entitled XYZ” according
to this definition.

The Document may include Warranty Disclaimers next to the notice which
states that this License applies to the Document. These Warranty Disclaimers
are considered to be included by reference in this License, but only
as regards disclaiming warranties: any other implication that these
Warranty Disclaimers may have is void and has no effect on the meaning
of this License.


\section*{\noun{2. Verbatim copying}}

You may copy and distribute the Document in any medium, either commercially
or noncommercially, provided that this License, the copyright notices,
and the license notice saying this License applies to the Document
are reproduced in all copies, and that you add no other conditions
whatsoever to those of this License. You may not use technical measures
to obstruct or control the reading or further copying of the copies
you make or distribute. However, you may accept compensation in exchange
for copies. If you distribute a large enough number of copies you
must also follow the conditions in section 3.

You may also lend copies, under the same conditions stated above,
and you may publicly display copies.


\section*{\noun{3. Copying in quantity}}

If you publish printed copies (or copies in media that commonly have
printed covers) of the Document, numbering more than 100, and the
Document's license notice requires Cover Texts, you must enclose the
copies in covers that carry, clearly and legibly, all these Cover
Texts: Front-Cover Texts on the front cover, and Back-Cover Texts
on the back cover. Both covers must also clearly and legibly identify
you as the publisher of these copies. The front cover must present
the full title with all words of the title equally prominent and visible.
You may add other material on the covers in addition. Copying with
changes limited to the covers, as long as they preserve the title
of the Document and satisfy these conditions, can be treated as verbatim
copying in other respects.

If the required texts for either cover are too voluminous to fit legibly,
you should put the first ones listed (as many as fit reasonably) on
the actual cover, and continue the rest onto adjacent pages.

If you publish or distribute Opaque copies of the Document numbering
more than 100, you must either include a machine-readable Transparent
copy along with each Opaque copy, or state in or with each Opaque
copy a computer-network location from which the general network-using
public has access to download using public-standard network protocols
a complete Transparent copy of the Document, free of added material.
If you use the latter option, you must take reasonably prudent steps,
when you begin distribution of Opaque copies in quantity, to ensure
that this Transparent copy will remain thus accessible at the stated
location until at least one year after the last time you distribute
an Opaque copy (directly or through your agents or retailers) of that
edition to the public.

It is requested, but not required, that you contact the authors of
the Document well before redistributing any large number of copies,
to give them a chance to provide you with an updated version of the
Document.


\section*{\noun{4. Modifications}}

You may copy and distribute a Modified Version of the Document under
the conditions of sections 2 and 3 above, provided that you release
the Modified Version under precisely this License, with the Modified
Version filling the role of the Document, thus licensing distribution
and modification of the Modified Version to whoever possesses a copy
of it. In addition, you must do these things in the Modified Version:
\begin{description}
\item [{A.\hspace*{3.2mm}}] Use in the Title Page (and on the covers,
if any) a title distinct from that of the Document, and from those
of previous versions (which should, if there were any, be listed in
the History section of the Document). You may use the same title as
a previous version if the original publisher of that version gives
permission.
\item [{B.\hspace*{3.4mm}}] List on the Title Page, as authors, one or
more persons or entities responsible for authorship of the modifications
in the Modified Version, together with at least five of the principal
authors of the Document (all of its principal authors, if it has fewer
than five), unless they release you from this requirement.
\item [{C.\hspace*{3.4mm}}] State on the Title page the name of the publisher
of the Modified Version, as the publisher.
\item [{D.\hspace*{3.4mm}}] Preserve all the copyright notices of the
Document.
\item [{E.\hspace*{3.4mm}}] Add an appropriate copyright notice for your
modifications adjacent to the other copyright notices.
\item [{F.\hspace*{3.8mm}}] Include, immediately after the copyright notices,
a license notice giving the public permission to use the Modified
Version under the terms of this License, in the form shown in the
Addendum below.
\item [{G.\hspace*{3.1mm}}] Preserve in that license notice the full lists
of Invariant Sections and required Cover Texts given in the Document's
license notice.
\item [{H.\hspace*{3.2mm}}] Include an unaltered copy of this License.
\item [{I.\hspace*{5.0mm}}] Preserve the section Entitled “History”, Preserve
its Title, and add to it an item stating at least the title, year,
new authors, and publisher of the Modified Version as given on the
Title Page. If there is no section Entitled “History” in the Document,
create one stating the title, year, authors, and publisher of the
Document as given on its Title Page, then add an item describing the
Modified Version as stated in the previous sentence.
\item [{J.\hspace*{4.3mm}}] Preserve the network location, if any, given
in the Document for public access to a Transparent copy of the Document,
and likewise the network locations given in the Document for previous
versions it was based on. These may be placed in the “History” section.
You may omit a network location for a work that was published at least
four years before the Document itself, or if the original publisher
of the version it refers to gives permission.
\item [{K.\hspace*{3.3mm}}] For any section Entitled “Acknowledgements”
or “Dedications”, Preserve the Title of the section, and preserve
in the section all the substance and tone of each of the contributor
acknowledgements and/or dedications given therein.
\item [{L.\hspace*{4.1mm}}] Preserve all the Invariant Sections of the
Document, unaltered in their text and in their titles. Section numbers
or the equivalent are not considered part of the section titles.
\item [{M.\hspace*{3mm}}] Delete any section Entitled “Endorsements”.
Such a section may not be included in the Modified Version.
\item [{N.\hspace*{3.4mm}}] Do not retitle any existing section to be
Entitled “Endorsements” or to conflict in title with any Invariant
Section.
\item [{O.\hspace*{3.4mm}}] Preserve any Warranty Disclaimers.
\end{description}
If the Modified Version includes new front-matter sections or appendices
that qualify as Secondary Sections and contain no material copied
from the Document, you may at your option designate some or all of
these sections as invariant. To do this, add their titles to the list
of Invariant Sections in the Modified Version's license notice. These
titles must be distinct from any other section titles.

You may add a section Entitled “Endorsements”, provided it contains
nothing but endorsements of your Modified Version by various parties—for
example, statements of peer review or that the text has been approved
by an organization as the authoritative definition of a standard.

You may add a passage of up to five words as a Front-Cover Text, and
a passage of up to 25 words as a Back-Cover Text, to the end of the
list of Cover Texts in the Modified Version. Only one passage of Front-Cover
Text and one of Back-Cover Text may be added by (or through arrangements
made by) any one entity. If the Document already includes a cover
text for the same cover, previously added by you or by arrangement
made by the same entity you are acting on behalf of, you may not add
another; but you may replace the old one, on explicit permission from
the previous publisher that added the old one.

The author(s) and publisher(s) of the Document do not by this License
give permission to use their names for publicity for or to assert
or imply endorsement of any Modified Version.


\section*{\noun{5. Combining documents}}

You may combine the Document with other documents released under this
License, under the terms defined in section 4 above for modified versions,
provided that you include in the combination all of the Invariant
Sections of all of the original documents, unmodified, and list them
all as Invariant Sections of your combined work in its license notice,
and that you preserve all their Warranty Disclaimers.

The combined work need only contain one copy of this License, and
multiple identical Invariant Sections may be replaced with a single
copy. If there are multiple Invariant Sections with the same name
but different contents, make the title of each such section unique
by adding at the end of it, in parentheses, the name of the original
author or publisher of that section if known, or else a unique number.
Make the same adjustment to the section titles in the list of Invariant
Sections in the license notice of the combined work.

In the combination, you must combine any sections Entitled “History”
in the various original documents, forming one section Entitled “History”;
likewise combine any sections Entitled “Acknowledgements”, and any
sections Entitled “Dedications”. You must delete all sections Entitled
“Endorsements”.


\section*{\noun{6. Collections of documents}}

You may make a collection consisting of the Document and other documents
released under this License, and replace the individual copies of
this License in the various documents with a single copy that is included
in the collection, provided that you follow the rules of this License
for verbatim copying of each of the documents in all other respects.

You may extract a single document from such a collection, and distribute
it individually under this License, provided you insert a copy of
this License into the extracted document, and follow this License
in all other respects regarding verbatim copying of that document.


\section*{\noun{7. Aggregation with independent works}}

A compilation of the Document or its derivatives with other separate
and independent documents or works, in or on a volume of a storage
or distribution medium, is called an “aggregate” if the copyright
resulting from the compilation is not used to limit the legal rights
of the compilation's users beyond what the individual works permit.
When the Document is included in an aggregate, this License does not
apply to the other works in the aggregate which are not themselves
derivative works of the Document.

If the Cover Text requirement of section 3 is applicable to these
copies of the Document, then if the Document is less than one half
of the entire aggregate, the Document's Cover Texts may be placed
on covers that bracket the Document within the aggregate, or the electronic
equivalent of covers if the Document is in electronic form. Otherwise
they must appear on printed covers that bracket the whole aggregate.


\section*{\noun{8. Translation}}

Translation is considered a kind of modification, so you may distribute
translations of the Document under the terms of section 4. Replacing
Invariant Sections with translations requires special permission from
their copyright holders, but you may include translations of some
or all Invariant Sections in addition to the original versions of
these Invariant Sections. You may include a translation of this License,
and all the license notices in the Document, and any Warranty Disclaimers,
provided that you also include the original English version of this
License and the original versions of those notices and disclaimers.
In case of a disagreement between the translation and the original
version of this License or a notice or disclaimer, the original version
will prevail.

If a section in the Document is Entitled “Acknowledgements”, “Dedications”,
or “History”, the requirement (section 4) to Preserve its Title (section
1) will typically require changing the actual title.


\section*{\noun{9. Termination}}

You may not copy, modify, sublicense, or distribute the Document except
as expressly provided under this License. Any attempt otherwise to
copy, modify, sublicense, or distribute it is void, and will automatically
terminate your rights under this License.

However, if you cease all violation of this License, then your license
from a particular copyright holder is reinstated (a) provisionally,
unless and until the copyright holder explicitly and finally terminates
your license, and (b) permanently, if the copyright holder fails to
notify you of the violation by some reasonable means prior to 60 days
after the cessation.

Moreover, your license from a particular copyright holder is reinstated
permanently if the copyright holder notifies you of the violation
by some reasonable means, this is the first time you have received
notice of violation of this License (for any work) from that copyright
holder, and you cure the violation prior to 30 days after your receipt
of the notice.

Termination of your rights under this section does not terminate the
licenses of parties who have received copies or rights from you under
this License. If your rights have been terminated and not permanently
reinstated, receipt of a copy of some or all of the same material
does not give you any rights to use it.


\section*{\noun{10. Future revisions of this license}}

The Free Software Foundation may publish new, revised versions of
the GNU Free Documentation License from time to time. Such new versions
will be similar in spirit to the present version, but may differ in
detail to address new problems or concerns. See \url{https://www.gnu.org/copyleft/}.

Each version of the License is given a distinguishing version number.
If the Document specifies that a particular numbered version of this
License \textquotedbl{}or any later version\textquotedbl{} applies
to it, you have the option of following the terms and conditions either
of that specified version or of any later version that has been published
(not as a draft) by the Free Software Foundation. If the Document
does not specify a version number of this License, you may choose
any version ever published (not as a draft) by the Free Software Foundation.
If the Document specifies that a proxy can decide which future versions
of this License can be used, that proxy's public statement of acceptance
of a version permanently authorizes you to choose that version for
the Document.


\section*{\noun{11. Relicensing}}

“Massive Multiauthor Collaboration Site” (or “MMC Site”) means any
World Wide Web server that publishes copyrightable works and also
provides prominent facilities for anybody to edit those works. A public
wiki that anybody can edit is an example of such a server. A “Massive
Multiauthor Collaboration” (or “MMC”) contained in the site means
any set of copyrightable works thus published on the MMC site.

“CC-BY-SA” means the Creative Commons Attribution-Share Alike 3.0
license published by Creative Commons Corporation, a not-for-profit
corporation with a principal place of business in San Francisco, California,
as well as future copyleft versions of that license published by that
same organization.

“Incorporate” means to publish or republish a Document, in whole or
in part, as part of another Document.

An MMC is “eligible for relicensing” if it is licensed under this
License, and if all works that were first published under this License
somewhere other than this MMC, and subsequently incorporated in whole
or in part into the MMC, (1) had no cover texts or invariant sections,
and (2) were thus incorporated prior to November 1, 2008.

The operator of an MMC Site may republish an MMC contained in the
site under CC-BY-SA on the same site at any time before August 1,
2009, provided the MMC is eligible for relicensing.


\section*{\noun{Addendum}: How to use this License for your documents}

To use this License in a document you have written, include a copy
of the License in the document and put the following copyright and
license notices just after the title page:
\begin{quote}
Copyright © YEAR YOUR NAME.\\
Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3
or any later version published by the Free Software Foundation;

with no Invariant Sections, no Front-Cover Texts, and no Back-Cover
Texts.

A copy of the license is included in the section entitled \textquotedbl{}GNU
Free Documentation License\textquotedbl{}.
\end{quote}
If you have Invariant Sections, Front-Cover Texts and Back-Cover Texts,
replace the \textquotedbl{}with $\ldots$ Texts.\textquotedbl{} line
with this:
\begin{quote}
with the Invariant Sections being LIST THEIR TITLES, with the Front-Cover
Texts being LIST, and with the Back-Cover Texts being LIST.
\end{quote}
If you have Invariant Sections without Cover Texts, or some other
combination of the three, merge those two alternatives to suit the
situation.

If your document contains nontrivial examples of program code, we
recommend releasing these examples in parallel under your choice of
free software license, such as the GNU General Public License, to
permit their use in free software.

\label{END}
\end{document}
